{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc88f6c2-0fe6-4809-bd30-668aff01e30c",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysing Using Youtube Video Data from Most Popular Channels in the top 10 countries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2c58a7-dc81-4131-802c-ae3435a6ce7f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Aims, objectives and background\n",
    "\n",
    "## 1.1. Introduction\n",
    "\n",
    "Founded in 2005, Youtube has grown to become the second largest search engine in the world (behind Google) that processes more than 3 billion searches per month. [[1]](https://www.mushroomnetworks.com/infographics/youtube---the-2nd-largest-search-engine-infographic/). It is, however, generally a myth how the Youtube algorithm works, what makes a video get views and be recommended over another. In fact, YouTube has one of the largest scale and most sophisticated industrial recommendation systems in existence [[2]](https://dl.acm.org/doi/10.1145/2959100.2959190). For new content creators, it is a challenge to understand why a video gets video and others do not. There are many \"myths\" around the success of a Youtube video [[3]](https://vidiq.com/blog/post/5-youtube-algorithm-myths-youtubers-need-to-know-about/), for example if the video has more likes or comments, or if the video is of a certain duration. It is also worth experimenting and looking for \"trends\" in the topics that Youtube channels are covering in a certain niche.\n",
    "\n",
    "Having recently stepping into the content creation world with a new Youtube channel on data analytics and data science, I decided to gain some insights on this topic which might be useful for other new content creators. The scope of this small project is limited to data science channels and I will not consider other niches (that might have a different characteristics and audience base). Therefore, in this project will explore the statistics of around 10 most successful data science Youtube channel.\n",
    "\n",
    "## 1.2. Aims and objectives\n",
    "\n",
    "Within this project, I would like to explore the following:\n",
    "\n",
    "- Getting to know Youtube API and how to obtain video data.\n",
    "- Analyzing video data and verify different common \"myths\" about what makes a video do well on Youtube, for example:\n",
    "    - Does the number of likes and comments matter for a video to get more views?\n",
    "    - Does the video duration matter for views and interaction (likes/ comments)?\n",
    "    - Does title length matter for views?\n",
    "    - How many tags do good performing videos have? What are the common tags among these videos?\n",
    "    - Across all the creators I take into consideration, how often do they upload new videos? On which days in the week?\n",
    "- Explore the trending topics using NLP techniques\n",
    "    - Which popular topics are being covered in the videos (e.g. using wordcloud for video titles)?\n",
    "    - Which questions are being asked in the comment sections in the videos\n",
    "\n",
    "## 1.3. Steps of the project\n",
    "1. Obtain video meta data via Youtube API for the top 10-15 channels in the data science niche (this includes several small steps: create a developer key, request data and transform the responses into a usable data format)\n",
    "2. Prepocess data and engineer additional features for analysis\n",
    "3. Exploratory data analysis\n",
    "4. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21458ddf-101b-4ecd-8ee8-3cf6655eb46b",
   "metadata": {},
   "source": [
    "## 1.4. Dataset\n",
    "\n",
    "### Data selection\n",
    "\n",
    "As this project is particularly focused on data science channels, I found that not many readily available datasets online are suitable for this purpose. The 2 alternative datasets I found are:\n",
    "\n",
    "- [The top trending Youtube videos on Kaggle](https://www.kaggle.com/rsrishav/youtube-trending-video-dataset): This dataset contains several months of data on daily trending YouTube videos for several countries. There are up to 200 trending videos per day. However, this dataset is not fit for this project because the trending videos are about a wide range of topics that are not necessarily related to data science. \n",
    "\n",
    "- Another dataset is obtained from this [Github repo](https://gitlab.com/thebrahminator/Youtube-View-Predictor) of Vishwanath Seshagiri, which is the metadata of 0.5M+ YouTube videos along with their channel data. There is no clear documentation on how this dataset was created, but a quick look at the datasets in the repository suggested that the data was obtained using keyword search of popular keywords such as \"football\" or \"science\". There are also some relevant keywords such as \"python\". However, I decided not to use these datasets because they don't contain data for the channels I am interested in.\n",
    "\n",
    "I created my own dataset using the [Google Youtube Data API version 3.0](https://developers.google.com/youtube/v3). The exact steps of data creation is presented in section *2. Data Creation* below.\n",
    "\n",
    "### Data limitations\n",
    "\n",
    "The dataset is a real-world dataset and suitable for the research. However, the selection of the top 10 Youtube channels to include in the research is purely based on my knowledge of the channels in data science field and might not be accurate. My definition is \"popular\" is only based on subscriber count but there are other metrics that could be taken into consideration as well (e.g. views, engagement). The top 10 also seems arbitrary given the plethora of channels on Youtube. There might be smaller channels that might also very interesting to look into, which could be the next step of this project.\n",
    "\n",
    "### Ethics of data source\n",
    "\n",
    "According to [Youtube API's guide](https://developers.google.com/youtube/v3/getting-started), the usage of Youtube API is free of charge given that your application send requests within a quota limit. \"The YouTube Data API uses a quota to ensure that developers use the service as intended and do not create applications that unfairly reduce service quality or limit access for others. \" The default quota allocation for each application is 10,000 units per day, and you could request additional quota by completing a form to YouTube API Services if you reach the quota limit.\n",
    "\n",
    "Since all data requested from Youtube API is public data (which everyone on the Internet can see on Youtube), there is no particular privacy issues as far as I am concerned. In addition, the data is obtained only for research purposes in this case and not for any commercial interests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2ba6bd0-2c70-42d5-ab1d-9ebff01c62ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil import parser\n",
    "import isodate\n",
    "\n",
    "# Data visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\", color_codes=True)\n",
    "from IPython.display import JSON\n",
    "\n",
    "# Google API\n",
    "from googleapiclient.discovery import build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab8a223f-2420-421f-8647-344591a19e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jamal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jamal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# NLP libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Aims, objectives and background\n",
    "\n",
    "## 1.1. Introduction\n",
    "\n",
    "Founded in 2005, Youtube has grown to become the second largest search engine in the world (behind Google) that processes more than 3 billion searches per month. [[1]](https://www.mushroomnetworks.com/infographics/youtube---the-2nd-largest-search-engine-infographic/). It is, however, generally a myth how the Youtube algorithm works, what makes a video get views and be recommended over another. In fact, YouTube has one of the largest scale and most sophisticated industrial recommendation systems in existence [[2]](https://dl.acm.org/doi/10.1145/2959100.2959190). For new content creators, it is a challenge to understand why a video gets video and others do not. There are many \"myths\" around the success of a Youtube video [[3]](https://vidiq.com/blog/post/5-youtube-algorithm-myths-youtubers-need-to-know-about/), for example if the video has more likes or comments, or if the video is of a certain duration. It is also worth experimenting and looking for \"trends\" in the topics that Youtube channels are covering in a certain niche.\n",
    "\n",
    "Having recently stepping into the content creation world with a new Youtube channel on data analytics and data science, I decided to gain some insights on this topic which might be useful for other new content creators. The scope of this small project is limited to data science channels and I will not consider other niches (that might have a different characteristics and audience base). Therefore, in this project will explore the statistics of around 10 most successful data science Youtube channel.\n",
    "\n",
    "## 1.2. Aims and objectives\n",
    "\n",
    "Within this project, I would like to explore the following:\n",
    "\n",
    "- Getting to know Youtube API and how to obtain video data.\n",
    "- Analyzing video data and verify different common \"myths\" about what makes a video do well on Youtube, for example:\n",
    "    - Does the number of likes and comments matter for a video to get more views?\n",
    "    - Does the video duration matter for views and interaction (likes/ comments)?\n",
    "    - Does title length matter for views?\n",
    "    - How many tags do good performing videos have? What are the common tags among these videos?\n",
    "    - Across all the creators I take into consideration, how often do they upload new videos? On which days in the week?\n",
    "- Explore the trending topics using NLP techniques\n",
    "    - Which popular topics are being covered in the videos (e.g. using wordcloud for video titles)?\n",
    "    - Which questions are being asked in the comment sections in the videos\n",
    "\n",
    "## 1.3. Steps of the project\n",
    "1. Obtain video meta data via Youtube API for the top 10-15 channels in the data science niche (this includes several small steps: create a developer key, request data and transform the responses into a usable data format)\n",
    "2. Prepocess data and engineer additional features for analysis\n",
    "3. Exploratory data analysis\n",
    "4. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Dataset\n",
    "\n",
    "### Data selection\n",
    "\n",
    "As this project is particularly focused on data science channels, I found that not many readily available datasets online are suitable for this purpose. The 2 alternative datasets I found are:\n",
    "\n",
    "- [The top trending Youtube videos on Kaggle](https://www.kaggle.com/rsrishav/youtube-trending-video-dataset): This dataset contains several months of data on daily trending YouTube videos for several countries. There are up to 200 trending videos per day. However, this dataset is not fit for this project because the trending videos are about a wide range of topics that are not necessarily related to data science. \n",
    "\n",
    "- Another dataset is obtained from this [Github repo](https://gitlab.com/thebrahminator/Youtube-View-Predictor) of Vishwanath Seshagiri, which is the metadata of 0.5M+ YouTube videos along with their channel data. There is no clear documentation on how this dataset was created, but a quick look at the datasets in the repository suggested that the data was obtained using keyword search of popular keywords such as \"football\" or \"science\". There are also some relevant keywords such as \"python\". However, I decided not to use these datasets because they don't contain data for the channels I am interested in.\n",
    "\n",
    "I created my own dataset using the [Google Youtube Data API version 3.0](https://developers.google.com/youtube/v3). The exact steps of data creation is presented in section *2. Data Creation* below.\n",
    "\n",
    "### Data limitations\n",
    "\n",
    "The dataset is a real-world dataset and suitable for the research. However, the selection of the top 10 Youtube channels to include in the research is purely based on my knowledge of the channels in data science field and might not be accurate. My definition is \"popular\" is only based on subscriber count but there are other metrics that could be taken into consideration as well (e.g. views, engagement). The top 10 also seems arbitrary given the plethora of channels on Youtube. There might be smaller channels that might also very interesting to look into, which could be the next step of this project.\n",
    "\n",
    "### Ethics of data source\n",
    "\n",
    "According to [Youtube API's guide](https://developers.google.com/youtube/v3/getting-started), the usage of Youtube API is free of charge given that your application send requests within a quota limit. \"The YouTube Data API uses a quota to ensure that developers use the service as intended and do not create applications that unfairly reduce service quality or limit access for others. \" The default quota allocation for each application is 10,000 units per day, and you could request additional quota by completing a form to YouTube API Services if you reach the quota limit.\n",
    "\n",
    "Since all data requested from Youtube API is public data (which everyone on the Internet can see on Youtube), there is no particular privacy issues as far as I am concerned. In addition, the data is obtained only for research purposes in this case and not for any commercial interests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil import parser\n",
    "import isodate\n",
    "\n",
    "# Data visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\", color_codes=True)\n",
    "from IPython.display import JSON\n",
    "\n",
    "# Google API\n",
    "from googleapiclient.discovery import build\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jamal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jamal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# NLP libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be282b2-b566-4587-97d1-71b680cf6b92",
   "metadata": {},
   "source": [
    "# 2. Data creation with Youtube API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400f8704-cfe4-495b-af35-bb5dfb677c6e",
   "metadata": {},
   "source": [
    "I first created a project on Google Developers Console, then requested an authorization credential (API key). Afterwards, I enabled Youtube API for my application, so that I can send API requests to Youtube API services. Then, I went on Youtube and checked the channel ID of each of the channels that I would like to include in my research scope (using their URLs). Then I created the functions for getting the channel statistics via the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'AIzaSyDs9TExsfc8fDMn4lBRYXZax1vSr0ftsdk'  # Youtube API key Personal \n",
    "\n",
    "channel_ids = ['UCX6OQ3DkcsbYNE6H8uQQuVA', # Mr. Beast US\n",
    "               'UCbCmjCuTUZos6Inko4u57UQ', # Cocomelon US\n",
    "               'UCqwUrj10mAEsqezcItqvwEw', # Bhuvaneshwar Bam IN\n",
    "               'UC_vcKmg67vjMP7ciLnSxSHQ', # Amit Bhadana IN\n",
    "               'UCZf__ehlCEBPop-_sldpBUQ', # HikakinTV JP\n",
    "               'UC1opHUrw8rvnsadT-iGp7Cg', # PewDiePie SE\n",
    "               'UCYWOjHweP2V-8kGKmmAmQJQ', # Badabun MX \n",
    "               'UCECJDeK0MNapZbpaOzxrUPA', # Luisito Comunica MX\n",
    "               'UCOmHUn--16B90oW2L6FRR3A', # BLACKPINK\n",
    "              ]\n",
    "\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kind': 'youtube#channelListResponse', 'etag': 'L55fUgO1n8nsS6u_ZzrecJPX02k', 'pageInfo': {'totalResults': 9, 'resultsPerPage': 5}, 'items': [{'kind': 'youtube#channel', 'etag': 'Y5wkvLzlzNUyvDHlL9OUn5Jj_ik', 'id': 'UC1opHUrw8rvnsadT-iGp7Cg', 'snippet': {'title': 'Aqua Ch. 湊あくあ', 'description': \"ζ*(・ヮ・)*ζ＜みなさんどうもこんあくあ～！\\nホロライブ所属すーぱーあいどるゲーマーメイドの湊あくあです！\\n歌ったりゲームすることが大好きです！チャンネル登録してね～～～！\\n\\nζ*(・ヮ・)*ζ＜konaqua~!!\\nI'm Minato Aqua.\\nI love the game & singing. Super Idol Gamer Maid♥\\nNice to meet you!!\", 'customUrl': '@minatoaqua', 'publishedAt': '2018-08-01T06:38:45Z', 'thumbnails': {'default': {'url': 'https://yt3.ggpht.com/ytc/APkrFKYNHGxqc20HFlu8ZfmrBWOZLYubAKfoEqIxFNTW7w=s88-c-k-c0x00ffffff-no-rj-mo', 'width': 88, 'height': 88}, 'medium': {'url': 'https://yt3.ggpht.com/ytc/APkrFKYNHGxqc20HFlu8ZfmrBWOZLYubAKfoEqIxFNTW7w=s240-c-k-c0x00ffffff-no-rj-mo', 'width': 240, 'height': 240}, 'high': {'url': 'https://yt3.ggpht.com/ytc/APkrFKYNHGxqc20HFlu8ZfmrBWOZLYubAKfoEqIxFNTW7w=s800-c-k-c0x00ffffff-no-rj-mo', 'width': 800, 'height': 800}}, 'localized': {'title': 'Aqua Ch. 湊あくあ', 'description': \"ζ*(・ヮ・)*ζ＜みなさんどうもこんあくあ～！\\nホロライブ所属すーぱーあいどるゲーマーメイドの湊あくあです！\\n歌ったりゲームすることが大好きです！チャンネル登録してね～～～！\\n\\nζ*(・ヮ・)*ζ＜konaqua~!!\\nI'm Minato Aqua.\\nI love the game & singing. Super Idol Gamer Maid♥\\nNice to meet you!!\"}, 'country': 'JP'}, 'contentDetails': {'relatedPlaylists': {'likes': '', 'uploads': 'UU1opHUrw8rvnsadT-iGp7Cg'}}, 'statistics': {'viewCount': '368194153', 'subscriberCount': '1920000', 'hiddenSubscriberCount': False, 'videoCount': '592'}}, {'kind': 'youtube#channel', 'etag': 'F-GclJqUv8BExKItHMwbddQEaEA', 'id': 'UCECJDeK0MNapZbpaOzxrUPA', 'snippet': {'title': 'Luisito Comunica', 'description': 'El canal más chido de YouTube\\n\\nluisitocomunica@wearedw.com', 'customUrl': '@luisitocomunica', 'publishedAt': '2012-04-15T04:13:36Z', 'thumbnails': {'default': {'url': 'https://yt3.ggpht.com/ytc/APkrFKY-TKOgTF1bXy2GFCc8fIMU1HKP53JZPvU86380Fw=s88-c-k-c0x00ffffff-no-rj', 'width': 88, 'height': 88}, 'medium': {'url': 'https://yt3.ggpht.com/ytc/APkrFKY-TKOgTF1bXy2GFCc8fIMU1HKP53JZPvU86380Fw=s240-c-k-c0x00ffffff-no-rj', 'width': 240, 'height': 240}, 'high': {'url': 'https://yt3.ggpht.com/ytc/APkrFKY-TKOgTF1bXy2GFCc8fIMU1HKP53JZPvU86380Fw=s800-c-k-c0x00ffffff-no-rj', 'width': 800, 'height': 800}}, 'localized': {'title': 'Luisito Comunica', 'description': 'El canal más chido de YouTube\\n\\nluisitocomunica@wearedw.com'}, 'country': 'MX'}, 'contentDetails': {'relatedPlaylists': {'likes': '', 'uploads': 'UUECJDeK0MNapZbpaOzxrUPA'}}, 'statistics': {'viewCount': '9048186869', 'subscriberCount': '41400000', 'hiddenSubscriberCount': False, 'videoCount': '1316'}}, {'kind': 'youtube#channel', 'etag': 'R3doFHwpGOGtnio_9L42zFvRvCk', 'id': 'UCZf__ehlCEBPop-_sldpBUQ', 'snippet': {'title': 'HikakinTV', 'description': '登録ありがとうございます。\\n◆プロフィール◆\\nYouTubeにてHIKAKIN、HikakinTV、HikakinGames、HikakinBlogと\\n４つのチャンネルを運営し、動画の総アクセス数は180億回を突破、\\nチャンネル登録者数は計2000万人以上、YouTubeタレント事務所uuum株式会社ファウンダー兼最高顧問。', 'customUrl': '@hikakintv', 'publishedAt': '2011-07-19T11:31:43Z', 'thumbnails': {'default': {'url': 'https://yt3.ggpht.com/ytc/APkrFKaRKZAxzI0lN-B6GUJ_GIF65TNJFG0mQar3XLLyoA=s88-c-k-c0x00ffffff-no-rj', 'width': 88, 'height': 88}, 'medium': {'url': 'https://yt3.ggpht.com/ytc/APkrFKaRKZAxzI0lN-B6GUJ_GIF65TNJFG0mQar3XLLyoA=s240-c-k-c0x00ffffff-no-rj', 'width': 240, 'height': 240}, 'high': {'url': 'https://yt3.ggpht.com/ytc/APkrFKaRKZAxzI0lN-B6GUJ_GIF65TNJFG0mQar3XLLyoA=s800-c-k-c0x00ffffff-no-rj', 'width': 800, 'height': 800}}, 'localized': {'title': 'HikakinTV', 'description': '登録ありがとうございます。\\n◆プロフィール◆\\nYouTubeにてHIKAKIN、HikakinTV、HikakinGames、HikakinBlogと\\n４つのチャンネルを運営し、動画の総アクセス数は180億回を突破、\\nチャンネル登録者数は計2000万人以上、YouTubeタレント事務所uuum株式会社ファウンダー兼最高顧問。'}}, 'contentDetails': {'relatedPlaylists': {'likes': '', 'uploads': 'UUZf__ehlCEBPop-_sldpBUQ'}}, 'statistics': {'viewCount': '11705114156', 'subscriberCount': '11900000', 'hiddenSubscriberCount': False, 'videoCount': '3367'}}, {'kind': 'youtube#channel', 'etag': 'H-XPjd9XnZm7mQdXJaFrtD-PQxw', 'id': 'UCX6OQ3DkcsbYNE6H8uQQuVA', 'snippet': {'title': 'MrBeast', 'description': \"SUBSCRIBE FOR A COOKIE!\\nAccomplishments:\\n- Raised $20,000,000 To Plant 20,000,000 Trees\\n- Removed 30,000,000 pounds of trash from the ocean\\n- Built wells in Africa\\n- helped 1,000 blind people see\\n- helped 1,000 deaf people hear\\n- Given millions to charity\\n- Started my own snack company Feastables\\n- Donated over 100 cars lol\\n- Gave away a private island (twice)\\n- Gave away 1 million dollars in one video\\n- Counted to 100k\\n- Read the Dictionary\\n- Read Bee Movie Script\\n- Read Longest English Word\\n- Watched Paint Dry\\n- Ubering Across America\\n- Watched It's Every Day Bro For 10 Hours\\n- Ran a marathon in the world's largest shoes\\n- Adopted every dog in a shelter\\n- Bought $1,000,000 in lottery tickets\\n- Sold houses for $1\\n- I got buried alive\\n- Recreated Squid Game in real life\\n- Gave away a chocolate factory\\n- Gave away private jet\\n- Survived 50 hours in Antarctica\\nYou get the point haha\\n\\n\\n*Do not email me asking for money, I give away money because it makes me happy :)\", 'customUrl': '@mrbeast', 'publishedAt': '2012-02-20T00:43:50Z', 'thumbnails': {'default': {'url': 'https://yt3.ggpht.com/ytc/APkrFKbAfC_5NBQ3CM6Lyd2zXUFbC4mym1GCRhmpIwcMXg=s88-c-k-c0x00ffffff-no-rj', 'width': 88, 'height': 88}, 'medium': {'url': 'https://yt3.ggpht.com/ytc/APkrFKbAfC_5NBQ3CM6Lyd2zXUFbC4mym1GCRhmpIwcMXg=s240-c-k-c0x00ffffff-no-rj', 'width': 240, 'height': 240}, 'high': {'url': 'https://yt3.ggpht.com/ytc/APkrFKbAfC_5NBQ3CM6Lyd2zXUFbC4mym1GCRhmpIwcMXg=s800-c-k-c0x00ffffff-no-rj', 'width': 800, 'height': 800}}, 'localized': {'title': 'MrBeast', 'description': \"SUBSCRIBE FOR A COOKIE!\\nAccomplishments:\\n- Raised $20,000,000 To Plant 20,000,000 Trees\\n- Removed 30,000,000 pounds of trash from the ocean\\n- Built wells in Africa\\n- helped 1,000 blind people see\\n- helped 1,000 deaf people hear\\n- Given millions to charity\\n- Started my own snack company Feastables\\n- Donated over 100 cars lol\\n- Gave away a private island (twice)\\n- Gave away 1 million dollars in one video\\n- Counted to 100k\\n- Read the Dictionary\\n- Read Bee Movie Script\\n- Read Longest English Word\\n- Watched Paint Dry\\n- Ubering Across America\\n- Watched It's Every Day Bro For 10 Hours\\n- Ran a marathon in the world's largest shoes\\n- Adopted every dog in a shelter\\n- Bought $1,000,000 in lottery tickets\\n- Sold houses for $1\\n- I got buried alive\\n- Recreated Squid Game in real life\\n- Gave away a chocolate factory\\n- Gave away private jet\\n- Survived 50 hours in Antarctica\\nYou get the point haha\\n\\n\\n*Do not email me asking for money, I give away money because it makes me happy :)\"}, 'country': 'US'}, 'contentDetails': {'relatedPlaylists': {'likes': '', 'uploads': 'UUX6OQ3DkcsbYNE6H8uQQuVA'}}, 'statistics': {'viewCount': '36157434388', 'subscriberCount': '207000000', 'hiddenSubscriberCount': False, 'videoCount': '765'}}, {'kind': 'youtube#channel', 'etag': 'ijAl89Php7tySx16jJF96nCj1sk', 'id': 'UCYWOjHweP2V-8kGKmmAmQJQ', 'snippet': {'title': 'Badabun', 'description': '', 'customUrl': '@badabunoficial', 'publishedAt': '2014-10-14T00:15:54Z', 'thumbnails': {'default': {'url': 'https://yt3.ggpht.com/80xetee0SWVYmzEzpqOHG-MhmBZ1xapnmGVAUqtYxQnVSB7-NAh95XzCF6iexAuclKTns0b-=s88-c-k-c0x00ffffff-no-rj', 'width': 88, 'height': 88}, 'medium': {'url': 'https://yt3.ggpht.com/80xetee0SWVYmzEzpqOHG-MhmBZ1xapnmGVAUqtYxQnVSB7-NAh95XzCF6iexAuclKTns0b-=s240-c-k-c0x00ffffff-no-rj', 'width': 240, 'height': 240}, 'high': {'url': 'https://yt3.ggpht.com/80xetee0SWVYmzEzpqOHG-MhmBZ1xapnmGVAUqtYxQnVSB7-NAh95XzCF6iexAuclKTns0b-=s800-c-k-c0x00ffffff-no-rj', 'width': 800, 'height': 800}}, 'localized': {'title': 'Badabun', 'description': ''}, 'country': 'MX'}, 'contentDetails': {'relatedPlaylists': {'likes': '', 'uploads': 'UUYWOjHweP2V-8kGKmmAmQJQ'}}, 'statistics': {'viewCount': '19552977150', 'subscriberCount': '47100000', 'hiddenSubscriberCount': False, 'videoCount': '19503'}}, {'kind': 'youtube#channel', 'etag': 'Klh2XLcbTs-_pZkjl_emX6txfFU', 'id': 'UCOmHUn--16B90oW2L6FRR3A', 'snippet': {'title': 'BLACKPINK', 'description': 'BLACKPINK Official YouTube Channel\\n블랙핑크 공식 유튜브 채널입니다.\\n\\nJISOO, JENNIE, ROSÉ, LISA\\n지수, 제니, 로제, 리사', 'customUrl': '@blackpink', 'publishedAt': '2016-06-29T03:15:23Z', 'thumbnails': {'default': {'url': 'https://yt3.ggpht.com/hZDUwjoeQqigphL4A1tkg9c6hVp5yXmbboBR7PYFUSFj5PIJSA483NB5v7b0XVoTN9GCku3tqQ=s88-c-k-c0x00ffffff-no-nd-rj', 'width': 88, 'height': 88}, 'medium': {'url': 'https://yt3.ggpht.com/hZDUwjoeQqigphL4A1tkg9c6hVp5yXmbboBR7PYFUSFj5PIJSA483NB5v7b0XVoTN9GCku3tqQ=s240-c-k-c0x00ffffff-no-nd-rj', 'width': 240, 'height': 240}, 'high': {'url': 'https://yt3.ggpht.com/hZDUwjoeQqigphL4A1tkg9c6hVp5yXmbboBR7PYFUSFj5PIJSA483NB5v7b0XVoTN9GCku3tqQ=s800-c-k-c0x00ffffff-no-nd-rj', 'width': 800, 'height': 800}}, 'localized': {'title': 'BLACKPINK', 'description': 'BLACKPINK Official YouTube Channel\\n블랙핑크 공식 유튜브 채널입니다.\\n\\nJISOO, JENNIE, ROSÉ, LISA\\n지수, 제니, 로제, 리사'}, 'country': 'KR'}, 'contentDetails': {'relatedPlaylists': {'likes': '', 'uploads': 'UUOmHUn--16B90oW2L6FRR3A'}}, 'statistics': {'viewCount': '33904663784', 'subscriberCount': '92000000', 'hiddenSubscriberCount': False, 'videoCount': '585'}}, {'kind': 'youtube#channel', 'etag': '79pcv6PE3mWNL5c-BIU2VukDVgw', 'id': 'UC_vcKmg67vjMP7ciLnSxSHQ', 'snippet': {'title': 'Amit Bhadana', 'description': 'Business queries - amitbhadana@comogram.com\\nI will find you and make you laugh :)', 'customUrl': '@amitbhadana', 'publishedAt': '2012-10-24T13:00:34Z', 'thumbnails': {'default': {'url': 'https://yt3.ggpht.com/1vX1mZYVJJcNlU_X1jwHJYqelk9Q1Z4u65wYDlhDwsRrwlg601-Wuql_DSYO_Ogkt86DA8WU=s88-c-k-c0x00ffffff-no-rj', 'width': 88, 'height': 88}, 'medium': {'url': 'https://yt3.ggpht.com/1vX1mZYVJJcNlU_X1jwHJYqelk9Q1Z4u65wYDlhDwsRrwlg601-Wuql_DSYO_Ogkt86DA8WU=s240-c-k-c0x00ffffff-no-rj', 'width': 240, 'height': 240}, 'high': {'url': 'https://yt3.ggpht.com/1vX1mZYVJJcNlU_X1jwHJYqelk9Q1Z4u65wYDlhDwsRrwlg601-Wuql_DSYO_Ogkt86DA8WU=s800-c-k-c0x00ffffff-no-rj', 'width': 800, 'height': 800}}, 'localized': {'title': 'Amit Bhadana', 'description': 'Business queries - amitbhadana@comogram.com\\nI will find you and make you laugh :)'}, 'country': 'IN'}, 'contentDetails': {'relatedPlaylists': {'likes': '', 'uploads': 'UU_vcKmg67vjMP7ciLnSxSHQ'}}, 'statistics': {'viewCount': '2428790270', 'subscriberCount': '24500000', 'hiddenSubscriberCount': False, 'videoCount': '106'}}, {'kind': 'youtube#channel', 'etag': 'C5a4vIByLQpOwQetS4Y-Oh2VXmA', 'id': 'UCqwUrj10mAEsqezcItqvwEw', 'snippet': {'title': 'BB Ki Vines', 'description': 'BB Ki Vines is a channel that chronicles the everyday happenings in the lives of BB and his family members.\\n\\nBhuvan Bam is an actor, singer-songwriter, comedian and entrepreneur. He began his journey in 2012, as a performer at a restaurant in Delhi and then in 2015, began uploading short comedy sketches to his YouTube channel. He also runs his merchandise brand, Youthiapa which was founded in 2017. Bhuvan is amongst the first independent creators to cross 10 million subscribers. He starred in a short film, Plus Minus which earned him a Filmfare award. In 2020, he was named in Forbes’ 30 Under 30 List.\\n\\nBhuvan is a staunch believer of education equality and has even partnered with Youtube to share the importance of Girl Child Education. He is the only creator to be invited to cover the World Economic Forum in Davos.\\n\\nThis is the official channel of Bhuvan Bam.\\n\\nFor business enquiries contact: manage@bbkivines.in\\n', 'customUrl': '@bbkivines', 'publishedAt': '2015-06-20T08:40:00Z', 'thumbnails': {'default': {'url': 'https://yt3.ggpht.com/l_ZIXrVEQcHTBTsmpt2CFiWJF9_0hwB3rngr1_lxozZ3Lz58Ij5TcDFOp2TYlioU2gI9RlyExw=s88-c-k-c0x00ffffff-no-rj', 'width': 88, 'height': 88}, 'medium': {'url': 'https://yt3.ggpht.com/l_ZIXrVEQcHTBTsmpt2CFiWJF9_0hwB3rngr1_lxozZ3Lz58Ij5TcDFOp2TYlioU2gI9RlyExw=s240-c-k-c0x00ffffff-no-rj', 'width': 240, 'height': 240}, 'high': {'url': 'https://yt3.ggpht.com/l_ZIXrVEQcHTBTsmpt2CFiWJF9_0hwB3rngr1_lxozZ3Lz58Ij5TcDFOp2TYlioU2gI9RlyExw=s800-c-k-c0x00ffffff-no-rj', 'width': 800, 'height': 800}}, 'localized': {'title': 'BB Ki Vines', 'description': 'BB Ki Vines is a channel that chronicles the everyday happenings in the lives of BB and his family members.\\n\\nBhuvan Bam is an actor, singer-songwriter, comedian and entrepreneur. He began his journey in 2012, as a performer at a restaurant in Delhi and then in 2015, began uploading short comedy sketches to his YouTube channel. He also runs his merchandise brand, Youthiapa which was founded in 2017. Bhuvan is amongst the first independent creators to cross 10 million subscribers. He starred in a short film, Plus Minus which earned him a Filmfare award. In 2020, he was named in Forbes’ 30 Under 30 List.\\n\\nBhuvan is a staunch believer of education equality and has even partnered with Youtube to share the importance of Girl Child Education. He is the only creator to be invited to cover the World Economic Forum in Davos.\\n\\nThis is the official channel of Bhuvan Bam.\\n\\nFor business enquiries contact: manage@bbkivines.in\\n'}, 'country': 'IN'}, 'contentDetails': {'relatedPlaylists': {'likes': '', 'uploads': 'UUqwUrj10mAEsqezcItqvwEw'}}, 'statistics': {'viewCount': '4824402860', 'subscriberCount': '26300000', 'hiddenSubscriberCount': False, 'videoCount': '190'}}, {'kind': 'youtube#channel', 'etag': 'rMH7_z2bWPAohpNZBCCeSkbjTvg', 'id': 'UCbCmjCuTUZos6Inko4u57UQ', 'snippet': {'title': 'Cocomelon - Nursery Rhymes', 'description': 'At CoComelon, our primary goal has always been to engage families with entertaining and educational content that makes universally-relatable preschool moments fun. \\nOur beautiful 3D animation and toe-tapping songs create a world that centers on the everyday experiences of young children. \\nIn addition to helping preschoolers learn letters, numbers, animal sounds, colors, and more, \\nthe videos impart prosocial life lessons, providing parents with an opportunity to teach and play with their children as they watch together.\\n\\nCoComelon. Where kids can be happy and smart!\\n\\nWebsite ► https://cocomelon.com/ \\nFacebook ►https://www.facebook.com/CoComelonKids \\nInstagram ►https://www.instagram.com/cocomelon_official/ \\nTikTok ► https://www.tiktok.com/@cocomelon\\n', 'customUrl': '@cocomelon', 'publishedAt': '2006-09-01T22:18:49Z', 'thumbnails': {'default': {'url': 'https://yt3.ggpht.com/ytc/APkrFKbLXhZ7Ymj04WG4qmGwzucU8C9-l-7Oqb6cuWuIWg=s88-c-k-c0x00ffffff-no-rj-mo', 'width': 88, 'height': 88}, 'medium': {'url': 'https://yt3.ggpht.com/ytc/APkrFKbLXhZ7Ymj04WG4qmGwzucU8C9-l-7Oqb6cuWuIWg=s240-c-k-c0x00ffffff-no-rj-mo', 'width': 240, 'height': 240}, 'high': {'url': 'https://yt3.ggpht.com/ytc/APkrFKbLXhZ7Ymj04WG4qmGwzucU8C9-l-7Oqb6cuWuIWg=s800-c-k-c0x00ffffff-no-rj-mo', 'width': 800, 'height': 800}}, 'localized': {'title': 'Cocomelon - Nursery Rhymes', 'description': 'At CoComelon, our primary goal has always been to engage families with entertaining and educational content that makes universally-relatable preschool moments fun. \\nOur beautiful 3D animation and toe-tapping songs create a world that centers on the everyday experiences of young children. \\nIn addition to helping preschoolers learn letters, numbers, animal sounds, colors, and more, \\nthe videos impart prosocial life lessons, providing parents with an opportunity to teach and play with their children as they watch together.\\n\\nCoComelon. Where kids can be happy and smart!\\n\\nWebsite ► https://cocomelon.com/ \\nFacebook ►https://www.facebook.com/CoComelonKids \\nInstagram ►https://www.instagram.com/cocomelon_official/ \\nTikTok ► https://www.tiktok.com/@cocomelon\\n'}, 'country': 'US'}, 'contentDetails': {'relatedPlaylists': {'likes': '', 'uploads': 'UUbCmjCuTUZos6Inko4u57UQ'}}, 'statistics': {'viewCount': '170365245506', 'subscriberCount': '167000000', 'hiddenSubscriberCount': False, 'videoCount': '1027'}}]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "\n",
    "# Get credentials and create an API client\n",
    "youtube = build(\n",
    "    api_service_name, api_version, developerKey=api_key)\n",
    "\n",
    "request = youtube.channels().list(\n",
    "    part=\"snippet,contentDetails,statistics\",\n",
    "    id=','.join(channel_ids)\n",
    ")\n",
    "response = request.execute()\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c0493ab-cf9e-48e0-bbed-05ee47b71df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_stats(youtube, channel_ids):\n",
    "    \"\"\"\n",
    "    Get channel statistics: title, subscriber count, view count, video count, upload playlist\n",
    "    Params:\n",
    "    \n",
    "    youtube: the build object from googleapiclient.discovery\n",
    "    channels_ids: list of channel IDs\n",
    "    \n",
    "    Returns:\n",
    "    Dataframe containing the channel statistics for all channels in the provided list: title, subscriber count, view count, video count, upload playlist\n",
    "    \n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    request = youtube.channels().list(\n",
    "                part='snippet,contentDetails,statistics',\n",
    "                id=','.join(channel_ids))\n",
    "    response = request.execute() \n",
    "    \n",
    "    for i in range(len(response['items'])):\n",
    "        data = dict(channelName = response['items'][i]['snippet']['title'],\n",
    "                    subscribers = response['items'][i]['statistics']['subscriberCount'],\n",
    "                    views = response['items'][i]['statistics']['viewCount'],\n",
    "                    totalVideos = response['items'][i]['statistics']['videoCount'],\n",
    "                    playlistId = response['items'][i]['contentDetails']['relatedPlaylists']['uploads'])\n",
    "        all_data.append(data)\n",
    "    \n",
    "    return pd.DataFrame(all_data)\n",
    "\n",
    "def get_video_ids(youtube, playlist_id):\n",
    "    \"\"\"\n",
    "    Get list of video IDs of all videos in the given playlist\n",
    "    Params:\n",
    "    \n",
    "    youtube: the build object from googleapiclient.discovery\n",
    "    playlist_id: playlist ID of the channel\n",
    "    \n",
    "    Returns:\n",
    "    List of video IDs of all videos in the playlist\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    request = youtube.playlistItems().list(\n",
    "                part='contentDetails',\n",
    "                playlistId = playlist_id,\n",
    "                maxResults = 50)\n",
    "    response = request.execute()\n",
    "    \n",
    "    video_ids = []\n",
    "    \n",
    "    if 'items' in response:\n",
    "        for i in range(len(response['items'])):\n",
    "            video_ids.append(response['items'][i]['contentDetails']['videoId'])\n",
    "\n",
    "    next_page_token = response.get('nextPageToken')\n",
    "    more_pages = True\n",
    "    \n",
    "    while more_pages and next_page_token is not None:\n",
    "        request = youtube.playlistItems().list(\n",
    "                    part='contentDetails',\n",
    "                    playlistId = playlist_id,\n",
    "                    maxResults = 50,\n",
    "                    pageToken = next_page_token)\n",
    "        response = request.execute()\n",
    "\n",
    "        if 'items' in response:\n",
    "            for i in range(len(response['items'])):\n",
    "                video_ids.append(response['items'][i]['contentDetails']['videoId'])\n",
    "\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "        \n",
    "    return video_ids\n",
    "\n",
    "def get_video_details(youtube, video_ids):\n",
    "    \"\"\"\n",
    "    Get video statistics of all videos with given IDs\n",
    "    Params:\n",
    "    \n",
    "    youtube: the build object from googleapiclient.discovery\n",
    "    video_ids: list of video IDs\n",
    "    \n",
    "    Returns:\n",
    "    Dataframe with statistics of videos, i.e.:\n",
    "        'channelTitle', 'title', 'description', 'tags', 'publishedAt'\n",
    "        'viewCount', 'likeCount', 'favoriteCount', 'commentCount'\n",
    "        'duration', 'definition', 'caption'\n",
    "    \"\"\"\n",
    "        \n",
    "    all_video_info = []\n",
    "    \n",
    "    for i in range(0, len(video_ids), 50):\n",
    "        request = youtube.videos().list(\n",
    "            part=\"snippet,contentDetails,statistics\",\n",
    "            id=','.join(video_ids[i:i+50])\n",
    "        )\n",
    "        response = request.execute() \n",
    "\n",
    "        for video in response['items']:\n",
    "            stats_to_keep = {'snippet': ['channelTitle', 'title', 'description', 'tags', 'publishedAt'],\n",
    "                             'statistics': ['viewCount', 'likeCount', 'favouriteCount', 'commentCount'],\n",
    "                             'contentDetails': ['duration', 'definition', 'caption']\n",
    "                            }\n",
    "            video_info = {}\n",
    "            video_info['video_id'] = video['id']\n",
    "\n",
    "            for k in stats_to_keep.keys():\n",
    "                for v in stats_to_keep[k]:\n",
    "                    try:\n",
    "                        video_info[v] = video[k][v]\n",
    "                    except:\n",
    "                        video_info[v] = None\n",
    "\n",
    "            all_video_info.append(video_info)\n",
    "            \n",
    "    return pd.DataFrame(all_video_info)\n",
    "\n",
    "def get_comments_in_videos(youtube, video_ids):\n",
    "    \"\"\"\n",
    "    Get top level comments as text from all videos with given IDs (only the first 10 comments due to quote limit of Youtube API)\n",
    "    Params:\n",
    "    \n",
    "    youtube: the build object from googleapiclient.discovery\n",
    "    video_ids: list of video IDs\n",
    "    \n",
    "    Returns:\n",
    "    Dataframe with video IDs and associated top level comment in text.\n",
    "    \n",
    "    \"\"\"\n",
    "    all_comments = []\n",
    "    \n",
    "    for video_id in video_ids:\n",
    "        try:   \n",
    "            request = youtube.commentThreads().list(\n",
    "                part=\"snippet,replies\",\n",
    "                videoId=video_id\n",
    "            )\n",
    "            response = request.execute()\n",
    "        \n",
    "            comments_in_video = [comment['snippet']['topLevelComment']['snippet']['textOriginal'] for comment in response['items'][0:10]]\n",
    "            comments_in_video_info = {'video_id': video_id, 'comments': comments_in_video}\n",
    "\n",
    "            all_comments.append(comments_in_video_info)\n",
    "            \n",
    "        except: \n",
    "            # When error occurs - most likely because comments are disabled on a video\n",
    "            print('Could not get comments for video ' + video_id)\n",
    "        \n",
    "    return pd.DataFrame(all_comments)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channelName</th>\n",
       "      <th>subscribers</th>\n",
       "      <th>views</th>\n",
       "      <th>totalVideos</th>\n",
       "      <th>playlistId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BLACKPINK</td>\n",
       "      <td>92000000</td>\n",
       "      <td>33904663784</td>\n",
       "      <td>585</td>\n",
       "      <td>UUOmHUn--16B90oW2L6FRR3A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Badabun</td>\n",
       "      <td>47100000</td>\n",
       "      <td>19552977150</td>\n",
       "      <td>19503</td>\n",
       "      <td>UUYWOjHweP2V-8kGKmmAmQJQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MrBeast</td>\n",
       "      <td>207000000</td>\n",
       "      <td>36157434388</td>\n",
       "      <td>765</td>\n",
       "      <td>UUX6OQ3DkcsbYNE6H8uQQuVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BB Ki Vines</td>\n",
       "      <td>26300000</td>\n",
       "      <td>4824402860</td>\n",
       "      <td>190</td>\n",
       "      <td>UUqwUrj10mAEsqezcItqvwEw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HikakinTV</td>\n",
       "      <td>11900000</td>\n",
       "      <td>11705114156</td>\n",
       "      <td>3367</td>\n",
       "      <td>UUZf__ehlCEBPop-_sldpBUQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>167000000</td>\n",
       "      <td>170365245506</td>\n",
       "      <td>1027</td>\n",
       "      <td>UUbCmjCuTUZos6Inko4u57UQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Amit Bhadana</td>\n",
       "      <td>24500000</td>\n",
       "      <td>2428790270</td>\n",
       "      <td>106</td>\n",
       "      <td>UU_vcKmg67vjMP7ciLnSxSHQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Luisito Comunica</td>\n",
       "      <td>41400000</td>\n",
       "      <td>9048186869</td>\n",
       "      <td>1316</td>\n",
       "      <td>UUECJDeK0MNapZbpaOzxrUPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Aqua Ch. 湊あくあ</td>\n",
       "      <td>1920000</td>\n",
       "      <td>368194153</td>\n",
       "      <td>592</td>\n",
       "      <td>UU1opHUrw8rvnsadT-iGp7Cg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  channelName subscribers         views totalVideos  \\\n",
       "0                   BLACKPINK    92000000   33904663784         585   \n",
       "1                     Badabun    47100000   19552977150       19503   \n",
       "2                     MrBeast   207000000   36157434388         765   \n",
       "3                 BB Ki Vines    26300000    4824402860         190   \n",
       "4                   HikakinTV    11900000   11705114156        3367   \n",
       "5  Cocomelon - Nursery Rhymes   167000000  170365245506        1027   \n",
       "6                Amit Bhadana    24500000    2428790270         106   \n",
       "7            Luisito Comunica    41400000    9048186869        1316   \n",
       "8               Aqua Ch. 湊あくあ     1920000     368194153         592   \n",
       "\n",
       "                 playlistId  \n",
       "0  UUOmHUn--16B90oW2L6FRR3A  \n",
       "1  UUYWOjHweP2V-8kGKmmAmQJQ  \n",
       "2  UUX6OQ3DkcsbYNE6H8uQQuVA  \n",
       "3  UUqwUrj10mAEsqezcItqvwEw  \n",
       "4  UUZf__ehlCEBPop-_sldpBUQ  \n",
       "5  UUbCmjCuTUZos6Inko4u57UQ  \n",
       "6  UU_vcKmg67vjMP7ciLnSxSHQ  \n",
       "7  UUECJDeK0MNapZbpaOzxrUPA  \n",
       "8  UU1opHUrw8rvnsadT-iGp7Cg  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_channel_stats(youtube, channel_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['higkbFOl5RA',\n",
       " 'uWZ7nTKNAeM',\n",
       " 'Kj5qw7t7E8c',\n",
       " '7PwiABxmOyM',\n",
       " '5SUVOIelSBA',\n",
       " 'hZndMcOQV5M',\n",
       " 'b7kWQkGByqU',\n",
       " 'fyZRSb7t7cA',\n",
       " 'n0hxEfOn7SA',\n",
       " 'IfiFXokno5k',\n",
       " 'btee5fMyZEg',\n",
       " 'qdku8MUgG5E',\n",
       " 'S5USR-bcAro',\n",
       " 'osm3WdGQGW0',\n",
       " 'V8ufTvZ-5uk',\n",
       " 'NVCZ-pSj7X8',\n",
       " 'FkpYU0mR3EM',\n",
       " 'MXBw3gimjF8',\n",
       " '7fyOeZhUZ_s',\n",
       " '5zWg2j5WWto',\n",
       " 'tydtZ7donS8',\n",
       " 'vDD35_F1Nyg',\n",
       " 'Ie-MroA5erg',\n",
       " 'Uf8fzBU7xm8',\n",
       " 'O7rYQHBSybA',\n",
       " 'ZTl-7yhRhzw',\n",
       " '7ItUqvAqifw',\n",
       " '7a1FGNePszw',\n",
       " 'n_uu5iHX3Ro',\n",
       " 'BBTUlonM57g',\n",
       " '7pnm3YwyelA',\n",
       " 'nFCB7jlLvfs',\n",
       " 'BtAEQQg1U7Q',\n",
       " '-BnK_7jGm3Y',\n",
       " 'vE7ZA1o-3Kg',\n",
       " '5edDBloZv_A',\n",
       " 'xHgK5OwZMWI',\n",
       " 'Pxr7rp-tOJw',\n",
       " 'd3-xm0GYgbA',\n",
       " '5gwktA0qh3g',\n",
       " 'Y3okDFuXqjQ',\n",
       " 'XQR5IQxhgpQ',\n",
       " 'XNtF7KVfBtI',\n",
       " 'IpfcI5_7HVE',\n",
       " 'RTyGyLt7VGs',\n",
       " 'Duo7_lF-oaE',\n",
       " '5SHXmlHUIWU',\n",
       " 'cD7lvPVqmJU',\n",
       " 'I7M0zv5bpYc',\n",
       " '1APAs5aHeeQ',\n",
       " 'AMZeRF73PG8',\n",
       " 'Y3VaR_nxsbc',\n",
       " 'C5trBZRuKDU',\n",
       " 'PMR5RFwpBFw',\n",
       " 'y0TyQNO7Llk',\n",
       " 'XASJfeL7rik',\n",
       " 'XWnfHj5sdw0',\n",
       " 'MygTjcS5PGw',\n",
       " 'hM72Qy7bRTs',\n",
       " 'gYVFQ7SlbqU',\n",
       " 'SSLmgXoR57k',\n",
       " 'n3m_djBzRAM',\n",
       " 'spzH3Wq3Tf0',\n",
       " 'sYc-5zaPTWc',\n",
       " 'SKF2V5LzpRE',\n",
       " 'evlD3k7ZR5M',\n",
       " 'ctDgiUv7mpM',\n",
       " 'T2XzgWAM730',\n",
       " 'SyTY7-ZTens',\n",
       " 'AXp75cbAnEQ',\n",
       " 'EDKb7BVaIDE',\n",
       " 'XIs7UyTkJk0',\n",
       " 'zLvdfKj5bbE',\n",
       " 'wlIpMx-O7uU',\n",
       " 'NoWm5UaZosE',\n",
       " '0Cyd77kdLyQ',\n",
       " 'WqFCgAxBx5k',\n",
       " 'rGHg5tEHKIM',\n",
       " 'm7h5yO7muLM',\n",
       " '7BMrIoYjOgw',\n",
       " 'mgO15Eo0tk0',\n",
       " 'qbY-BQd50Xg',\n",
       " 'e3yT1GBoH5c',\n",
       " 'zFpq3eglSy0',\n",
       " 'jO7NcaWroKA',\n",
       " 'rKm7JME5mrA',\n",
       " 'vt5kZxCZnf0',\n",
       " 'VpY5ZaTh-1E',\n",
       " '0lgiwxSAW5A',\n",
       " '1hRBDFL7tmE',\n",
       " 'UUYNKAw7zEk',\n",
       " 'EpELt27kZ2s',\n",
       " 'ciMmDec7X3w',\n",
       " 'oflATuuq7KQ',\n",
       " '3gXbSrwCNFU',\n",
       " 'hnBI5OqSXWQ',\n",
       " '3IOErkBpnjc',\n",
       " 'sQNZE7lbBTo',\n",
       " 'RbDcICCxm5k',\n",
       " 'UR167r7trjo',\n",
       " 'VusYvE7FHpY',\n",
       " 'AxNGCm-7PCY',\n",
       " 'a3bwGiUan-Q',\n",
       " '01aMp7U_X8M',\n",
       " 'hmZ7DLOsMCg',\n",
       " '01-2gQuDf7g',\n",
       " 'eu7EqtVZ-Jo',\n",
       " '2_0P3C5ICWk',\n",
       " '5gLO_rNFVNg',\n",
       " 'G1NkQJ-c7Fs',\n",
       " 'GQSw111HnH0',\n",
       " 'VC2NG3euo5g',\n",
       " 'n3Z5sV0SZro',\n",
       " 'n3bDSAhlIlk',\n",
       " 'leKNYgV7HHw',\n",
       " 'Z3LgRY6O_XE',\n",
       " 'yBhRfanP5n0',\n",
       " '5Cs25xZlbXo',\n",
       " 's-Sihx3pysg',\n",
       " '3EuOzLQIvc0',\n",
       " 'mvlNjrdP5zM',\n",
       " '8C150aDG1OY',\n",
       " 'nfYNsJyjm5w',\n",
       " '-3vUmAbbb_8',\n",
       " '7NOHyrq_zXY',\n",
       " 'oS-IpPZ3nqM',\n",
       " 'ceXkzd5xGaM',\n",
       " '_n-n25bDy3o',\n",
       " 'Zb_SiV3JPFI',\n",
       " '_dCgyuQN5PM',\n",
       " 'yvwbhmqq7Ck',\n",
       " '2MH5nS55kmE',\n",
       " 'MaDl-p7lctg',\n",
       " 'uqKBS5ll0U0',\n",
       " 'ocp7ZnwYGkE',\n",
       " 'Pv0875QVCZA',\n",
       " 'mupF3_MEcoE',\n",
       " 'vNEEeyq0X40',\n",
       " 'A7FOnzh08eI',\n",
       " '2Li5jhNIRIs',\n",
       " '27QlG-5Dc1M',\n",
       " 'gDyLWG-s5Nk',\n",
       " 'GkV7hc02fpw',\n",
       " 'h5JO1E3WzDs',\n",
       " 'n5pmfvhRlFc',\n",
       " '1HqJ7DGNhrY',\n",
       " 'rObRhHRaI7w',\n",
       " 'cI8u7hLBAYU',\n",
       " '7zLKwbbzJuQ',\n",
       " 'lOurrt52Km0',\n",
       " 'wZlaRlm5Xaw',\n",
       " 'YE_Jngn7HjA',\n",
       " 'h_Q5rBzn38g',\n",
       " 'tDTLTgqKzeU',\n",
       " 'FWM_RfFR5uM',\n",
       " 'K2e3f5s15h0',\n",
       " 'Yk3YyW02RiY',\n",
       " 'M3bZ1LyDVHc',\n",
       " 'Ag7d83107oc',\n",
       " 'QPci7MpSzcY',\n",
       " 'mM1LwnRa3hE',\n",
       " 'Stc5YN7TJcc',\n",
       " '5GhjmJHiAcU',\n",
       " 'dF5DSmViTxc',\n",
       " 'fN_5r5HxMoI',\n",
       " 'eym3xxPhBfY',\n",
       " 'ESfa_Scr7RQ',\n",
       " 'HpUJYkHX3zU',\n",
       " 'J7FcVD2FGPk',\n",
       " '5iY_HswCCIE',\n",
       " 't0KjR52ea5c',\n",
       " 'z7QzJP2Ubdg',\n",
       " 'Q7phumVPcyE',\n",
       " 'Y7GRljsQFgA',\n",
       " 'FsrNyrE7Qio',\n",
       " '26f7iLLQZsA',\n",
       " 'p4qzvq_5g3I',\n",
       " 'LBkD3EcX5Wk',\n",
       " 'pIqJoJ7_PJE',\n",
       " 'lfjr7gYpiKo',\n",
       " '7MNuFXWLQE0',\n",
       " 'Tpwq7vb7Z7U',\n",
       " 'wD7sC3WmasI',\n",
       " 'w3rzi3uhjUs',\n",
       " 'K2dylD77naE',\n",
       " '7Kzmy8VEGsM',\n",
       " '57sVMfxu6Y8',\n",
       " '3ikyGmdpaKo',\n",
       " 'Bd_HWQm3oYA',\n",
       " 'cXMvP-0Gy70',\n",
       " '0al5QxFEu0s',\n",
       " '32AqkNgBQuw',\n",
       " 'KqV30yXY__k',\n",
       " '32A3ko3ofWM',\n",
       " '3AXwbT0IXXg',\n",
       " 'M7ANIqnh3FE',\n",
       " 'G57lCMbVTps',\n",
       " 'Yfcpf8n3Wak',\n",
       " 'Nw-Y55gMssU',\n",
       " 'fb_2ox7IMxo',\n",
       " 't3OQRgwdS2I',\n",
       " 'grMw1J55OIc',\n",
       " 'Y5u32KU2B-8',\n",
       " 'K1dNiWImAjc',\n",
       " '3Z1o2BXdreI',\n",
       " 'U7E_IjZfWOI',\n",
       " 'XC98RrMoDv8',\n",
       " 'bqldz5EVLbU',\n",
       " 'rBw7z1ZFfWw',\n",
       " 'i-0_1q__GI8',\n",
       " 'fx5mBa7jBas',\n",
       " 'V03NVHl1L_w',\n",
       " '1gU0zRl7Lc8',\n",
       " 'g1TDK7EXGBk',\n",
       " 'Zzw7Ye5dLls',\n",
       " '_yvUNPtf5Ms',\n",
       " 'rb3mHBFToOA',\n",
       " '0xq_5xIr-1c',\n",
       " '78Xd7u1xarM',\n",
       " '0gavo7Skukc',\n",
       " 'BX8hNBKaN8g',\n",
       " 'mV7za33cRm0',\n",
       " 'YKigLxxJ5gQ',\n",
       " 'z87JwUKQGwc',\n",
       " 'SE5FnotDQJM',\n",
       " 'Q5IwCLl80dU',\n",
       " 'M5LLqvr0CKs',\n",
       " 'SCt0e7-vcsE',\n",
       " 'ZaKn5wM7dz8',\n",
       " 'fgUsr7uwcNM',\n",
       " '5XlNIEtUY1M',\n",
       " 'qZ32V-EAVBg',\n",
       " 'evUnbx7XnPc',\n",
       " 'oQxTsGwos70',\n",
       " 'KnTaHoFr7-s',\n",
       " 'mrkwFxCnW58',\n",
       " 'u5YBxlgciQ0',\n",
       " '5MIKtJFq37Y',\n",
       " 'QWzkjPD85AU',\n",
       " 'R7_5mBAOG6A',\n",
       " '_u4UyV2v1H0',\n",
       " '-1CFRIb7HOI',\n",
       " 'XaFVb3FinMo',\n",
       " 'cj5RFZTa2DM',\n",
       " 'NIlIxnKnfYY',\n",
       " 'ei5S3WaVZhI',\n",
       " '5YxNtnE0uns',\n",
       " 'TA7I2VCRidE',\n",
       " 'Yfw1eoe7oBo',\n",
       " 'llq7mlrMMfs',\n",
       " 'tsJwjEAh7wk',\n",
       " 'zbt_l3WzJUU',\n",
       " '5jCUUZqjaqk',\n",
       " 'ga7rl7CaZss',\n",
       " 'BPUuPd5HNDA',\n",
       " 'kSQFn7qDPI0',\n",
       " '8MqpMjBU3Y8',\n",
       " '2IBHT5vKFgo',\n",
       " 'rUND1xw13oY',\n",
       " 'i3defgLmFuY',\n",
       " 'bk5XSFfgeQA',\n",
       " '5mEwdvIOJqs',\n",
       " 'v1UiR5nrxmM',\n",
       " 'Mu3rXhuTNQI',\n",
       " 'pvjcT57PIaU',\n",
       " 'AvqeEl5_leo',\n",
       " 'H2FXF0Mx7MA',\n",
       " '0k0GR7yhL3s',\n",
       " 'iGVx5Ao5pNc',\n",
       " 'IrE5m30nSCo',\n",
       " 'x8Y-oOJ62vc',\n",
       " '01SCV7y1rpg',\n",
       " '3Ji8TLeDYd0',\n",
       " 'F7Pky-PKQaM',\n",
       " 'OD7wsfblIAU',\n",
       " 'RJKo3bDCBGo',\n",
       " '5FalwD0yHb0',\n",
       " 'UVmswmd5SoM',\n",
       " 'QPY1bsx-fdQ',\n",
       " '7Ksax2WGNnQ',\n",
       " 'qhxw80J7drE',\n",
       " 'qskqb3JGgVE',\n",
       " 'Frwvwx70jG8',\n",
       " 'jAH3MEsh3aU',\n",
       " '1knsQZLeh7U',\n",
       " 'JOsDw3tSCDQ',\n",
       " 'C7xA-ULj_mI',\n",
       " 's28BDiWzw7s',\n",
       " 'y0hYPF7dETA',\n",
       " 'IZrC78PBzso',\n",
       " '3YCVgypvgZs',\n",
       " '5jpnnIKR0xw',\n",
       " '8sEp-nS7lD8',\n",
       " '-8Th72T7lxk',\n",
       " '7SVQu0cYEH0',\n",
       " 'ZYc75M_W0iY',\n",
       " '7SAeLWygV50',\n",
       " 'aRue7HhWScc',\n",
       " 'O5-EnGZOEYs',\n",
       " 'Sz-ZCB7ioEY',\n",
       " 'P0hPJ1_x52A',\n",
       " 'n5hlOPmFgfQ',\n",
       " '33QjmoNw_Ko',\n",
       " 'Bmza5g03zzQ',\n",
       " 'MiYr5MJg1uw',\n",
       " 'OwM7HFneBzE',\n",
       " 'btVMyM_3IUM',\n",
       " '5WRgIGc1oCA',\n",
       " 'gh0KeeIz7hU',\n",
       " '7nvsmUFabC0',\n",
       " '5BIpHw0XoQw',\n",
       " 'UqzO5-aLwfk',\n",
       " 'kix3FgZcv7w',\n",
       " 'Bw1RBte7q58',\n",
       " 'adg_iRSL7VY',\n",
       " 'lMoSL5By7Zk',\n",
       " '5__-Sd_psQI',\n",
       " 'XY5OHEHesYo',\n",
       " '-7iKs5QlJFo',\n",
       " '5fvqfhns5nk',\n",
       " 'ic3_ozZa1ic',\n",
       " '7u5MrZssBYc',\n",
       " 'SAd1FR5NTus',\n",
       " 'Fbpyr3KTVZ8',\n",
       " 'qjQP7xtuwVY',\n",
       " 'pZwkVAuCn5c',\n",
       " 'zX0YZg7Tyz0',\n",
       " 'v71pnWNXmfk',\n",
       " 'j3UGALdig7w',\n",
       " 'c7xPpC2iOXI',\n",
       " '7JD3LNSKxCs',\n",
       " '77kA5qBJHJg',\n",
       " 'j1bZJPlf1JI',\n",
       " 'tmVN0Umgg3Q',\n",
       " 'G7bANXXBx_8',\n",
       " 'Nxwh7Mllauo',\n",
       " 'r1lFt_HNdPI',\n",
       " 'fhQTw5ltGGg',\n",
       " 'fAaUrN7TXxw',\n",
       " 'M7SwWmJWDfc',\n",
       " 'vdRG7XgitBU',\n",
       " 'gj_NKBUp8Hk',\n",
       " 'bF5xuJVdXy0',\n",
       " 'u55tQQmBh7M',\n",
       " 'V4aTYqa9wlE',\n",
       " 'lgjYO1V5h3A',\n",
       " '7yhhZ3fyaIs',\n",
       " 'fYcPN7cDIjk',\n",
       " 'fMDh7lsHYcc',\n",
       " 'BXX_BV7RiNc',\n",
       " 'Fdr5Qhmh1LI',\n",
       " 'lmG7mwzTmQA',\n",
       " 'ES5qki-a5dc',\n",
       " 'zqUG7LBHJus',\n",
       " 'v7fqWQ0BPfw',\n",
       " 'uE3Fv8bHpos',\n",
       " 'k7EwuFkDfxI',\n",
       " '_HmZ7TeMNBo',\n",
       " 'ScyY7IDQv5g',\n",
       " 'lhVyvI17KqU',\n",
       " '7RoDwuNeMjc',\n",
       " 'bGMb0wZ5VdY',\n",
       " 'H5yJ7Cetp7w',\n",
       " 'ZoO32mzlFxU',\n",
       " 'G30tKK-MTQg',\n",
       " '70yMnV-l_-Y',\n",
       " 'Obk0kGQo5rw',\n",
       " '3CqsjQxaT3s',\n",
       " 'kzjbV7dxm7c',\n",
       " '5TDTZYYSwas',\n",
       " 'rvTgnh8st78',\n",
       " '3NZno885v0A',\n",
       " 'jKc7VddlTy0',\n",
       " 'Gvzc56cBlBQ',\n",
       " 'A5TRJRN1LLw',\n",
       " 'a5_GrFrP2zg',\n",
       " 'BYKhWOE3Vvk',\n",
       " 'OG36QXZnL7g',\n",
       " '5RAknPZ2J1A',\n",
       " 'dAy55dy37bk',\n",
       " 'yoZcU7hpTHc',\n",
       " 'w1Mng7T1jxo',\n",
       " 'TS3gDtSwbzw',\n",
       " 'bQHIOcx7l3s',\n",
       " 'ZRVwPbM_shg',\n",
       " 'y0s5qiSxq08',\n",
       " '1cFHFQRJkoc',\n",
       " 'zn5IZDVRhKE',\n",
       " 'fB5LFgVOl08',\n",
       " 'aVGNBKT5UN0',\n",
       " 'xDS78--7zeg',\n",
       " '7p-OYEQaoaU',\n",
       " 'PAs5AFsb2mU',\n",
       " 'ogCdR7TSgoc',\n",
       " 'GiogS5-k5mw',\n",
       " 'DOAAa7jaVpk',\n",
       " '8V31s-Ez_to',\n",
       " 'r_J7pjR0Mdk',\n",
       " '0ushxXt51Vo',\n",
       " 'TW8xxe7_BTE',\n",
       " 'NihpPvvVt5k',\n",
       " 'mVSvZj5Hnh0',\n",
       " '2-p5N-m2_aM',\n",
       " '3MjD1-eN_dM',\n",
       " 'UBQn7we7BT0',\n",
       " 'LRD_j5dbrYE',\n",
       " 'YIucyaJZ7vg',\n",
       " 'vzZAC7f26aA',\n",
       " 'uD31mkvGGck',\n",
       " 'O7I1FhytIQ8',\n",
       " '7ORG7nOsDYk',\n",
       " 'P3n_Y-ICUVg',\n",
       " 'oAxqcWxCy7A',\n",
       " '-cot3EB7Ehw',\n",
       " '8OGG-kuO5Kg',\n",
       " '0fB3RVdAaVs',\n",
       " '9VBB2Bt6OVg',\n",
       " 'TLi7IC7OaBc',\n",
       " 'rvfbO5ANbzw',\n",
       " 'iqnLkzoli3U',\n",
       " 'w_bShKn_x3I',\n",
       " 'QsxCWK77HMU',\n",
       " 'A3pUUJD1F2Y',\n",
       " 'tU7OSXXNiZc',\n",
       " 'jrAMeKbi_50',\n",
       " 'LkkqkTbon5E',\n",
       " 'ImdUXJI75nc',\n",
       " 'T5mW8em1Zos',\n",
       " 'lqOk-7nbcGw',\n",
       " '56g_jt7wXd8',\n",
       " 'N7JJ0S3Gd7g',\n",
       " 'Xg5tLUGgJTY',\n",
       " 'wqFyZrg37ag',\n",
       " 'Jizn7_5uDOs',\n",
       " 'w-o73uuIREU',\n",
       " 'Hnc3W7HvRGI',\n",
       " 'vXTZrxF3vZQ',\n",
       " 'ZjS3EB8CHEc',\n",
       " 'p35Th7d3TkE',\n",
       " 'M5hR3LSM7Fs',\n",
       " 'Z3iLe07cUu8',\n",
       " 'Doq-bx5sK7E',\n",
       " 'g7-2LMzeuVY',\n",
       " 'Xb7BR2WRw3s',\n",
       " 'azlZwmdT7ic',\n",
       " 'L7IgfTIuJo0',\n",
       " '3gtiOlhMAmc',\n",
       " 'kxWRSMD7Hao',\n",
       " 'S11TXF3H-ds',\n",
       " 'w1n7PxqWsNU',\n",
       " 'wiRK7kUUqnc',\n",
       " 'kFvcBDj7IDI',\n",
       " 'kLHc0c3Yv7U',\n",
       " 'N3fN-DsRjVg',\n",
       " '0Alf5_sY7Lg',\n",
       " 'uoHI_yB3Vtg',\n",
       " 'mlpxl7UoRAc',\n",
       " '5f0qSBrDUBQ',\n",
       " 'LhRAsT5OdfY',\n",
       " '7AVQTmmQ7sU',\n",
       " '7TFm3U-gGp8',\n",
       " 'RqzOUS3-ZUE',\n",
       " 'LyAWYrfeVjY',\n",
       " 'MMJw7pbS2Ec',\n",
       " 'Y2lZH3hG-7A',\n",
       " 'J3SfbVrZXsY',\n",
       " 'FUb-lE0tQC4',\n",
       " 'znE7BGX80YI',\n",
       " 'iz51J3vcCyo',\n",
       " 'xkvDZDx7Db8',\n",
       " 'wmb5PzjQLto',\n",
       " 'QmVrCZF3Tog',\n",
       " '3YZRpSDj5Kw',\n",
       " 'bjvAzTiyS7U',\n",
       " 'QgCyr_Z1-5w',\n",
       " 'eH7AbrY5X_c',\n",
       " 'QT1bY3zICek',\n",
       " 'PuI0DZAxgYw',\n",
       " 'UvOVskLQB3M',\n",
       " 'rSlEgEI7SEo',\n",
       " 'kj0F3stJb8I',\n",
       " 'ceFbZy_H3Lw',\n",
       " 'qPj53FquCWc',\n",
       " 'IPNmrQEmQ5M',\n",
       " 'h5ljEC2L-SI',\n",
       " 'kJDBQAAP7mY',\n",
       " 'SYS7iH-Ix3A',\n",
       " 'goWjS5h--tM',\n",
       " '7QHjIk0fsfs',\n",
       " 'BG3lrb5EZVk',\n",
       " '7QsY5FNVK5M',\n",
       " '8rUgR3PeV7w',\n",
       " 'c5wzDadfq00',\n",
       " 'ZxjaW7zGTbA',\n",
       " 'ROnl78oPFxo',\n",
       " 'B7nBsxInPJA',\n",
       " 'sUPd-NWaM7o',\n",
       " '0PuxgdQqU5I',\n",
       " 'Uz5dH_elu_I',\n",
       " 'SjLA7VOnBD0',\n",
       " 'tVHc5ApM2JA',\n",
       " '7zWv5gH1OfU',\n",
       " 'a5vWGA_U18g',\n",
       " '3FQWxeKHxcA',\n",
       " 'Py7yGtU_Xqg',\n",
       " 'R-7HLwojuQI',\n",
       " 'mhQJ7fOZRpc',\n",
       " 'NCi7TuAsZWg',\n",
       " '3qCcZ_WrHPs',\n",
       " 'RiniRiqb7w0',\n",
       " 'mDlzYe3KFvk',\n",
       " 'Jv37oYc_NT8',\n",
       " 'gHq7ikYmH2s',\n",
       " '3BhFXBTcbjY',\n",
       " 'V3rDBZYSIxA',\n",
       " 'krrsY0LJZ50',\n",
       " 'W1cHrRv_D7Y',\n",
       " 'b36c_rVUBqs',\n",
       " 'pIdC58OPAqY',\n",
       " 'S-eI5E5B0zQ',\n",
       " 'Z2587sOY77s',\n",
       " 'ZIBP7HWto20',\n",
       " 'bfhPP7paHcg',\n",
       " '1U7_uvq0YXI',\n",
       " 'rqTUI1QyB7o',\n",
       " 'uB_f2c7fE1I',\n",
       " 'x2l_r27XKuk',\n",
       " 'llU68N88aYM',\n",
       " 'MBoPqhEfYmU',\n",
       " 'WBGx7jan1uU',\n",
       " 'BVs5erOgBpE',\n",
       " 'jdCbnRZh5jw',\n",
       " 'xIGvff7JqzQ',\n",
       " 'WQe3N_MrBMQ',\n",
       " '0RhcdLFS3lY',\n",
       " 'AdymyAcY1nQ',\n",
       " 'SXnkZNZTCzk',\n",
       " '7xlx73tB8AA',\n",
       " 'rKsmSrcMJ7E',\n",
       " 'BN3VJb2H18I',\n",
       " 'SZ7ChdFOFKA',\n",
       " 'MnKNzylBdQk',\n",
       " '2yPW7OepjqI',\n",
       " 'UpR0ZlUm2B8',\n",
       " 'ji0E51HkhUc',\n",
       " 'nOxSbgaTORE',\n",
       " '31zYbnmHVoE',\n",
       " 'O7vDZZGRjuw',\n",
       " 'T-7KA8Q1CVY',\n",
       " 'VRJ3vuaX5Bw',\n",
       " 'TSzVbgUk7Jo',\n",
       " 'XFhGDrCzQ5M',\n",
       " 'QhZ7jf5qrj8',\n",
       " 'dxbRSn1Zixg',\n",
       " 'w0ymkCJo3Cc',\n",
       " '7-XkFHs0mVg',\n",
       " 'RPbyxu7Gl8A',\n",
       " 'mTE-MzneZBo',\n",
       " 'WBFnsUi2hUY',\n",
       " 'sDhHaNK2-no',\n",
       " 'DGWutiDf5Bs',\n",
       " 'BbbSULr3kBs',\n",
       " 'o2bXOyyGe7c',\n",
       " 'MSDgcF_77eQ',\n",
       " 'PhGUKP7dY1w',\n",
       " '3zdPyHTDR3M',\n",
       " 'YzrH-GaZHwo',\n",
       " 'Vg2VYd7LxGk',\n",
       " 'xSRTII7m7rk',\n",
       " 'xfC7gsONmaE',\n",
       " 'wy5ydiJhpaU',\n",
       " 'jSwaR7dXTFY',\n",
       " 'BOeesPTK5Tc',\n",
       " 'DKhVBq-n3NQ',\n",
       " 'hGKeGTExoMc',\n",
       " 'dPmFtUAueQM',\n",
       " 'gTMrS7bxIpg',\n",
       " 'nd-cqcaWLzQ',\n",
       " 'yh5dZubTb10',\n",
       " '2PZLPzcDr5k',\n",
       " 'duM0erJQKKA',\n",
       " 'HxKEgjUBDAs',\n",
       " 'vQpiw_FsXWI',\n",
       " 'vXbLJqbyPqg',\n",
       " 'iMVzTtiizlw',\n",
       " 'scGpw7fkwZM',\n",
       " 'pnDBDp_pufg',\n",
       " 'idjpFCpkItA',\n",
       " 'mvWrrx2a5xw',\n",
       " 'o3NyDMsW1Lc',\n",
       " '1fabmpg1O2w',\n",
       " 'XXDofNaZUaM',\n",
       " 'cAkA25csaJM',\n",
       " '1WJYAHbrpGA',\n",
       " 'Zz-ltAp-sHc',\n",
       " 'h2AkC2ddtas',\n",
       " 'ZYb0XmMioVg',\n",
       " '7yB5triHZJM',\n",
       " '1Jgfm3YRhqc',\n",
       " '5AdaUEZSko8',\n",
       " '8urynrWxkzk',\n",
       " 'TvRVcN-fJLE',\n",
       " '30obJXlk2MA',\n",
       " 'Yuc_GcXjxjw',\n",
       " 'U1iJyT1RzXU',\n",
       " 'bMKR_iilIH0',\n",
       " 'Xo-rmc-8hGI',\n",
       " 'XBBCPBxSzvI',\n",
       " 'z1nfF1bj_WQ',\n",
       " 'pCUYc5S1WPA',\n",
       " 'qhqPGnGg-IU',\n",
       " 'S7ZKQqzvPwM',\n",
       " 'xqKYvXceoMQ',\n",
       " 'FqJW5gUt_wA',\n",
       " 'FzD7QqQlHhg',\n",
       " '8p0BUMi2eiw',\n",
       " 'smXl8etS2_I',\n",
       " '8wKwSQhFUAs',\n",
       " 'Fa21h-hFg7E',\n",
       " 'kwXfr8s_Yhs',\n",
       " 'Uzfvqs3jcRk',\n",
       " 'Hx-SQ_aCuQ8',\n",
       " 'pT2MqDLhBWg',\n",
       " 'kaw2bpjkuDw',\n",
       " 'nW2Jk6D7FLA',\n",
       " 'PFCXDYCmZE8',\n",
       " 'b0uGveXlmCM',\n",
       " 'ANrv0biUAds',\n",
       " 'I23Crm6NDwg',\n",
       " 'QErIRaEy-oQ',\n",
       " 'MUTqxPMkeV8',\n",
       " 'xa_F3JRDS9s',\n",
       " 'Nm7WvntgkKw',\n",
       " 'QP32qgrmMNc',\n",
       " 'LEkyLCxGRXo',\n",
       " 'hrp8s5e7kQw',\n",
       " 'gwCbBGseFx0',\n",
       " '-SHwOOXRue8',\n",
       " 'gAJ_p0BB7KM',\n",
       " '8-eQ-iSsEjE',\n",
       " 'Tn0FHDzIQzU',\n",
       " 'yapZf_HXddw',\n",
       " 'X-Syv5upkKQ',\n",
       " 'lIsMhMTCyoo',\n",
       " 'VDQuhN1plxo',\n",
       " 'HBDLD-XSpSc',\n",
       " 'tGOBvtKXHQ0',\n",
       " '5fap6EXvVpc',\n",
       " 'b3m_XRgX1V8',\n",
       " 'kbTbTzE1cvQ',\n",
       " 'XXrQiq15FkU',\n",
       " 'zPHERhDPIJM',\n",
       " 'KAfULYulCJM',\n",
       " 'RlVB-Q8eLHk',\n",
       " 'b0k-fdXk28c',\n",
       " 'DEuruU-doQM',\n",
       " 'cEdeotYQMCM',\n",
       " 'ofCsslfc-So',\n",
       " 'rzziAEhCJhI',\n",
       " 'YybcDn5BJAg',\n",
       " 'o_lfRo1_52c',\n",
       " 'Qq0_H0Zx51E',\n",
       " 'VRovUa1ioOw',\n",
       " 'lWEb0E1LmjE',\n",
       " 'ThfRyRj_1KI',\n",
       " 'V27iErwCs2E',\n",
       " 'iI7Nx3nXrdk',\n",
       " 'YvCQ1UZeHnA',\n",
       " 'E0jUYAfFHIM',\n",
       " 'D5gd_0dhQ00',\n",
       " 'VbHHk-Qw_nw',\n",
       " '55dkC87QFU8',\n",
       " 'pqQDCOWtcZY',\n",
       " 'g8c0psnuDc8',\n",
       " 'rPTKNk1vU5w',\n",
       " 'WtYprWCWaVA',\n",
       " '1LaaEldNh0Q',\n",
       " 'Np0xscEb3Dw',\n",
       " 'W5r3Y2TPZHo',\n",
       " 'anWsme7SRSs',\n",
       " 'jGbevSbPwOI',\n",
       " '2QaV5nZXAtg',\n",
       " 'aqagmL1HDIE',\n",
       " 'XLFWrl3YJvM',\n",
       " 'osQDJ_0pINo',\n",
       " 'NJamEdNA0Oo',\n",
       " 'UyPwDHGlfWg',\n",
       " 'W-viLbh55hU',\n",
       " 'AnR27zAEMz8',\n",
       " 'FzkRv2WG1mI',\n",
       " '1iEVwFKdLwk',\n",
       " 'QEjKKOvUGHo',\n",
       " 'jUGnmLlUh-0',\n",
       " 'fdk7YXVtHzs',\n",
       " 'JsStwsYSSXk',\n",
       " '5HMvkrsp_NA',\n",
       " 'NPdfEazxWds',\n",
       " 'zRKSiN-XuyU',\n",
       " 'VGdQBwQLOjA',\n",
       " 'dp5LL7aLoRQ',\n",
       " 'sse3HJeSnDY',\n",
       " 'SChnk5xmUsY',\n",
       " 'lJAhatjFSiQ',\n",
       " 'aBWRYpXasVA',\n",
       " 'QQcCbXVfBko',\n",
       " 'SfCvmHDX3S0',\n",
       " 'WJt-TjBBKQs',\n",
       " 'SuwfgKC-DCQ',\n",
       " 'JZ0zYQDzl2M',\n",
       " 'YWXIEayjbKo',\n",
       " 'woWZUn-rkOI',\n",
       " 'zhbR1tokcbU',\n",
       " 'Bh_QOGWDPlY',\n",
       " 'v7GSyZ3m8mU',\n",
       " 'yc5jWYLl2Ew',\n",
       " 'Xy2x8LqCD-s',\n",
       " 'K2JLxnsdsFM',\n",
       " 'QwWprUHJCS0',\n",
       " 'pGyZNE0b2g0',\n",
       " '2aYtXEGY_7U',\n",
       " 'IgmMJihw6vo',\n",
       " 'DwtkATJTNUI',\n",
       " 'rdglI0Skkts',\n",
       " 'jXyGqrxwhxw',\n",
       " 'BQGfIGsb7Yg',\n",
       " 'QSdgWGLVSyI',\n",
       " 'dN07VPzK3eQ',\n",
       " 'bTB5SbSPXzc',\n",
       " 'rvLTecJN7IY',\n",
       " 'P5X1yb3c1Iw',\n",
       " 'lzaY_BMmjPU',\n",
       " 'MQfV81zMPBY',\n",
       " 'MgFQfydhkZk',\n",
       " 'byYzA1ZGTo0',\n",
       " '3RtGaewzYiA',\n",
       " 'hfWa5dnHuEY',\n",
       " 'lRDNiQr5Hps',\n",
       " 'JtwY3OozzLY',\n",
       " 'RO7yoetoevo',\n",
       " 'u0zraWAkeZ0',\n",
       " 'YXFjvoU2APA',\n",
       " '73WbbZ-d42k',\n",
       " '2zZsJM8Z60s',\n",
       " 'OkNcKB7pRtc',\n",
       " 'nox0ydY25KE',\n",
       " 'gkxGecLiBrk',\n",
       " '07Qtivl6jII',\n",
       " 'GM3SIBr7NvI',\n",
       " 'C3ywJSYG7xU',\n",
       " 'p7oZ7lKnr78',\n",
       " 'cWRF71VBotM',\n",
       " 'zQt7KgCQaS0',\n",
       " 'tX5UNUzxIG8',\n",
       " 'eZ2taWMglsY',\n",
       " 'UVkTy7Fxiu0',\n",
       " 'mmy5YtL0vq0',\n",
       " 'r_b2SD1zerk',\n",
       " '-E4_0mnfcOM',\n",
       " 'ZqWNFZyIerY',\n",
       " 'qyjAztPCuZU',\n",
       " 'hL7IfeSv3Xo',\n",
       " 'qJ2kz2GuMLQ',\n",
       " 'g3aObIPi0gU',\n",
       " 'VGbMRZM5bfo',\n",
       " 'nU3CSnOUQpo',\n",
       " 'cP84Fhr2sH0',\n",
       " '2yUCIU1qvPw',\n",
       " '5Y1D4SRdxy8',\n",
       " 'Yo7iD3HPERU',\n",
       " 'utuDcOaPRi0',\n",
       " '_aB9hfM3WyE',\n",
       " 'uDS-RsRz0BE',\n",
       " 'sytZUTYwUbg',\n",
       " 'VgAmLMOjl60',\n",
       " 'r0phk5uuiKE',\n",
       " 'ens96m3A18U',\n",
       " 'nj2_HiN-pig',\n",
       " 'P-EhNhG-2Qs',\n",
       " 'n07zxQE2cOM',\n",
       " '3CvXjPLtDrA',\n",
       " 'zW4HJkuFFtc',\n",
       " 'VY0EXQqSeRc',\n",
       " 'MgeD8MB6fyg',\n",
       " 'otuF7G5Jyww',\n",
       " '_vleyqsv5mU',\n",
       " 'gDqtZf5uOfM',\n",
       " 'Tu9F_rHxgHQ',\n",
       " '_fxIVudzl2o',\n",
       " 'QfNGNApzFxw',\n",
       " 'y6PGWPp3pA0',\n",
       " '_SzgMGtAvpk',\n",
       " '9KdQXFDcHQk',\n",
       " 'EzuaomOXyMQ',\n",
       " 'FBpSRByD0NE',\n",
       " '_fJNAf6_4NU',\n",
       " '8qV9Hy0C5zk',\n",
       " '_u0QF2igT-k',\n",
       " 'VYASWTVdo9A',\n",
       " 'ql9RAWINH98',\n",
       " 'fy6Ad6sFwyU',\n",
       " 'dix50t3IFjY',\n",
       " 'nJTx07MyB8g',\n",
       " 'xouV5kwEDaE',\n",
       " 'MtGDAqVDUaE',\n",
       " '15AIGmEItow',\n",
       " 'gb8B2Sv2PPw',\n",
       " 'Edd65bdIbfM',\n",
       " 'KMac308NLoc',\n",
       " 'HYK91P2NeIA',\n",
       " '6ykkOuy5cn4',\n",
       " 'QIRATWti9wE',\n",
       " 'LjfSUUIqP6Q',\n",
       " 'zFLb7FJB9i8',\n",
       " 'GXbZA4I0QIg',\n",
       " '2f4jkR6ESOo',\n",
       " 'QQPTw8fYsu8',\n",
       " 'ZlqB0oY_YuE',\n",
       " 'B5rf6CmwPKM',\n",
       " '-1hH9NJxvdE',\n",
       " 'WPUcPHztTmU',\n",
       " 'Nh9VKYk_TlI',\n",
       " 'A48hAjywfgU',\n",
       " '6qNQWGDg_Y8',\n",
       " 'fO_1fNo-vik',\n",
       " '8RzgOK7iBdA',\n",
       " '4AaIFfqAbLE',\n",
       " '5SP0VTbnMfk',\n",
       " 'Hw_LtZoav7A',\n",
       " '1FxFw9TRS0k',\n",
       " 'h-7ySacMrR8',\n",
       " 'ETcvVM7EZA4',\n",
       " 'xmlQX4Gcl7Q',\n",
       " 'eeGSVZNrvZI',\n",
       " 'jfBNWAGJh5c',\n",
       " '20vunG-wXTY',\n",
       " 'XfJopmwPvxQ',\n",
       " '6WLk4gLQ7UM',\n",
       " 'auIiInoxoSA',\n",
       " 'Le26fxJfTVg',\n",
       " 'Q8d8QC364ps',\n",
       " '5zJEXmjvRTA',\n",
       " 'CK2LvfWwuhg',\n",
       " 'iAYPE9dp1TY',\n",
       " '9V_8Nlzjl90',\n",
       " 'Yn57JWZN_vI',\n",
       " 'eINvp2O0qf4',\n",
       " '06EvL-Tth9g',\n",
       " 'Zk6g4HCejCw',\n",
       " 'J7i1ul4cLuc',\n",
       " 'AzL8eXErKdo',\n",
       " 'OMvHHTGaL-g',\n",
       " 'fgHmbBjgQEs',\n",
       " 'gCHKoyOMB0Q',\n",
       " 'M--_UJpApDQ',\n",
       " 'jkoNyawuSBY',\n",
       " 'FzrARCqYCxo',\n",
       " 'X-gq6vtyqrs',\n",
       " 'DIJyO53feQI',\n",
       " 'he1u8t696w8',\n",
       " '3ihBVFEY8Yw',\n",
       " 'bC8uGmOTVh4',\n",
       " '4b7TxHWswEw',\n",
       " 'bWVJEdUHakA',\n",
       " 'C3ep5F3t9ck',\n",
       " '8eZK9xAtHIk',\n",
       " 'NFIEHVDseDs',\n",
       " '5r1_QY-_OfA',\n",
       " 't-svehMWt4c',\n",
       " 'nNJTveJyaFA',\n",
       " 'IykZWDrE-RM',\n",
       " '2CfI2RuqpBQ',\n",
       " 'W8boP7S4aO4',\n",
       " 'ZoUctuNU-us',\n",
       " 'sQFQPH5IL2Y',\n",
       " '2eR7agyOsyQ',\n",
       " 'BC3XMn_wnEs',\n",
       " 'oygw53aNk9I',\n",
       " 'w_BzvTFfGzU',\n",
       " 'R63rHZbBdqs',\n",
       " 'D4NHaZ2S0AY',\n",
       " '2DksbqXN-vo',\n",
       " 'pI-Eg2YUGAY',\n",
       " 'd0BBcTGeITw',\n",
       " 'Ij_kEfyaDtw',\n",
       " 'f1C4n8Y6rDU',\n",
       " 'f8hiPCZFe_k',\n",
       " 'c8gRNhbJjyQ',\n",
       " 'hCIqTp0FaN8',\n",
       " '00780KJVvek',\n",
       " '2KYfH8Qb4DE',\n",
       " 'dITj2yI1ez4',\n",
       " 'FLvSdJv1MlI',\n",
       " 'fG7eCt26Vrk',\n",
       " 'mUjtlhoFqs4',\n",
       " 'RfbAYeX4Wcw',\n",
       " 'ETAbAOo6IXA',\n",
       " 'taV-Cag7x-Y',\n",
       " 'Smn5bZZLNwE',\n",
       " '78y5jcV1Dmg',\n",
       " 'G-W3hlT_Pq4',\n",
       " '2-Am8llw87c',\n",
       " '1s_29igEqcs',\n",
       " 'YLo9K5lD5bs',\n",
       " 'OSuNMpjvgh8',\n",
       " 'UUUTH7j-D58',\n",
       " 'Ct7uspWZTUE',\n",
       " 'Vk7s25N1lQM',\n",
       " 'yVeSCcKY5lQ',\n",
       " 'R7V5d94XkGQ',\n",
       " '2R9_bkcWNd4',\n",
       " 'EU8S-zxS9PI',\n",
       " '5wnfkIfw0jE',\n",
       " '-6duBsde_XM',\n",
       " 'SFYsgddkQ34',\n",
       " 'pxTcV3B1sDw',\n",
       " 'HrJr2MRno5s',\n",
       " 'Cvj4OxZQ78I',\n",
       " 'hVAvXoYhkvw',\n",
       " '6DOxJ8OGyjM',\n",
       " 'KHTexo5G5yE',\n",
       " 'HaUvkAXPrzA',\n",
       " '_ZiZQboSXWU',\n",
       " 'OoJ9Elysi9M',\n",
       " 'sXp3DfcuJps',\n",
       " 'N69XEH1h1VY',\n",
       " 'O0wSi-Pawhg',\n",
       " 'TTR4qjrUo-o',\n",
       " 'mVJLF4tYIKE',\n",
       " '8ca5lMeva-U',\n",
       " 'rJ_EuCXKx6U',\n",
       " 'MhDBpqCyPEA',\n",
       " 'w_Yard3Xf8U',\n",
       " 'HCq2g_PQfP8',\n",
       " 't8ZamIx7fBM',\n",
       " 'Md6-jnygdj4',\n",
       " 'Yyc7OLN6mm8',\n",
       " 'iiTP6Qc_4sQ',\n",
       " '-5PC8n5uk9Y',\n",
       " 'le7XUFQ2mi8',\n",
       " 'haWsuUL4mGQ',\n",
       " '9ePCkAXXTtI',\n",
       " 'CLfB2JtvKT0',\n",
       " 'CV1biiM4jKI',\n",
       " 'BXE0r_ni99w',\n",
       " '4mQ8pKTBbmA',\n",
       " 'J4UmKGc-Clk',\n",
       " 'JgcxZPoe2_I',\n",
       " 'f0uHcPBS1aw',\n",
       " '3gJ81huC9ho',\n",
       " '8kJ2BecFNow',\n",
       " 'LrxsE-tbR48',\n",
       " '2cAJBpQu39s',\n",
       " 'pwn8Ee9oFm4',\n",
       " 'zl5qZ4pBgVk',\n",
       " 'TJoGgMPxE0k',\n",
       " 'iv5VzSY3NHc',\n",
       " '6oXvxSPKets',\n",
       " 'yQPWggK5J6o',\n",
       " 'YdyE2PQh3D4',\n",
       " 'Cf11X6Z9dcY',\n",
       " 'jsmUneLpays',\n",
       " '0MAczNS-N14',\n",
       " 'pvVYE7lEjDs',\n",
       " 'geiq6kpJ2gI',\n",
       " 'WeMiCj1AW2E',\n",
       " 'JDno3uvv3CA',\n",
       " 'vcA095WbnNI',\n",
       " '0gD-Bc4xdDE',\n",
       " 'TTxdyyHqiAk',\n",
       " 'G5qSTJLj0DA',\n",
       " 'tScZQ95AeIs',\n",
       " '_7H2MZcOdEc',\n",
       " '4yFLn2KwBOw',\n",
       " '5rVcO7RCaus',\n",
       " 'ga87tMU0nOI',\n",
       " 'w_kC_AT9QAg',\n",
       " 'GZwjEGSGE-U',\n",
       " 'SgmTRWYLw4o',\n",
       " 'OJA-JbzvRxw',\n",
       " '85uASNcQEKQ',\n",
       " 'XM8DazQI1ns',\n",
       " 'k0CacSrwdsM',\n",
       " 'D6pN-w4XclY',\n",
       " 'omoxqb28zPs',\n",
       " 'wIQgh6zeKCQ',\n",
       " 'dbKO5QVWclo',\n",
       " 'ernDAfoD-o0',\n",
       " '2yYjCS48OMw',\n",
       " 'FZo1-PXc2vI',\n",
       " 'oWkASDGrj0s',\n",
       " 'UlfYJBH64MU',\n",
       " 'GTM4l2OVREY',\n",
       " 'q1YcFgsWIe0',\n",
       " 'wIWBdTPIg3Y',\n",
       " '6Ds0xXPsZj0',\n",
       " 'nw0pK6pg6gg',\n",
       " 'xhDkd2eywzU',\n",
       " 'OxonEiUp03o',\n",
       " 'MhFXdXH0Njk',\n",
       " 'JFv4RY_ZLOE',\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_video_ids(youtube, 'UUZf__ehlCEBPop-_sldpBUQ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SSLEOFError",
     "evalue": "EOF occurred in violation of protocol (_ssl.c:2427)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSSLEOFError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jamal\\jamaleb67.github.io\\jamaleb67.github.io\\work\\Sample_project_youtube_videos_EDA.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jamal/jamaleb67.github.io/jamaleb67.github.io/work/Sample_project_youtube_videos_EDA.ipynb#Y163sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m video_df \u001b[39m=\u001b[39m get_video_details(youtube, get_video_ids(youtube, \u001b[39m'\u001b[39;49m\u001b[39mUUZf__ehlCEBPop-_sldpBUQ\u001b[39;49m\u001b[39m'\u001b[39;49m))\n",
      "\u001b[1;32mc:\\Users\\jamal\\jamaleb67.github.io\\jamaleb67.github.io\\work\\Sample_project_youtube_videos_EDA.ipynb Cell 18\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jamal/jamaleb67.github.io/jamaleb67.github.io/work/Sample_project_youtube_videos_EDA.ipynb#Y163sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jamal/jamaleb67.github.io/jamaleb67.github.io/work/Sample_project_youtube_videos_EDA.ipynb#Y163sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mGet list of video IDs of all videos in the given playlist\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jamal/jamaleb67.github.io/jamaleb67.github.io/work/Sample_project_youtube_videos_EDA.ipynb#Y163sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mParams:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jamal/jamaleb67.github.io/jamaleb67.github.io/work/Sample_project_youtube_videos_EDA.ipynb#Y163sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jamal/jamaleb67.github.io/jamaleb67.github.io/work/Sample_project_youtube_videos_EDA.ipynb#Y163sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jamal/jamaleb67.github.io/jamaleb67.github.io/work/Sample_project_youtube_videos_EDA.ipynb#Y163sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m request \u001b[39m=\u001b[39m youtube\u001b[39m.\u001b[39mplaylistItems()\u001b[39m.\u001b[39mlist(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jamal/jamaleb67.github.io/jamaleb67.github.io/work/Sample_project_youtube_videos_EDA.ipynb#Y163sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m             part\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcontentDetails\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jamal/jamaleb67.github.io/jamaleb67.github.io/work/Sample_project_youtube_videos_EDA.ipynb#Y163sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m             playlistId \u001b[39m=\u001b[39m playlist_id,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jamal/jamaleb67.github.io/jamaleb67.github.io/work/Sample_project_youtube_videos_EDA.ipynb#Y163sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m             maxResults \u001b[39m=\u001b[39m \u001b[39m50\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jamal/jamaleb67.github.io/jamaleb67.github.io/work/Sample_project_youtube_videos_EDA.ipynb#Y163sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m response \u001b[39m=\u001b[39m request\u001b[39m.\u001b[39;49mexecute()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jamal/jamaleb67.github.io/jamaleb67.github.io/work/Sample_project_youtube_videos_EDA.ipynb#Y163sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m video_ids \u001b[39m=\u001b[39m []\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jamal/jamaleb67.github.io/jamaleb67.github.io/work/Sample_project_youtube_videos_EDA.ipynb#Y163sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mitems\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m response:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\googleapiclient\\_helpers.py:130\u001b[0m, in \u001b[0;36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[39melif\u001b[39;00m positional_parameters_enforcement \u001b[39m==\u001b[39m POSITIONAL_WARNING:\n\u001b[0;32m    129\u001b[0m         logger\u001b[39m.\u001b[39mwarning(message)\n\u001b[1;32m--> 130\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\googleapiclient\\http.py:923\u001b[0m, in \u001b[0;36mHttpRequest.execute\u001b[1;34m(self, http, num_retries)\u001b[0m\n\u001b[0;32m    920\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mheaders[\u001b[39m\"\u001b[39m\u001b[39mcontent-length\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbody))\n\u001b[0;32m    922\u001b[0m \u001b[39m# Handle retries for server-side errors.\u001b[39;00m\n\u001b[1;32m--> 923\u001b[0m resp, content \u001b[39m=\u001b[39m _retry_request(\n\u001b[0;32m    924\u001b[0m     http,\n\u001b[0;32m    925\u001b[0m     num_retries,\n\u001b[0;32m    926\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mrequest\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    927\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sleep,\n\u001b[0;32m    928\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_rand,\n\u001b[0;32m    929\u001b[0m     \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49muri),\n\u001b[0;32m    930\u001b[0m     method\u001b[39m=\u001b[39;49m\u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmethod),\n\u001b[0;32m    931\u001b[0m     body\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    932\u001b[0m     headers\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    933\u001b[0m )\n\u001b[0;32m    935\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresponse_callbacks:\n\u001b[0;32m    936\u001b[0m     callback(resp)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\googleapiclient\\http.py:222\u001b[0m, in \u001b[0;36m_retry_request\u001b[1;34m(http, num_retries, req_type, sleep, rand, uri, method, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[39mif\u001b[39;00m exception:\n\u001b[0;32m    221\u001b[0m     \u001b[39mif\u001b[39;00m retry_num \u001b[39m==\u001b[39m num_retries:\n\u001b[1;32m--> 222\u001b[0m         \u001b[39mraise\u001b[39;00m exception\n\u001b[0;32m    223\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    224\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\googleapiclient\\http.py:191\u001b[0m, in \u001b[0;36m_retry_request\u001b[1;34m(http, num_retries, req_type, sleep, rand, uri, method, *args, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     exception \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 191\u001b[0m     resp, content \u001b[39m=\u001b[39m http\u001b[39m.\u001b[39;49mrequest(uri, method, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    192\u001b[0m \u001b[39m# Retry on SSL errors and socket timeout errors.\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \u001b[39mexcept\u001b[39;00m _ssl_SSLError \u001b[39mas\u001b[39;00m ssl_error:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\httplib2\\__init__.py:1724\u001b[0m, in \u001b[0;36mHttp.request\u001b[1;34m(self, uri, method, body, headers, redirections, connection_type)\u001b[0m\n\u001b[0;32m   1722\u001b[0m             content \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1723\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1724\u001b[0m             (response, content) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[0;32m   1725\u001b[0m                 conn, authority, uri, request_uri, method, body, headers, redirections, cachekey,\n\u001b[0;32m   1726\u001b[0m             )\n\u001b[0;32m   1727\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1728\u001b[0m     is_timeout \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(e, socket\u001b[39m.\u001b[39mtimeout)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\httplib2\\__init__.py:1444\u001b[0m, in \u001b[0;36mHttp._request\u001b[1;34m(self, conn, host, absolute_uri, request_uri, method, body, headers, redirections, cachekey)\u001b[0m\n\u001b[0;32m   1441\u001b[0m \u001b[39mif\u001b[39;00m auth:\n\u001b[0;32m   1442\u001b[0m     auth\u001b[39m.\u001b[39mrequest(method, request_uri, headers, body)\n\u001b[1;32m-> 1444\u001b[0m (response, content) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conn_request(conn, request_uri, method, body, headers)\n\u001b[0;32m   1446\u001b[0m \u001b[39mif\u001b[39;00m auth:\n\u001b[0;32m   1447\u001b[0m     \u001b[39mif\u001b[39;00m auth\u001b[39m.\u001b[39mresponse(response, body):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\httplib2\\__init__.py:1367\u001b[0m, in \u001b[0;36mHttp._conn_request\u001b[1;34m(self, conn, request_uri, method, body, headers)\u001b[0m\n\u001b[0;32m   1365\u001b[0m     \u001b[39mif\u001b[39;00m conn\u001b[39m.\u001b[39msock \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1366\u001b[0m         conn\u001b[39m.\u001b[39mconnect()\n\u001b[1;32m-> 1367\u001b[0m     conn\u001b[39m.\u001b[39;49mrequest(method, request_uri, body, headers)\n\u001b[0;32m   1368\u001b[0m \u001b[39mexcept\u001b[39;00m socket\u001b[39m.\u001b[39mtimeout:\n\u001b[0;32m   1369\u001b[0m     conn\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1776.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py:1286\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1283\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\u001b[39mself\u001b[39m, method, url, body\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, headers\u001b[39m=\u001b[39m{}, \u001b[39m*\u001b[39m,\n\u001b[0;32m   1284\u001b[0m             encode_chunked\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m   1285\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1286\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_request(method, url, body, headers, encode_chunked)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1776.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py:1332\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1328\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(body, \u001b[39mstr\u001b[39m):\n\u001b[0;32m   1329\u001b[0m     \u001b[39m# RFC 2616 Section 3.7.1 says that text default has a\u001b[39;00m\n\u001b[0;32m   1330\u001b[0m     \u001b[39m# default charset of iso-8859-1.\u001b[39;00m\n\u001b[0;32m   1331\u001b[0m     body \u001b[39m=\u001b[39m _encode(body, \u001b[39m'\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 1332\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendheaders(body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1776.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py:1281\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1279\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1280\u001b[0m     \u001b[39mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1281\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_output(message_body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1776.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py:1041\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1039\u001b[0m msg \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer)\n\u001b[0;32m   1040\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1041\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(msg)\n\u001b[0;32m   1043\u001b[0m \u001b[39mif\u001b[39;00m message_body \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1044\u001b[0m \n\u001b[0;32m   1045\u001b[0m     \u001b[39m# create a consistent interface to message_body\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(message_body, \u001b[39m'\u001b[39m\u001b[39mread\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m   1047\u001b[0m         \u001b[39m# Let file-like take precedence over byte-like.  This\u001b[39;00m\n\u001b[0;32m   1048\u001b[0m         \u001b[39m# is needed to allow the current position of mmap'ed\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m         \u001b[39m# files to be taken into account.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1776.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py:1002\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1000\u001b[0m sys\u001b[39m.\u001b[39maudit(\u001b[39m\"\u001b[39m\u001b[39mhttp.client.send\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m, data)\n\u001b[0;32m   1001\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1002\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msock\u001b[39m.\u001b[39;49msendall(data)\n\u001b[0;32m   1003\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   1004\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, collections\u001b[39m.\u001b[39mabc\u001b[39m.\u001b[39mIterable):\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1776.0_x64__qbz5n2kfra8p0\\Lib\\ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.sendall\u001b[1;34m(self, data, flags)\u001b[0m\n\u001b[0;32m   1272\u001b[0m         amount \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(byte_view)\n\u001b[0;32m   1273\u001b[0m         \u001b[39mwhile\u001b[39;00m count \u001b[39m<\u001b[39m amount:\n\u001b[1;32m-> 1274\u001b[0m             v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(byte_view[count:])\n\u001b[0;32m   1275\u001b[0m             count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m v\n\u001b[0;32m   1276\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1776.0_x64__qbz5n2kfra8p0\\Lib\\ssl.py:1243\u001b[0m, in \u001b[0;36mSSLSocket.send\u001b[1;34m(self, data, flags)\u001b[0m\n\u001b[0;32m   1239\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1240\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1241\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to send() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1242\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1243\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mwrite(data)\n\u001b[0;32m   1244\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1245\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39msend(data, flags)\n",
      "\u001b[1;31mSSLEOFError\u001b[0m: EOF occurred in violation of protocol (_ssl.c:2427)"
     ]
    }
   ],
   "source": [
    "video_df = get_video_details(youtube, get_video_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Comment_df = get_comments_in_videos(youtube, video_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b15849-4219-42a0-bfed-437d6bc3238e",
   "metadata": {},
   "source": [
    "### Get channel statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabd5b3f-0153-4b83-ba51-3ffc3da9181f",
   "metadata": {},
   "source": [
    "Using the `get_channel_stats` function defined below, now we are going to obtain the channel statistics for the 9 channels in scope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc260d74-37a6-42df-bda1-2381d763451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_data = get_channel_stats(youtube, channel_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0de242a-6e8d-465f-a6f7-1ce70c5a98af",
   "metadata": {},
   "source": [
    "Now I can print out the data and take a look at the channel statistics overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e89b36d-c6ec-4bd5-8f5e-bde8eee84f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e50a72-504f-4f14-9ddf-da153986fe58",
   "metadata": {},
   "source": [
    "I noticed the count columns in `channel_data` is currently in string format, so I will convert them into numeric so that we can visualize and do numeric operations on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d6a4b0-2fa0-4357-ba4f-b84bd3a5c097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert count columns to numeric columns\n",
    "numeric_cols = ['subscribers', 'views', 'totalVideos']\n",
    "channel_data[numeric_cols] = channel_data[numeric_cols].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3328be3e-8ffc-4aaf-9159-ade775fbb211",
   "metadata": {},
   "source": [
    "Let's take a look at the number of subscribers per channel to have a view of how popular the channels are when compared with one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bff5976-20e3-400a-a304-13536f4c0cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 가능한 font list 확인\n",
    "import matplotlib.font_manager as fm\n",
    "f = [f.name for f in fm.fontManager.ttflist]\n",
    "\n",
    "# 확인 이후\n",
    "plt.rc('font', family='Malgun Gothic')\n",
    "## Adjusted Size to fit the legend in the figure and rotated the x-axis labels.\n",
    "\n",
    "sns.set(rc={'figure.figsize':(10, 10)})\n",
    "ax = sns.barplot(x='channelName', y='subscribers', data=channel_data.sort_values('subscribers', ascending=False))\n",
    "ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x/1000) + 'K'))\n",
    "plot = ax.set_xticklabels(ax.get_xticklabels(),rotation = 35, ha=\"right\")\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b144aff-4dae-4ffa-92b1-e62007f76c83",
   "metadata": {},
   "source": [
    "Next, we will look at the rank considering the total number of views of the channels. The rank is fairly similar to the subscriber count rank. Sentdex and Corey Schafer remain the two most popular channels considering both subscribers and views. Interestingly, some channels have more subscribers but less views and vice versa. For example, Ken Jee channel has significantly more subscribers than Luke Barousse channel, but slightly less views in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8e4486-61cc-4c55-9b82-047483b4a4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(x='channelName', y='views', data=channel_data.sort_values('views', ascending=False))\n",
    "ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x/1000) + 'K'))\n",
    "plot = ax.set_xticklabels(ax.get_xticklabels(),rotation = 35, ha=\"right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa57d70-f940-4e7a-9b50-f7e5f44f0d26",
   "metadata": {},
   "source": [
    "### Get video statistics for all the channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a964726-88af-43ed-b54e-c0fe3581d1a2",
   "metadata": {},
   "source": [
    "In the next step, we will obtain the video statistics for all the channels. In total, we obtained 3,722 videos as seen in below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee815cb-46e2-40d0-85a0-a56db0dd42ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with video statistics and comments from all channels\n",
    "\n",
    "video_df = pd.DataFrame()\n",
    "comments_df = pd.DataFrame() \n",
    "\n",
    "for c in channel_data['channelName'].unique():\n",
    "    print(\"Getting video information from channel: \" + c)\n",
    "    playlist_id = channel_data.loc[channel_data['channelName']== c, 'playlistId'].iloc[0]\n",
    "    video_ids = get_video_ids(youtube, playlist_id)\n",
    "    \n",
    "    # get video data\n",
    "    video_data = get_video_details(youtube, video_ids)\n",
    "    # get comment data\n",
    "    comments_data = get_comments_in_videos(youtube, video_ids)\n",
    "\n",
    "    # append video data together and comment data toghether\n",
    "    video_df = video_df.concat(video_data, ignore_index=True)\n",
    "    comments_df = comments_df.concat(comments_data, ignore_index=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde6042c-60d1-4914-99fb-d28eecc7ba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584d23f1-4da1-482d-9140-b31ea222b6ac",
   "metadata": {},
   "source": [
    "Let's take a look at the `comment_df` as well. We only get 3,743 comments in total due to the fact that we limited to 10 first comments on the video to avoid exceeding the Youtube API quota limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571744e5-3412-4e4d-b5dd-4a2fc6fd72e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "comments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda95a32-453a-4726-a6e2-12f6c4aa8bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write video data to CSV file for future references\n",
    "video_df.to_csv('video_data_top10_channels.csv')\n",
    "comments_df.to_csv('comments_data_top10_channels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92abf7a3-e7a5-4318-92a1-86374987a2bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preprocessing & Feature engineering\n",
    "\n",
    "To be able to make use of the data for analysis, we need to perform a few pre-processing steps. Firstly, I would like reformat some columns, especially the date and time columns such as \"pushlishedAt\" and \"duration\". In addition, I also think it is necessary to enrich the data with some new features that might be useful for understanding the videos' characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1480633c-30e4-4cea-9dff-fd70e16f499f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Check for empty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9168616-174d-45ac-8803-633fd2055db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d989df23-12e0-4109-82a5-6fc3f29b504f",
   "metadata": {},
   "source": [
    "There's no strange dates in the publish date column, videos were published between 2013 and 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fe7909-dca9-4a4f-8430-9c188e08bee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_df.publishedAt.sort_values().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b75398-a0be-4f48-b635-d7ae57bc733c",
   "metadata": {},
   "source": [
    "Next, we need to check if the data type of the columns are correct. I have checked the data types and indeed some count columns such as view count and comment count are currently not in correct data type. In this step, we convert these count columns into integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c5aa85-b1f4-451e-bc16-07f7c23bb18e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = ['viewCount', 'likeCount', 'favoriteCount', 'commentCount']\n",
    "video_df[cols] = video_df[cols].apply(pd.to_numeric, errors='coerce', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4874ec6a-6660-46d9-8a3c-3ec6ad5fd9a5",
   "metadata": {},
   "source": [
    "### Enriching data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8e4d5f-0d86-4a93-aa86-633bf5fc974f",
   "metadata": {},
   "source": [
    "I want to enrich the data for further analyses, for example:\n",
    "\n",
    "- create published date column with another column showing the day in the week the video was published, which will be useful for later analysis.\n",
    "\n",
    "- convert video duration to seconds instead of the current default string format\n",
    "\n",
    "- calculate number of tags for each video\n",
    "\n",
    "- calculate comments and likes per 1000 view ratio\n",
    "\n",
    "- calculate title character length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c67380c-d2cd-4447-ad7b-1f5f700520d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create publish day (in the week) column\n",
    "video_df['publishedAt'] =  video_df['publishedAt'].apply(lambda x: parser.parse(x)) \n",
    "video_df['pushblishDayName'] = video_df['publishedAt'].apply(lambda x: x.strftime(\"%A\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd980e2c-f3f4-49c9-b0c4-9a6dac08b7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert duration to seconds\n",
    "video_df['durationSecs'] = video_df['duration'].apply(lambda x: isodate.parse_duration(x))\n",
    "video_df['durationSecs'] = video_df['durationSecs'].astype('timedelta64[s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a271eda-3417-476f-ab75-b769173a76e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add number of tags\n",
    "video_df['tagsCount'] = video_df['tags'].apply(lambda x: 0 if x is None else len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e994d2df-c812-4cc5-a7cb-df1df19b8355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments and likes per 1000 view ratio\n",
    "video_df['likeRatio'] = video_df['likeCount']/ video_df['viewCount'] * 1000\n",
    "video_df['commentRatio'] = video_df['commentCount']/ video_df['viewCount'] * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4ecd96-ad0b-498a-97a7-364286fa7c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title character length\n",
    "video_df['titleLength'] = video_df['title'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f842b3df-ae90-443f-96f4-a7d495616644",
   "metadata": {},
   "source": [
    "Let's look at the video dataset at this point to see if everything went well. It looks good - now we will proceed to exploratory analysis part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034765b0-b2eb-4709-997d-95650aabf167",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b98a1a9-0239-48ff-b843-2d752797e690",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exploratory analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ecdda0-6cbf-4c4c-93bd-f8dead3fd374",
   "metadata": {},
   "source": [
    "### Views distribution per channel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2539ddb5-95ab-4cc7-8d0f-657f37e37d46",
   "metadata": {},
   "source": [
    "With the video statistics for all channel, now we can see how the views are distributed per channel. Some channels might have a lot of views on one of their videos and the rest do not receive many views. Other channels might have more evenly distribution views per video. It can be observed that Corey Schafer, sentdex and Luke Barousse have quite large variance in their views, suggesting that they have a few viral videos. Alex The Analyst, Krish Naik and Data Science Dojo have less views overall but the views are more consistent across videos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e5d670-1df4-402a-a95d-b8278f0e61f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (18, 6)\n",
    "sns.violinplot(video_df['channelTitle'], video_df['viewCount'], palette = 'pastel')\n",
    "plt.title('Views per channel', fontsize = 14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b486a3a7-8cee-4217-8cbc-e6a97e157479",
   "metadata": {},
   "source": [
    "### Does the number of likes and comments matter for a video to get more views?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1938911-360f-45b5-9a84-d1132519d556",
   "metadata": {},
   "source": [
    "Firstly, I would like to check if comments and likes do correlate with how many views a video would get. In the plots below, it can be observed that the number of views and number of comments/ likes strongly correlated with each other. The number of likes seems to suggest stronger correlation than the number of comments. However, this is expected as the more people watching a video, the more likely this video will get comments and likes. To correct for this factor, we will plot these relationships again using the comments per 1000 view and likes per 1000 view ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cddc4e-15d9-4361-b66d-97e25d50f564",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax =plt.subplots(1,2)\n",
    "sns.scatterplot(data = video_df, x = \"commentCount\", y = \"viewCount\", ax=ax[0])\n",
    "sns.scatterplot(data = video_df, x = \"likeCount\", y = \"viewCount\", ax=ax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e6bda8-f68b-43b3-ab29-9f97e0f9cb5f",
   "metadata": {},
   "source": [
    "Now we will take a look at the correlation if we look at the comment ratio and like ratio instead of the absolute number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8dd9db-459c-4024-af51-f7446fa1a18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax =plt.subplots(1,2)\n",
    "sns.scatterplot(data = video_df, x = \"commentRatio\", y = \"viewCount\", ax=ax[0])\n",
    "sns.scatterplot(data = video_df, x = \"likeRatio\", y = \"viewCount\", ax=ax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a757b7e0-5b10-4c04-b68f-13a823366d31",
   "metadata": {},
   "source": [
    "After correcting for the absolute number of views, it turns out that the correlation is much less clear. The comment-view relationship seems to completely disappear: a lot of videos have millions of views and very few comments, while some vides have very few views have better interaction. However, it is understandable that comments take more effort than views and likes, and normally comments would die off when the video gets older.\n",
    "\n",
    "As for like-view relatioship, we can still see some positive correlation between views and like ratio (though very subtle), which means that the more views a video has, the more people would hit the like button! This seems to support the idea of social proof, which means that people tend to like better the products that are already liked by many other people."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b32207-773c-4173-af24-05c6e6e54086",
   "metadata": {},
   "source": [
    "#### Does the video duration matter for views and interaction (likes/ comments)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea36f48-8886-467c-af24-e106ff3a5506",
   "metadata": {},
   "source": [
    "As can be seen in the histogram below, most videos are between 300 to 1200 seconds, which is about 5 to 20 minutes. Here I have to limit the duration to 10,000 because of some really long videos (potentially streaming videos). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa2aedf-deb4-4361-a04d-2f58fadc117b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=video_df[video_df['durationSecs'] < 10000], x=\"durationSecs\", bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775ddd0b-9291-49c6-a346-3b2ba49bfc9b",
   "metadata": {},
   "source": [
    "Now we plot the duration against comment count and like count. It can be seen that actually shorter videos tend to get more likes and comments than very long videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ebab9e-9a1d-433c-8f42-724bedc0218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax =plt.subplots(1,2)\n",
    "sns.scatterplot(data = video_df, x = \"durationSecs\", y = \"commentCount\", ax=ax[0])\n",
    "sns.scatterplot(data = video_df, x = \"durationSecs\", y = \"likeCount\", ax=ax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6572cae4-4569-428a-af43-f3b7723feda4",
   "metadata": {},
   "source": [
    "### Does title length matter for views?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9374c48f-6429-4805-a4c8-1af24ef48ed0",
   "metadata": {},
   "source": [
    "There is no clear relationship between title length and views as seen the scatterplot below, but most-viewed videos tend to have average title length of 30-70 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fa3602-3932-4ae5-acaf-ade0541988cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data = video_df, x = \"titleLength\", y = \"viewCount\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2df32b2-06bb-4ba9-9007-2225330e16d9",
   "metadata": {},
   "source": [
    "### Wordcloud for words in title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3cf29e-7145-41ad-8e47-e64ad44a2207",
   "metadata": {},
   "source": [
    "As I'm interested to see what the creators are making videos about and which terms most frequently appear in their video titles, I will create a wordcloud for the most common words. We first need to remove the stopwords such as \"you\", \"I\", \"the\", etc. which do note contribute a lot to the meaning of the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5ec091-9480-4354-b7df-0f12877b385e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "video_df['title_no_stopwords'] = video_df['title'].apply(lambda x: [item for item in str(x).split() if item not in stop_words])\n",
    "\n",
    "all_words = list([a for b in video_df['title_no_stopwords'].tolist() for a in b])\n",
    "all_words_str = ' '.join(all_words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd4825e-2b5e-4960-be24-e1537a738254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cloud(wordcloud):\n",
    "    plt.figure(figsize=(30, 20))\n",
    "    plt.imshow(wordcloud) \n",
    "    plt.axis(\"off\");\n",
    "\n",
    "wordcloud = WordCloud(width = 2000, height = 1000, random_state=1, background_color='black', \n",
    "                      colormap='viridis', collocations=False).generate(all_words_str)\n",
    "plot_cloud(wordcloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb275665-6821-4293-8a05-ba932d2e3450",
   "metadata": {},
   "source": [
    "It can be seen that most common words are Data, Python, Tutorial, Science,  Projects, Analysis, Programming, Learning, which is very expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2190d1-8224-413f-a057-b1782e82b9c0",
   "metadata": {},
   "source": [
    "### Number of tags vs views"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a134fe4-83ff-4c59-b257-8b5aa88e7bc0",
   "metadata": {},
   "source": [
    "It seems that most videos have between 5 and 30 tags. The relationship between number of tags and view count is not clearly seen, but too few tags or too many tags do seem to correlate with fewer views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a632ec-c7ec-49b9-b9ff-1801220b2e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data = video_df, x = \"tagsCount\", y = \"viewCount\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e29f5b0-99e4-448a-9405-2f011b0743a8",
   "metadata": {},
   "source": [
    "### Which day in the week are most videos uploaded?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254897ef-0268-4a06-af94-c3da558fe4ab",
   "metadata": {},
   "source": [
    "It's interesting to see that more videos are uploaded on Mondays and Fridays. Fewer videos are uploaded during the weekend. This could be because of the nature of the niche that is more geared towards tutorials and heavy materials, which is not suitable for weekends' consumption. But it could also just means that most creators work on their videos during the weekend or during the week and upload them beginning of the week or Friday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ce745c-e30f-4177-84dc-4b43c407815e",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_df = pd.DataFrame(video_df['pushblishDayName'].value_counts())\n",
    "weekdays = [ 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "day_df = day_df.reindex(weekdays)\n",
    "ax = day_df.reset_index().plot.bar(x='index', y='pushblishDayName', rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11325ab3-d357-48a7-84fe-72418d897229",
   "metadata": {},
   "source": [
    "### Wordcloud for video comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968eac77-6ff4-4800-a8ce-8eca07b1237c",
   "metadata": {},
   "source": [
    "We can see what are the frequently-mentioned words in the video comments. I will do this by visualizing the keywords in a wordcloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c762a578-22d1-4bb4-a9cc-8688ed38d418",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "comments_df['comments_no_stopwords'] = comments_df['comments'].apply(lambda x: [item for item in str(x).split() if item not in stop_words])\n",
    "\n",
    "all_words = list([a for b in comments_df['comments_no_stopwords'].tolist() for a in b])\n",
    "all_words_str = ' '.join(all_words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4970dc62-5855-47b0-bd26-892dd69fc765",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width = 2000, height = 1000, random_state=1, background_color='black', \n",
    "                      colormap='viridis', collocations=False).generate(all_words_str)\n",
    "plot_cloud(wordcloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca5dcdd-1aa2-4374-b6e2-0a90a398efb6",
   "metadata": {},
   "source": [
    "We can see that next to the obvious words such as \"video\", \"data\", the most frequent words are quite positive, such as \"thank\", \"great\", \"good\", \"awesome\", \"love\". A lot of comments also request something with the word \"please\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68308be-d2c0-4524-82e0-04cff500fdc0",
   "metadata": {},
   "source": [
    "## Conclusions and future research ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b21d11c-900a-42e0-978f-34582f33f18d",
   "metadata": {
    "tags": []
   },
   "source": [
    "In this project, we have explored the video data of the 9 most popular Data science/ Data analyst channels and revealed many interesting findings for anyone who are starting out with a Youtube channel in data science or another topic:\n",
    "\n",
    "- The more likes and comments a video has, the more views the video gets (it is not guaranteed that this is a causal relationship, it is simply a correlation and can work both way). Likes seem to be a better indicator for interaction than comments and the number of likes seem to follow the \"social proof\", which means the more views the video has, the more people will like it.\n",
    "\n",
    "- Most videos have between 5 and 30 tags.\n",
    "\n",
    "- Most-viewed videos tend to have average title length of 30-70 characters. Too short or too long titles seem to harm viewership.\n",
    "\n",
    "- Videos are usually uploaded on Mondays and Fridays. Weekends and Sunday in particular is not a popular time for posting new videos.\n",
    "\n",
    "- Comments on videos are generally positive, we noticed a lot \"please\" words, suggesting potential market gaps in content that could be filled. \n",
    "\n",
    "**Project limitation:**\n",
    "\n",
    "The findings should also be taken with a grain of salt for a number of reasons:\n",
    "\n",
    "- The number of videos is quite small (the dataset has only ~3,700 videos)\n",
    "\n",
    "- I have only considered the first 10 comments on each video, which might not be representative for all comments\n",
    "\n",
    "- There are many other factors that haven't been taken into the analysis, including the marketing strategy of the creators and many random effects that would affect how successful a video is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40477a8-240a-4bf7-b752-89177a763237",
   "metadata": {},
   "source": [
    "**Ideas for future research:**\n",
    "\n",
    "To expand and build on this research project, one can:\n",
    "\n",
    "- Expand the dataset to also smaller channels in data science niche\n",
    "\n",
    "- Do sentiment analysis on the comments and find out which videos get more positive comments and which videos get less positive comments\n",
    "\n",
    "- Do market research by analyzing questions in the comment threads and identifying common questions/ market gaps which could potentially filled\n",
    "\n",
    "- Conduct this research for other niches (e.g. vlogs or beauty channels), to compare different niches with each other to see the different patterns in viewership and video characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9707add-cfaf-491a-859c-9137b765ae84",
   "metadata": {},
   "source": [
    "### References/ Resources used:\n",
    "\n",
    "[1] Youtube API. Avaiable at https://developers.google.com/youtube/v3\n",
    "\n",
    "[2] Converting video durations to time function. https://stackoverflow.com/questions/15596753/how-do-i-get-video-durations-with-youtube-api-version-3\n",
    "\n",
    "[3] P. Covington, J. Adams, E. Sargin. The youtube video recommendation system. In Proceedings of the Fourth ACM Conference on Recommender Systems, RecSys '16, pages 191-198, New York, NY, USA, 2016. ACM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dceddedd-f561-44c5-be35-5add6ad0ed60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
