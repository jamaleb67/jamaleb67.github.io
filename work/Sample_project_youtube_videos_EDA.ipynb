{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc88f6c2-0fe6-4809-bd30-668aff01e30c",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysing Using Youtube Video Data from Most Popular Channels in the top 10 countries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2c58a7-dc81-4131-802c-ae3435a6ce7f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Aims, objectives and background\n",
    "\n",
    "## 1.1. Introduction\n",
    "\n",
    "Founded in 2005, Youtube has grown to become the second largest search engine in the world (behind Google) that processes more than 3 billion searches per month. [[1]](https://www.mushroomnetworks.com/infographics/youtube---the-2nd-largest-search-engine-infographic/). It is, however, generally a myth how the Youtube algorithm works, what makes a video get views and be recommended over another. In fact, YouTube has one of the largest scale and most sophisticated industrial recommendation systems in existence [[2]](https://dl.acm.org/doi/10.1145/2959100.2959190). For new content creators, it is a challenge to understand why a video gets video and others do not. There are many \"myths\" around the success of a Youtube video [[3]](https://vidiq.com/blog/post/5-youtube-algorithm-myths-youtubers-need-to-know-about/), for example if the video has more likes or comments, or if the video is of a certain duration. It is also worth experimenting and looking for \"trends\" in the topics that Youtube channels are covering in a certain niche.\n",
    "\n",
    "Having recently stepping into the content creation world with a new Youtube channel on data analytics and data science, I decided to gain some insights on this topic which might be useful for other new content creators. The scope of this small project is limited to data science channels and I will not consider other niches (that might have a different characteristics and audience base). Therefore, in this project will explore the statistics of around 10 most successful data science Youtube channel.\n",
    "\n",
    "## 1.2. Aims and objectives\n",
    "\n",
    "Within this project, I would like to explore the following:\n",
    "\n",
    "- Getting to know Youtube API and how to obtain video data.\n",
    "- Analyzing video data and verify different common \"myths\" about what makes a video do well on Youtube, for example:\n",
    "    - Does the number of likes and comments matter for a video to get more views?\n",
    "    - Does the video duration matter for views and interaction (likes/ comments)?\n",
    "    - Does title length matter for views?\n",
    "    - How many tags do good performing videos have? What are the common tags among these videos?\n",
    "    - Across all the creators I take into consideration, how often do they upload new videos? On which days in the week?\n",
    "- Explore the trending topics using NLP techniques\n",
    "    - Which popular topics are being covered in the videos (e.g. using wordcloud for video titles)?\n",
    "    - Which questions are being asked in the comment sections in the videos\n",
    "\n",
    "## 1.3. Steps of the project\n",
    "1. Obtain video meta data via Youtube API for the top 10-15 channels in the data science niche (this includes several small steps: create a developer key, request data and transform the responses into a usable data format)\n",
    "2. Prepocess data and engineer additional features for analysis\n",
    "3. Exploratory data analysis\n",
    "4. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21458ddf-101b-4ecd-8ee8-3cf6655eb46b",
   "metadata": {},
   "source": [
    "## 1.4. Dataset\n",
    "\n",
    "### Data selection\n",
    "\n",
    "As this project is particularly focused on data science channels, I found that not many readily available datasets online are suitable for this purpose. The 2 alternative datasets I found are:\n",
    "\n",
    "- [The top trending Youtube videos on Kaggle](https://www.kaggle.com/rsrishav/youtube-trending-video-dataset): This dataset contains several months of data on daily trending YouTube videos for several countries. There are up to 200 trending videos per day. However, this dataset is not fit for this project because the trending videos are about a wide range of topics that are not necessarily related to data science. \n",
    "\n",
    "- Another dataset is obtained from this [Github repo](https://gitlab.com/thebrahminator/Youtube-View-Predictor) of Vishwanath Seshagiri, which is the metadata of 0.5M+ YouTube videos along with their channel data. There is no clear documentation on how this dataset was created, but a quick look at the datasets in the repository suggested that the data was obtained using keyword search of popular keywords such as \"football\" or \"science\". There are also some relevant keywords such as \"python\". However, I decided not to use these datasets because they don't contain data for the channels I am interested in.\n",
    "\n",
    "I created my own dataset using the [Google Youtube Data API version 3.0](https://developers.google.com/youtube/v3). The exact steps of data creation is presented in section *2. Data Creation* below.\n",
    "\n",
    "### Data limitations\n",
    "\n",
    "The dataset is a real-world dataset and suitable for the research. However, the selection of the top 10 Youtube channels to include in the research is purely based on my knowledge of the channels in data science field and might not be accurate. My definition is \"popular\" is only based on subscriber count but there are other metrics that could be taken into consideration as well (e.g. views, engagement). The top 10 also seems arbitrary given the plethora of channels on Youtube. There might be smaller channels that might also very interesting to look into, which could be the next step of this project.\n",
    "\n",
    "### Ethics of data source\n",
    "\n",
    "According to [Youtube API's guide](https://developers.google.com/youtube/v3/getting-started), the usage of Youtube API is free of charge given that your application send requests within a quota limit. \"The YouTube Data API uses a quota to ensure that developers use the service as intended and do not create applications that unfairly reduce service quality or limit access for others. \" The default quota allocation for each application is 10,000 units per day, and you could request additional quota by completing a form to YouTube API Services if you reach the quota limit.\n",
    "\n",
    "Since all data requested from Youtube API is public data (which everyone on the Internet can see on Youtube), there is no particular privacy issues as far as I am concerned. In addition, the data is obtained only for research purposes in this case and not for any commercial interests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ba6bd0-2c70-42d5-ab1d-9ebff01c62ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil import parser\n",
    "import isodate\n",
    "\n",
    "# Data visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\", color_codes=True)\n",
    "\n",
    "# Google API\n",
    "from googleapiclient.discovery import build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8a223f-2420-421f-8647-344591a19e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be282b2-b566-4587-97d1-71b680cf6b92",
   "metadata": {},
   "source": [
    "# 2. Data creation with Youtube API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400f8704-cfe4-495b-af35-bb5dfb677c6e",
   "metadata": {},
   "source": [
    "I first created a project on Google Developers Console, then requested an authorization credential (API key). Afterwards, I enabled Youtube API for my application, so that I can send API requests to Youtube API services. Then, I went on Youtube and checked the channel ID of each of the channels that I would like to include in my research scope (using their URLs). Then I created the functions for getting the channel statistics via the API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U.S. Top Channels\n",
    "\n",
    "\n",
    "1. Mr. Beasts view-source:https://www.youtube.com/@MrBeast/about\n",
    "* UCX6OQ3DkcsbYNE6H8uQQuVA\n",
    "\n",
    "2. Cocomelon - Nursery Rhymes view-source:https://www.youtube.com/channel/UCbCmjCuTUZos6Inko4u57UQ\n",
    "* UCbCmjCuTUZos6Inko4u57UQ\n",
    "\n",
    "3. Dude Perfect view-source:https://www.youtube.com/channel/UCRijo3ddMTht_IHyNSNXpNQ\n",
    "* UCRijo3ddMTht_IHyNSNXpNQ\n",
    "\n",
    "4. âœ¿ Kids Diana Show view-source:https://www.youtube.com/channel/UCk8GzjMOrta8yxDcKfylJYw\n",
    "* UCk8GzjMOrta8yxDcKfylJYw\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For India, the top two YouTubers are **Bhuvaneshwar Bam** and **Amit Bhadana**. Bhuvaneshwar Bam is the creator of **BB ki Vines**, a comedy channel that features him playing multiple characters. He has more than 20 million subscribers and over 3 billion views. Amit Bhadana is another comedy channel that features slice of life content, relationships, and comedic skits. He has more than 22 million subscribers and over 1.8 billion views. You can visit their YouTube pages here: [BB ki Vines](^1^) and [Amit Bhadana](^2^).\n",
    "\n",
    "- For Japan, the top two YouTubers are **HikakinTV** and **Yuka Kinoshita**. HikakinTV is a channel that features various content such as music, games, challenges, and collaborations with other celebrities. He has more than 8.8 million subscribers and over 6.7 billion views. Yuka Kinoshita is a channel that features her eating large amounts of food in a short time. She has more than 5.6 million subscribers and over 2.4 billion views. You can visit their YouTube pages here: [HikakinTV](^3^) and [Yuka Kinoshita].\n",
    "\n",
    "- For Mexico, the top two YouTubers are **Luisito Comunica** and **Badabun**. Luisito Comunica is a channel that features his travels around the world, exploring different cultures, cuisines, and attractions. He has more than 36 million subscribers and over 4.9 billion views. Badabun is a channel that features various content such as entertainment, news, pranks, and social experiments. He has more than 43 million subscribers and over 14 billion views. You can visit their YouTube pages here: [Luisito Comunica] and [Badabun].\n",
    "\n",
    "- For South Korea, the top two YouTubers are **Boram Tube Vlog** and **Saebyuk Jang**. Boram Tube Vlog is a channel that features a six-year-old girl named Boram and her family doing various activities such as playing with toys, cooking, traveling, and reviewing products. She has more than 26 million subscribers and over 10 billion views. Saebyuk Jang is a channel that features a young boy named Saebyuk and his parents doing various content such as games, challenges, vlogs, and animations. He has more than 23 million subscribers and over 8 billion views. You can visit their YouTube pages here: [Boram Tube Vlog] and [Saebyuk Jang].\n",
    "\n",
    "\n",
    "1) YouTube. https://www.youtube.com/index.\n",
    "2) Top 50 Popular YouTubers in India (2023) - Moneymint. https://moneymint.com/top-youtubers-in-india/.\n",
    "3) List of most-subscribed YouTube channels - Wikipedia. https://en.wikipedia.org/wiki/List_of_most-subscribed_YouTube_channels.\n",
    "## India Top Channels\n",
    "1.  view-source:\n",
    "*\n",
    "2.   view-source:\n",
    "*\n",
    "\n",
    "## Japan Top Channels\n",
    "1.  view-source:\n",
    "*\n",
    "2.  view-source:\n",
    "*\n",
    "\n",
    "## Mexico Top Channels\n",
    "1.  view-source:\n",
    "*\n",
    "2.  view-source:\n",
    "*\n",
    "\n",
    "## South Korea Top Channels\n",
    "1.  view-source:\n",
    "*\n",
    "2.  view-source:\n",
    "*\n",
    "\n",
    "## United Kingdom Top Channels\n",
    "1.  view-source:\n",
    "*\n",
    "2.  view-source:\n",
    "*\n",
    "\n",
    "## Germany Top Channels\n",
    "1.\n",
    "*\n",
    "2.\n",
    "*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "America: US$ 25.035 trillion.\n",
    "China: US$ 18.321 trillion.\n",
    "Japan; US$ 4.301 trillion.\n",
    "Germany: US$ 4.031 trillion.\n",
    "India: US$ 3.469 trillion.\n",
    "UK: US$ 3.199 trillion.\n",
    "France: US$ 2.778 trillion.\n",
    "Russia: US$ 2.113 trillion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6efe38a-b85b-4161-8dd2-74c4a97e5890",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'AIzaSyDs9TExsfc8fDMn4lBRYXZax1vSr0ftsdk' \n",
    "\n",
    "channel_ids = ['UCtYLUTtgS3k1Fg4y5tAhLbw', # Statquest\n",
    "               'UCCezIgC97PvUuR4_gbFUs5g', # Corey Schafer\n",
    "               'UCfzlCWGWYyIQ0aLC5w48gBQ', # Sentdex\n",
    "               'UCNU_lfiiWBdtULKOw6X0Dig', # Krish Naik\n",
    "               'UCzL_0nIe8B4-7ShhVPfJkgw', # DatascienceDoJo\n",
    "               'UCLLw7jmFsvfIVaUFsLs8mlQ', # Luke Barousse \n",
    "               'UCiT9RITQ9PW6BhXK0y2jaeg', # Ken Jee\n",
    "               'UC7cs8q-gJRlGwj4A8OmCmXg', # Alex the analyst\n",
    "               'UC2UXDak6o7rBm23k3Vv5dww', # Tina Huang\n",
    "              ]\n",
    "\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0493ab-cf9e-48e0-bbed-05ee47b71df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_stats(youtube, channel_ids):\n",
    "    \"\"\"\n",
    "    Get channel statistics: title, subscriber count, view count, video count, upload playlist\n",
    "    Params:\n",
    "    \n",
    "    youtube: the build object from googleapiclient.discovery\n",
    "    channels_ids: list of channel IDs\n",
    "    \n",
    "    Returns:\n",
    "    Dataframe containing the channel statistics for all channels in the provided list: title, subscriber count, view count, video count, upload playlist\n",
    "    \n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    request = youtube.channels().list(\n",
    "                part='snippet,contentDetails,statistics',\n",
    "                id=','.join(channel_ids))\n",
    "    response = request.execute() \n",
    "    \n",
    "    for i in range(len(response['items'])):\n",
    "        data = dict(channelName = response['items'][i]['snippet']['title'],\n",
    "                    subscribers = response['items'][i]['statistics']['subscriberCount'],\n",
    "                    views = response['items'][i]['statistics']['viewCount'],\n",
    "                    totalVideos = response['items'][i]['statistics']['videoCount'],\n",
    "                    playlistId = response['items'][i]['contentDetails']['relatedPlaylists']['uploads'])\n",
    "        all_data.append(data)\n",
    "    \n",
    "    return pd.DataFrame(all_data)\n",
    "\n",
    "def get_video_ids(youtube, playlist_id):\n",
    "    \"\"\"\n",
    "    Get list of video IDs of all videos in the given playlist\n",
    "    Params:\n",
    "    \n",
    "    youtube: the build object from googleapiclient.discovery\n",
    "    playlist_id: playlist ID of the channel\n",
    "    \n",
    "    Returns:\n",
    "    List of video IDs of all videos in the playlist\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    request = youtube.playlistItems().list(\n",
    "                part='contentDetails',\n",
    "                playlistId = playlist_id,\n",
    "                maxResults = 50)\n",
    "    response = request.execute()\n",
    "    \n",
    "    video_ids = []\n",
    "    \n",
    "    for i in range(len(response['items'])):\n",
    "        video_ids.append(response['items'][i]['contentDetails']['videoId'])\n",
    "        \n",
    "    next_page_token = response.get('nextPageToken')\n",
    "    more_pages = True\n",
    "    \n",
    "    while more_pages:\n",
    "        if next_page_token is None:\n",
    "            more_pages = False\n",
    "        else:\n",
    "            request = youtube.playlistItems().list(\n",
    "                        part='contentDetails',\n",
    "                        playlistId = playlist_id,\n",
    "                        maxResults = 50,\n",
    "                        pageToken = next_page_token)\n",
    "            response = request.execute()\n",
    "    \n",
    "            for i in range(len(response['items'])):\n",
    "                video_ids.append(response['items'][i]['contentDetails']['videoId'])\n",
    "            \n",
    "            next_page_token = response.get('nextPageToken')\n",
    "        \n",
    "    return video_ids\n",
    "\n",
    "def get_video_details(youtube, video_ids):\n",
    "    \"\"\"\n",
    "    Get video statistics of all videos with given IDs\n",
    "    Params:\n",
    "    \n",
    "    youtube: the build object from googleapiclient.discovery\n",
    "    video_ids: list of video IDs\n",
    "    \n",
    "    Returns:\n",
    "    Dataframe with statistics of videos, i.e.:\n",
    "        'channelTitle', 'title', 'description', 'tags', 'publishedAt'\n",
    "        'viewCount', 'likeCount', 'favoriteCount', 'commentCount'\n",
    "        'duration', 'definition', 'caption'\n",
    "    \"\"\"\n",
    "        \n",
    "    all_video_info = []\n",
    "    \n",
    "    for i in range(0, len(video_ids), 50):\n",
    "        request = youtube.videos().list(\n",
    "            part=\"snippet,contentDetails,statistics\",\n",
    "            id=','.join(video_ids[i:i+50])\n",
    "        )\n",
    "        response = request.execute() \n",
    "\n",
    "        for video in response['items']:\n",
    "            stats_to_keep = {'snippet': ['channelTitle', 'title', 'description', 'tags', 'publishedAt'],\n",
    "                             'statistics': ['viewCount', 'likeCount', 'favouriteCount', 'commentCount'],\n",
    "                             'contentDetails': ['duration', 'definition', 'caption']\n",
    "                            }\n",
    "            video_info = {}\n",
    "            video_info['video_id'] = video['id']\n",
    "\n",
    "            for k in stats_to_keep.keys():\n",
    "                for v in stats_to_keep[k]:\n",
    "                    try:\n",
    "                        video_info[v] = video[k][v]\n",
    "                    except:\n",
    "                        video_info[v] = None\n",
    "\n",
    "            all_video_info.append(video_info)\n",
    "            \n",
    "    return pd.DataFrame(all_video_info)\n",
    "\n",
    "def get_comments_in_videos(youtube, video_ids):\n",
    "    \"\"\"\n",
    "    Get top level comments as text from all videos with given IDs (only the first 10 comments due to quote limit of Youtube API)\n",
    "    Params:\n",
    "    \n",
    "    youtube: the build object from googleapiclient.discovery\n",
    "    video_ids: list of video IDs\n",
    "    \n",
    "    Returns:\n",
    "    Dataframe with video IDs and associated top level comment in text.\n",
    "    \n",
    "    \"\"\"\n",
    "    all_comments = []\n",
    "    \n",
    "    for video_id in video_ids:\n",
    "        try:   \n",
    "            request = youtube.commentThreads().list(\n",
    "                part=\"snippet,replies\",\n",
    "                videoId=video_id\n",
    "            )\n",
    "            response = request.execute()\n",
    "        \n",
    "            comments_in_video = [comment['snippet']['topLevelComment']['snippet']['textOriginal'] for comment in response['items'][0:10]]\n",
    "            comments_in_video_info = {'video_id': video_id, 'comments': comments_in_video}\n",
    "\n",
    "            all_comments.append(comments_in_video_info)\n",
    "            \n",
    "        except: \n",
    "            # When error occurs - most likely because comments are disabled on a video\n",
    "            print('Could not get comments for video ' + video_id)\n",
    "        \n",
    "    return pd.DataFrame(all_comments)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b15849-4219-42a0-bfed-437d6bc3238e",
   "metadata": {},
   "source": [
    "### Get channel statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabd5b3f-0153-4b83-ba51-3ffc3da9181f",
   "metadata": {},
   "source": [
    "Using the `get_channel_stats` function defined below, now we are going to obtain the channel statistics for the 9 channels in scope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc260d74-37a6-42df-bda1-2381d763451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_data = get_channel_stats(youtube, channel_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0de242a-6e8d-465f-a6f7-1ce70c5a98af",
   "metadata": {},
   "source": [
    "Now I can print out the data and take a look at the channel statistics overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e89b36d-c6ec-4bd5-8f5e-bde8eee84f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e50a72-504f-4f14-9ddf-da153986fe58",
   "metadata": {},
   "source": [
    "I noticed the count columns in `channel_data` is currently in string format, so I will convert them into numeric so that we can visualize and do numeric operations on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d6a4b0-2fa0-4357-ba4f-b84bd3a5c097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert count columns to numeric columns\n",
    "numeric_cols = ['subscribers', 'views', 'totalVideos']\n",
    "channel_data[numeric_cols] = channel_data[numeric_cols].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3328be3e-8ffc-4aaf-9159-ade775fbb211",
   "metadata": {},
   "source": [
    "Let's take a look at the number of subscribers per channel to have a view of how popular the channels are when compared with one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bff5976-20e3-400a-a304-13536f4c0cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(10,8)})\n",
    "ax = sns.barplot(x='channelName', y='subscribers', data=channel_data.sort_values('subscribers', ascending=False))\n",
    "ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x/1000) + 'K'))\n",
    "plot = ax.set_xticklabels(ax.get_xticklabels(),rotation = 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b144aff-4dae-4ffa-92b1-e62007f76c83",
   "metadata": {},
   "source": [
    "Next, we will look at the rank considering the total number of views of the channels. The rank is fairly similar to the subscriber count rank. Sentdex and Corey Schafer remain the two most popular channels considering both subscribers and views. Interestingly, some channels have more subscribers but less views and vice versa. For example, Ken Jee channel has significantly more subscribers than Luke Barousse channel, but slightly less views in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8e4486-61cc-4c55-9b82-047483b4a4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(x='channelName', y='views', data=channel_data.sort_values('views', ascending=False))\n",
    "ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x/1000) + 'K'))\n",
    "plot = ax.set_xticklabels(ax.get_xticklabels(),rotation = 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa57d70-f940-4e7a-9b50-f7e5f44f0d26",
   "metadata": {},
   "source": [
    "### Get video statistics for all the channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a964726-88af-43ed-b54e-c0fe3581d1a2",
   "metadata": {},
   "source": [
    "In the next step, we will obtain the video statistics for all the channels. In total, we obtained 3,722 videos as seen in below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee815cb-46e2-40d0-85a0-a56db0dd42ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with video statistics and comments from all channels\n",
    "\n",
    "video_df = pd.DataFrame()\n",
    "comments_df = pd.DataFrame()\n",
    "\n",
    "for c in channel_data['channelName'].unique():\n",
    "    print(\"Getting video information from channel: \" + c)\n",
    "    playlist_id = channel_data.loc[channel_data['channelName']== c, 'playlistId'].iloc[0]\n",
    "    video_ids = get_video_ids(youtube, playlist_id)\n",
    "    \n",
    "    # get video data\n",
    "    video_data = get_video_details(youtube, video_ids)\n",
    "    # get comment data\n",
    "    comments_data = get_comments_in_videos(youtube, video_ids)\n",
    "\n",
    "    # append video data together and comment data toghether\n",
    "    video_df = video_df.append(video_data, ignore_index=True)\n",
    "    comments_df = comments_df.append(comments_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde6042c-60d1-4914-99fb-d28eecc7ba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584d23f1-4da1-482d-9140-b31ea222b6ac",
   "metadata": {},
   "source": [
    "Let's take a look at the `comment_df` as well. We only get 3,743 comments in total due to the fact that we limited to 10 first comments on the video to avoid exceeding the Youtube API quota limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571744e5-3412-4e4d-b5dd-4a2fc6fd72e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "comments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda95a32-453a-4726-a6e2-12f6c4aa8bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write video data to CSV file for future references\n",
    "video_df.to_csv('video_data_top10_channels.csv')\n",
    "comments_df.to_csv('comments_data_top10_channels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92abf7a3-e7a5-4318-92a1-86374987a2bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preprocessing & Feature engineering\n",
    "\n",
    "To be able to make use of the data for analysis, we need to perform a few pre-processing steps. Firstly, I would like reformat some columns, especially the date and time columns such as \"pushlishedAt\" and \"duration\". In addition, I also think it is necessary to enrich the data with some new features that might be useful for understanding the videos' characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1480633c-30e4-4cea-9dff-fd70e16f499f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Check for empty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9168616-174d-45ac-8803-633fd2055db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d989df23-12e0-4109-82a5-6fc3f29b504f",
   "metadata": {},
   "source": [
    "There's no strange dates in the publish date column, videos were published between 2013 and 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fe7909-dca9-4a4f-8430-9c188e08bee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_df.publishedAt.sort_values().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b75398-a0be-4f48-b635-d7ae57bc733c",
   "metadata": {},
   "source": [
    "Next, we need to check if the data type of the columns are correct. I have checked the data types and indeed some count columns such as view count and comment count are currently not in correct data type. In this step, we convert these count columns into integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c5aa85-b1f4-451e-bc16-07f7c23bb18e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = ['viewCount', 'likeCount', 'favoriteCount', 'commentCount']\n",
    "video_df[cols] = video_df[cols].apply(pd.to_numeric, errors='coerce', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4874ec6a-6660-46d9-8a3c-3ec6ad5fd9a5",
   "metadata": {},
   "source": [
    "### Enriching data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8e4d5f-0d86-4a93-aa86-633bf5fc974f",
   "metadata": {},
   "source": [
    "I want to enrich the data for further analyses, for example:\n",
    "\n",
    "- create published date column with another column showing the day in the week the video was published, which will be useful for later analysis.\n",
    "\n",
    "- convert video duration to seconds instead of the current default string format\n",
    "\n",
    "- calculate number of tags for each video\n",
    "\n",
    "- calculate comments and likes per 1000 view ratio\n",
    "\n",
    "- calculate title character length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c67380c-d2cd-4447-ad7b-1f5f700520d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create publish day (in the week) column\n",
    "video_df['publishedAt'] =  video_df['publishedAt'].apply(lambda x: parser.parse(x)) \n",
    "video_df['pushblishDayName'] = video_df['publishedAt'].apply(lambda x: x.strftime(\"%A\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd980e2c-f3f4-49c9-b0c4-9a6dac08b7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert duration to seconds\n",
    "video_df['durationSecs'] = video_df['duration'].apply(lambda x: isodate.parse_duration(x))\n",
    "video_df['durationSecs'] = video_df['durationSecs'].astype('timedelta64[s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a271eda-3417-476f-ab75-b769173a76e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add number of tags\n",
    "video_df['tagsCount'] = video_df['tags'].apply(lambda x: 0 if x is None else len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e994d2df-c812-4cc5-a7cb-df1df19b8355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments and likes per 1000 view ratio\n",
    "video_df['likeRatio'] = video_df['likeCount']/ video_df['viewCount'] * 1000\n",
    "video_df['commentRatio'] = video_df['commentCount']/ video_df['viewCount'] * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4ecd96-ad0b-498a-97a7-364286fa7c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title character length\n",
    "video_df['titleLength'] = video_df['title'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f842b3df-ae90-443f-96f4-a7d495616644",
   "metadata": {},
   "source": [
    "Let's look at the video dataset at this point to see if everything went well. It looks good - now we will proceed to exploratory analysis part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034765b0-b2eb-4709-997d-95650aabf167",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b98a1a9-0239-48ff-b843-2d752797e690",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exploratory analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ecdda0-6cbf-4c4c-93bd-f8dead3fd374",
   "metadata": {},
   "source": [
    "### Views distribution per channel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2539ddb5-95ab-4cc7-8d0f-657f37e37d46",
   "metadata": {},
   "source": [
    "With the video statistics for all channel, now we can see how the views are distributed per channel. Some channels might have a lot of views on one of their videos and the rest do not receive many views. Other channels might have more evenly distribution views per video. It can be observed that Corey Schafer, sentdex and Luke Barousse have quite large variance in their views, suggesting that they have a few viral videos. Alex The Analyst, Krish Naik and Data Science Dojo have less views overall but the views are more consistent across videos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e5d670-1df4-402a-a95d-b8278f0e61f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (18, 6)\n",
    "sns.violinplot(video_df['channelTitle'], video_df['viewCount'], palette = 'pastel')\n",
    "plt.title('Views per channel', fontsize = 14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b486a3a7-8cee-4217-8cbc-e6a97e157479",
   "metadata": {},
   "source": [
    "### Does the number of likes and comments matter for a video to get more views?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1938911-360f-45b5-9a84-d1132519d556",
   "metadata": {},
   "source": [
    "Firstly, I would like to check if comments and likes do correlate with how many views a video would get. In the plots below, it can be observed that the number of views and number of comments/ likes strongly correlated with each other. The number of likes seems to suggest stronger correlation than the number of comments. However, this is expected as the more people watching a video, the more likely this video will get comments and likes. To correct for this factor, we will plot these relationships again using the comments per 1000 view and likes per 1000 view ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cddc4e-15d9-4361-b66d-97e25d50f564",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax =plt.subplots(1,2)\n",
    "sns.scatterplot(data = video_df, x = \"commentCount\", y = \"viewCount\", ax=ax[0])\n",
    "sns.scatterplot(data = video_df, x = \"likeCount\", y = \"viewCount\", ax=ax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e6bda8-f68b-43b3-ab29-9f97e0f9cb5f",
   "metadata": {},
   "source": [
    "Now we will take a look at the correlation if we look at the comment ratio and like ratio instead of the absolute number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8dd9db-459c-4024-af51-f7446fa1a18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax =plt.subplots(1,2)\n",
    "sns.scatterplot(data = video_df, x = \"commentRatio\", y = \"viewCount\", ax=ax[0])\n",
    "sns.scatterplot(data = video_df, x = \"likeRatio\", y = \"viewCount\", ax=ax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a757b7e0-5b10-4c04-b68f-13a823366d31",
   "metadata": {},
   "source": [
    "After correcting for the absolute number of views, it turns out that the correlation is much less clear. The comment-view relationship seems to completely disappear: a lot of videos have millions of views and very few comments, while some vides have very few views have better interaction. However, it is understandable that comments take more effort than views and likes, and normally comments would die off when the video gets older.\n",
    "\n",
    "As for like-view relatioship, we can still see some positive correlation between views and like ratio (though very subtle), which means that the more views a video has, the more people would hit the like button! This seems to support the idea of social proof, which means that people tend to like better the products that are already liked by many other people."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b32207-773c-4173-af24-05c6e6e54086",
   "metadata": {},
   "source": [
    "#### Does the video duration matter for views and interaction (likes/ comments)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea36f48-8886-467c-af24-e106ff3a5506",
   "metadata": {},
   "source": [
    "As can be seen in the histogram below, most videos are between 300 to 1200 seconds, which is about 5 to 20 minutes. Here I have to limit the duration to 10,000 because of some really long videos (potentially streaming videos). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa2aedf-deb4-4361-a04d-2f58fadc117b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=video_df[video_df['durationSecs'] < 10000], x=\"durationSecs\", bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775ddd0b-9291-49c6-a346-3b2ba49bfc9b",
   "metadata": {},
   "source": [
    "Now we plot the duration against comment count and like count. It can be seen that actually shorter videos tend to get more likes and comments than very long videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ebab9e-9a1d-433c-8f42-724bedc0218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax =plt.subplots(1,2)\n",
    "sns.scatterplot(data = video_df, x = \"durationSecs\", y = \"commentCount\", ax=ax[0])\n",
    "sns.scatterplot(data = video_df, x = \"durationSecs\", y = \"likeCount\", ax=ax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6572cae4-4569-428a-af43-f3b7723feda4",
   "metadata": {},
   "source": [
    "### Does title length matter for views?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9374c48f-6429-4805-a4c8-1af24ef48ed0",
   "metadata": {},
   "source": [
    "There is no clear relationship between title length and views as seen the scatterplot below, but most-viewed videos tend to have average title length of 30-70 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fa3602-3932-4ae5-acaf-ade0541988cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data = video_df, x = \"titleLength\", y = \"viewCount\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2df32b2-06bb-4ba9-9007-2225330e16d9",
   "metadata": {},
   "source": [
    "### Wordcloud for words in title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3cf29e-7145-41ad-8e47-e64ad44a2207",
   "metadata": {},
   "source": [
    "As I'm interested to see what the creators are making videos about and which terms most frequently appear in their video titles, I will create a wordcloud for the most common words. We first need to remove the stopwords such as \"you\", \"I\", \"the\", etc. which do note contribute a lot to the meaning of the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5ec091-9480-4354-b7df-0f12877b385e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "video_df['title_no_stopwords'] = video_df['title'].apply(lambda x: [item for item in str(x).split() if item not in stop_words])\n",
    "\n",
    "all_words = list([a for b in video_df['title_no_stopwords'].tolist() for a in b])\n",
    "all_words_str = ' '.join(all_words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd4825e-2b5e-4960-be24-e1537a738254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cloud(wordcloud):\n",
    "    plt.figure(figsize=(30, 20))\n",
    "    plt.imshow(wordcloud) \n",
    "    plt.axis(\"off\");\n",
    "\n",
    "wordcloud = WordCloud(width = 2000, height = 1000, random_state=1, background_color='black', \n",
    "                      colormap='viridis', collocations=False).generate(all_words_str)\n",
    "plot_cloud(wordcloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb275665-6821-4293-8a05-ba932d2e3450",
   "metadata": {},
   "source": [
    "It can be seen that most common words are Data, Python, Tutorial, Science,  Projects, Analysis, Programming, Learning, which is very expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2190d1-8224-413f-a057-b1782e82b9c0",
   "metadata": {},
   "source": [
    "### Number of tags vs views"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a134fe4-83ff-4c59-b257-8b5aa88e7bc0",
   "metadata": {},
   "source": [
    "It seems that most videos have between 5 and 30 tags. The relationship between number of tags and view count is not clearly seen, but too few tags or too many tags do seem to correlate with fewer views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a632ec-c7ec-49b9-b9ff-1801220b2e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data = video_df, x = \"tagsCount\", y = \"viewCount\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e29f5b0-99e4-448a-9405-2f011b0743a8",
   "metadata": {},
   "source": [
    "### Which day in the week are most videos uploaded?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254897ef-0268-4a06-af94-c3da558fe4ab",
   "metadata": {},
   "source": [
    "It's interesting to see that more videos are uploaded on Mondays and Fridays. Fewer videos are uploaded during the weekend. This could be because of the nature of the niche that is more geared towards tutorials and heavy materials, which is not suitable for weekends' consumption. But it could also just means that most creators work on their videos during the weekend or during the week and upload them beginning of the week or Friday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ce745c-e30f-4177-84dc-4b43c407815e",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_df = pd.DataFrame(video_df['pushblishDayName'].value_counts())\n",
    "weekdays = [ 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "day_df = day_df.reindex(weekdays)\n",
    "ax = day_df.reset_index().plot.bar(x='index', y='pushblishDayName', rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11325ab3-d357-48a7-84fe-72418d897229",
   "metadata": {},
   "source": [
    "### Wordcloud for video comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968eac77-6ff4-4800-a8ce-8eca07b1237c",
   "metadata": {},
   "source": [
    "We can see what are the frequently-mentioned words in the video comments. I will do this by visualizing the keywords in a wordcloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c762a578-22d1-4bb4-a9cc-8688ed38d418",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "comments_df['comments_no_stopwords'] = comments_df['comments'].apply(lambda x: [item for item in str(x).split() if item not in stop_words])\n",
    "\n",
    "all_words = list([a for b in comments_df['comments_no_stopwords'].tolist() for a in b])\n",
    "all_words_str = ' '.join(all_words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4970dc62-5855-47b0-bd26-892dd69fc765",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width = 2000, height = 1000, random_state=1, background_color='black', \n",
    "                      colormap='viridis', collocations=False).generate(all_words_str)\n",
    "plot_cloud(wordcloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca5dcdd-1aa2-4374-b6e2-0a90a398efb6",
   "metadata": {},
   "source": [
    "We can see that next to the obvious words such as \"video\", \"data\", the most frequent words are quite positive, such as \"thank\", \"great\", \"good\", \"awesome\", \"love\". A lot of comments also request something with the word \"please\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68308be-d2c0-4524-82e0-04cff500fdc0",
   "metadata": {},
   "source": [
    "## Conclusions and future research ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b21d11c-900a-42e0-978f-34582f33f18d",
   "metadata": {
    "tags": []
   },
   "source": [
    "In this project, we have explored the video data of the 9 most popular Data science/ Data analyst channels and revealed many interesting findings for anyone who are starting out with a Youtube channel in data science or another topic:\n",
    "\n",
    "- The more likes and comments a video has, the more views the video gets (it is not guaranteed that this is a causal relationship, it is simply a correlation and can work both way). Likes seem to be a better indicator for interaction than comments and the number of likes seem to follow the \"social proof\", which means the more views the video has, the more people will like it.\n",
    "\n",
    "- Most videos have between 5 and 30 tags.\n",
    "\n",
    "- Most-viewed videos tend to have average title length of 30-70 characters. Too short or too long titles seem to harm viewership.\n",
    "\n",
    "- Videos are usually uploaded on Mondays and Fridays. Weekends and Sunday in particular is not a popular time for posting new videos.\n",
    "\n",
    "- Comments on videos are generally positive, we noticed a lot \"please\" words, suggesting potential market gaps in content that could be filled. \n",
    "\n",
    "**Project limitation:**\n",
    "\n",
    "The findings should also be taken with a grain of salt for a number of reasons:\n",
    "\n",
    "- The number of videos is quite small (the dataset has only ~3,700 videos)\n",
    "\n",
    "- I have only considered the first 10 comments on each video, which might not be representative for all comments\n",
    "\n",
    "- There are many other factors that haven't been taken into the analysis, including the marketing strategy of the creators and many random effects that would affect how successful a video is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40477a8-240a-4bf7-b752-89177a763237",
   "metadata": {},
   "source": [
    "**Ideas for future research:**\n",
    "\n",
    "To expand and build on this research project, one can:\n",
    "\n",
    "- Expand the dataset to also smaller channels in data science niche\n",
    "\n",
    "- Do sentiment analysis on the comments and find out which videos get more positive comments and which videos get less positive comments\n",
    "\n",
    "- Do market research by analyzing questions in the comment threads and identifying common questions/ market gaps which could potentially filled\n",
    "\n",
    "- Conduct this research for other niches (e.g. vlogs or beauty channels), to compare different niches with each other to see the different patterns in viewership and video characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9707add-cfaf-491a-859c-9137b765ae84",
   "metadata": {},
   "source": [
    "### References/ Resources used:\n",
    "\n",
    "[1] Youtube API. Avaiable at https://developers.google.com/youtube/v3\n",
    "\n",
    "[2] Converting video durations to time function. https://stackoverflow.com/questions/15596753/how-do-i-get-video-durations-with-youtube-api-version-3\n",
    "\n",
    "[3] P. Covington, J. Adams, E. Sargin. The youtube video recommendation system. In Proceedings of the Fourth ACM Conference on Recommender Systems, RecSys '16, pages 191-198, New York, NY, USA, 2016. ACM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dceddedd-f561-44c5-be35-5add6ad0ed60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
