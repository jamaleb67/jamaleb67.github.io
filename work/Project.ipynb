{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [Youtube/GDP](Top)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=https://i.imgur.com/ACFFpv2.png width=1500 class=\"center\">\n",
    "<h1 align=\"center\">Top Youtubers effecting GDP between 2019 - 2022??</h1>\n",
    "    \n",
    "    In today's world, the internet has become an integral part of our lives. With the rise of online platforms such as YouTube, it has become easier than ever for people to access information and entertainment from all over the world. At the same time, Gross Domestic Product (GDP) remains one of the most widely used indicators of economic performance. In this project, we aim to explore the relationship between these two seemingly unrelated topics: GDP and YouTube. By analyzing data on GDP and YouTube usage patterns, we hope to gain insights into how these two factors are connected and what implications this may have on our understanding of the modern world.\n",
    "\n",
    "The objective of this project is to analyze the relationship between GDP and YouTube usage patterns. We will use data on GDP and YouTube usage patterns to gain insights into how these two factors are connected and what implications this may have on our understanding of the modern world.\n",
    "\n",
    "Our goal is to answer the following questions:\n",
    "\n",
    "- What are the the top Youtubers in countries around the globe?\n",
    "- What is the Top GDP countries, and what is there growth during COVID?\n",
    "- Is there a correlation between Top Youtubers and selected GDP Nations?\n",
    "- What is statistical corelations can be made?\n",
    "\n",
    "To answer these questions, we will use Python and its data analysis libraries, such as Pandas and Matplotlib. We will start by importing the dataset and cleaning the data, followed by exploratory data analysis and visualization.\n",
    "\n",
    "I will be using the following datasets: \n",
    "- [Top Youtubers](https://www.kaggle.com/mdhrumil/top-5000-youtube-channels-data-from-socialblade)\n",
    "- [GDP](https://www.kaggle.com/fernandol/countries-of-the-world)\n",
    "\n",
    "APIs:\n",
    "- [YouTube API](https://developers.google.com/youtube/v3/docs/channels/list)\n",
    "- [Google API](https://console.cloud.google.com/apis/library/youtube.googleapis.com)\n",
    "\n",
    "\n",
    "\n",
    "# Table of contents <a class='anchor' id='top'>\n",
    "- [Introduction](#Introduction)\n",
    "- [Import libraries](#import)\n",
    "- [Load data](#load_data)\n",
    "- [GDP Analysis](#gdpproject)\n",
    "- [Bar chart](#bar_chart)\n",
    "- [GDP Conclusion](#geo)\n",
    "- [YouTube Analysis](#Analysis)\n",
    "- [Youtube API](#YouTube)\n",
    "- [Conclusion](#Conclusion)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction  <a class='anchor' id='Introduction'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries <a class='anchor' id='import'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: isodate in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.6.1)\n",
      "Requirement already satisfied: six in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from isodate) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: google-auth in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.1.0)\n",
      "Requirement already satisfied: google-auth-httplib2 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.1.1)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.106.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-auth) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-auth) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-auth) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-auth-oauthlib) (1.3.1)\n",
      "Requirement already satisfied: httplib2>=0.19.0 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-auth-httplib2) (0.22.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-api-python-client) (2.12.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.61.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (4.25.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.31.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httplib2>=0.19.0->google-auth-httplib2) (3.1.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pyasn1-modules>=0.2.1->google-auth) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: wordcloud in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.9.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from wordcloud) (1.26.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from wordcloud) (10.1.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from wordcloud) (3.8.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->wordcloud) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->wordcloud) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->wordcloud) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->wordcloud) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->wordcloud) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->wordcloud) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.8.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: click in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: wbgapi in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.0.12)\n",
      "Requirement already satisfied: requests in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from wbgapi) (2.31.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from wbgapi) (6.0.1)\n",
      "Requirement already satisfied: tabulate in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from wbgapi) (0.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->wbgapi) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->wbgapi) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->wbgapi) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->wbgapi) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: bar_chart_race in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.1.0)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from bar_chart_race) (2.1.2)\n",
      "Requirement already satisfied: matplotlib>=3.1 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from bar_chart_race) (3.8.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=3.1->bar_chart_race) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=3.1->bar_chart_race) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=3.1->bar_chart_race) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=3.1->bar_chart_race) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=3.1->bar_chart_race) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=3.1->bar_chart_race) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=3.1->bar_chart_race) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=3.1->bar_chart_race) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=3.1->bar_chart_race) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=0.24->bar_chart_race) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=0.24->bar_chart_race) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.7->matplotlib>=3.1->bar_chart_race) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: plotly in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (5.18.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from plotly) (8.2.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from plotly) (23.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.1.2)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (1.26.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.8.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: seaborn in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from seaborn) (1.26.1)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from seaborn) (2.1.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.3 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from seaborn) (3.8.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.2->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.3->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.26.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: requests in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scipy in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.11.3)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scipy) (1.26.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: sklearn in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.0.post10)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: statsmodels in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.14.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy>=1.18 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from statsmodels) (1.26.1)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.4 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from statsmodels) (1.11.3)\n",
      "Requirement already satisfied: pandas>=1.0 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from statsmodels) (2.1.2)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from statsmodels) (0.5.3)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from statsmodels) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.0->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.0->statsmodels) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.0->statsmodels) (2023.3)\n",
      "Requirement already satisfied: six in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from patsy>=0.5.2->statsmodels) (1.16.0)\n",
      "Requirement already satisfied: xgboost in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.0.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from xgboost) (1.26.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from xgboost) (1.11.3)\n",
      "Requirement already satisfied: lightgbm in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.1.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from lightgbm) (1.26.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from lightgbm) (1.11.3)\n",
      "Requirement already satisfied: catboost in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.2.2)\n",
      "Requirement already satisfied: graphviz in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from catboost) (3.8.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from catboost) (1.26.1)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from catboost) (2.1.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from catboost) (1.11.3)\n",
      "Requirement already satisfied: plotly in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from catboost) (5.18.0)\n",
      "Requirement already satisfied: six in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=0.24->catboost) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->catboost) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->catboost) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->catboost) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->catboost) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->catboost) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->catboost) (3.1.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from plotly->catboost) (8.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: bar_chart_race in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.1.0)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from bar_chart_race) (2.1.2)\n",
      "Requirement already satisfied: matplotlib>=3.1 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from bar_chart_race) (3.8.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=3.1->bar_chart_race) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=3.1->bar_chart_race) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=3.1->bar_chart_race) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=3.1->bar_chart_race) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=3.1->bar_chart_race) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=3.1->bar_chart_race) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=3.1->bar_chart_race) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=3.1->bar_chart_race) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=3.1->bar_chart_race) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=0.24->bar_chart_race) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=0.24->bar_chart_race) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.7->matplotlib>=3.1->bar_chart_race) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ffmpeg in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.4)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%pip install isodate\n",
    "%pip install google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client\n",
    "%pip install wordcloud\n",
    "%pip install nltk\n",
    "%pip install wbgapi\n",
    "%pip install bar_chart_race\n",
    "%pip install plotly\n",
    "%pip install pandas\n",
    "%pip install matplotlib\n",
    "%pip install seaborn\n",
    "%pip install numpy\n",
    "%pip install requests\n",
    "%pip install scipy\n",
    "%pip install sklearn\n",
    "%pip install statsmodels\n",
    "%pip install xgboost\n",
    "%pip install lightgbm\n",
    "%pip install catboost\n",
    "%pip install bar_chart_race\n",
    "%pip install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.26.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.26.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\jamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Libraries for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil import parser\n",
    "import isodate\n",
    "\n",
    "# Data visualization libraries\n",
    "%pip install scikit-learn\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import pyplot as pyplot\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "sns.set(style=\"darkgrid\", color_codes=True)\n",
    "%pip install scikit-learn\n",
    "\n",
    "# Google API\n",
    "from googleapiclient.discovery import build\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jamal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jamal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# NLP libraries\n",
    "import collections\n",
    "import itertools\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from wordcloud import WordCloud\n",
    "from wordcloud import ImageColorGenerator\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <b><u><span style=\"font-size: 24px\">\n",
    "  GDP Analysis from 2019 - 2020<a class='anchor' id='gdpproject'></span></u></b><br>\n",
    "</p>\n",
    "\n",
    "### Load data <a class='anchor' id='load_data'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'GDP by Country 1999-2022.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jamal\\jamaleb67.github.io\\jamaleb67.github.io\\work\\Project.ipynb Cell 9\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jamal/jamaleb67.github.io/jamaleb67.github.io/work/Project.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m pd\u001b[39m.\u001b[39mset_option(\u001b[39m'\u001b[39m\u001b[39mdisplay.max_rows\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jamal/jamaleb67.github.io/jamaleb67.github.io/work/Project.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m#load data\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jamal/jamaleb67.github.io/jamaleb67.github.io/work/Project.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mGDP by Country 1999-2022.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, decimal \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jamal/jamaleb67.github.io/jamaleb67.github.io/work/Project.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mreplace({\u001b[39m'\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m'\u001b[39m :\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m}, regex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jamal/jamaleb67.github.io/jamaleb67.github.io/work/Project.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mreplace({\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m :\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m}, regex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'GDP by Country 1999-2022.csv'"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "#load data\n",
    "data = pd.read_csv('GDP by Country 1999-2022.csv', decimal = ',')\n",
    "\n",
    "data = data.replace({'\\\"' :''}, regex=True)\n",
    "data = data.replace({',' :''}, regex=True)\n",
    "#display(data)\n",
    "\n",
    "data = data.astype({'1999' : 'float', '2022' : 'float'})\n",
    "\n",
    "#observe data\n",
    "data.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar Chart for Top 10 GDP countries and for targeted group <a class='anchor' id='bar_chart'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 10 GDP in 2022\n",
    "top_10_GDP_2022 = data.sort_values('2022', ascending = False).head(10)\n",
    "fig, ax = pyplot.subplots(figsize = (16, 6))\n",
    "sns.barplot(x = 'Country', y = '2022', data = top_10_GDP_2022, palette = 'Set1')\n",
    "ax.set_xlabel(ax.get_xlabel(), labelpad= 15)\n",
    "ax.set_ylabel('Gross Domestic Product', labelpad= 30)\n",
    "ax.xaxis.label.set_fontsize(16)\n",
    "ax.yaxis.label.set_fontsize(16)\n",
    "pyplot.xticks(rotation = 90)\n",
    "pyplot.title('Top GDP producing Countries in 2022', fontsize = 20)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2022 GDP for germany, south korea, UK, US, Mexico, japan and india\n",
    "\n",
    "Countries = data[data[\"Country\"].isin(['Germany', 'South Korea', 'United Kingdom', 'United States', 'Mexico', 'Japan', 'India'])] \n",
    "Countries_GDP_2022 = Countries.sort_values('2022', ascending = False)\n",
    "\n",
    "display(Countries_GDP_2022)\n",
    "\n",
    "fig, ax = pyplot.subplots(figsize = (16, 6))\n",
    "sns.barplot(x = 'Country', y = '2022', data = Countries_GDP_2022, legend=False, palette = 'Set1')\n",
    "ax.set_xlabel(ax.get_xlabel(), labelpad= 15)\n",
    "ax.set_ylabel('GDP by Country 2022', labelpad= 30)\n",
    "ax.xaxis.label.set_fontsize(16)\n",
    "ax.yaxis.label.set_fontsize(16)\n",
    "pyplot.xticks(rotation = 45)\n",
    "pyplot.title('2022 GDP for Germany, South korea, UK, US, Mexico, Japan and India', fontsize = 20)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Gross Domestic product average for 2019 - 2020 <a class='anchor' id='19-20'>\n",
    "+ Germany, South Korea UK, US, Mexico, Japan and India"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average GDP between 2018-2022 for germany, south korea, UK, US, Mexico, japan and india\n",
    "Countries = data[data[\"Country\"].isin(['Germany', 'South Korea', 'United Kingdom', 'United States', 'Mexico', 'Japan', 'India'])] \n",
    "Countries_GDP_2022 = Countries[['Country', '2018', '2019', '2020', '2021', '2022']]\n",
    "\n",
    "fig, ax = pyplot.subplots(figsize = (16, 6))\n",
    "new_data = pd.melt(Countries_GDP_2022, id_vars = ['Country'], value_vars = ['2018', '2019', '2020', '2021', '2022'], var_name = 'Year', value_name = 'GDP')\n",
    "\n",
    "new_data = new_data.astype({'Country' : 'str'})\n",
    "new_data = new_data.astype({'GDP' : 'float'})\n",
    "\n",
    "\n",
    "display(new_data)\n",
    "\n",
    "sns.pointplot(data = new_data, x = 'Year', y = 'GDP', hue = 'Country', ax = ax, palette = 'nipy_spectral')\n",
    "\n",
    "ax.set_xlabel(ax.get_xlabel(), labelpad= 15)\n",
    "ax.set_ylabel('Average GDP by Country 2018-2022', labelpad= 30)\n",
    "ax.xaxis.label.set_fontsize(16)\n",
    "ax.yaxis.label.set_fontsize(16)\n",
    "pyplot.title('Average GDP between 2018-2022', fontsize = 20)\n",
    "pyplot.show()\n",
    "\n",
    "#sort_new_data = new_data.sort_values('GDP', ascending = True)\n",
    "#sort_new_data = resort_new_data.sort_values('GDP', ascending = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#sort_new_data = new_data.sort_values('GDP', ascending = True)\n",
    "#sort_new_data = resort_new_data.sort_values('GDP', ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average GDP between 2018-2022 for germany, south korea, UK, Mexico, japan and india ***Without the US because it made the graph look bad***\n",
    "Countries = data[data[\"Country\"].isin(['Germany', 'South Korea', 'United Kingdom', 'Mexico', 'Japan', 'India'])] \n",
    "Countries_GDP_2022 = Countries[['Country', '2018', '2019', '2020', '2021', '2022']]\n",
    "\n",
    "fig, ax = pyplot.subplots(figsize = (16, 8))\n",
    "new_data = pd.melt(Countries_GDP_2022, id_vars = ['Country'], value_vars = ['2018', '2019', '2020', '2021', '2022'], var_name = 'Year', value_name = 'GDP')\n",
    "\n",
    "new_data = new_data.astype({'Country' : 'str'})\n",
    "new_data = new_data.astype({'GDP' : 'float'})\n",
    "\n",
    "\n",
    "\n",
    "display(new_data)\n",
    "\n",
    "sns.pointplot(data = new_data, x = 'Year', y = 'GDP', hue = 'Country', ax = ax, palette = 'nipy_spectral')\n",
    "\n",
    "ax.set_xlabel(ax.get_xlabel(), labelpad= 15)\n",
    "ax.set_ylabel('Average GDP by Country 2018-2022', labelpad= 30)\n",
    "ax.xaxis.label.set_fontsize(16)\n",
    "ax.yaxis.label.set_fontsize(16)\n",
    "pyplot.title('Average GDP between 2018-2022 without the U.S.', fontsize = 20)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HalfTime <a class='anchor' id='geo'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Region Code: You must provide a two-letter ISO 31661 country code \n",
    "* (e.g., US for the United States) to specify the region for which you want to find the top 10 YouTube channels.\n",
    "* Replace 'YOUR_REGION_CODE' in the code with the desired region code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ?WBGAPI World Bank Top 20 Countries by GDP?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import wbgapi as wb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(wb)\n",
    "wb.source.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##wb.economy.info(db=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## WORKING CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "class Coder(dict):\n",
    "    '''Class returned by coder if passed a list of terms\n",
    "    '''\n",
    "\n",
    "    def __repr__(self):\n",
    "        rows = self._coder_report()\n",
    "        columns = rows.pop(0)\n",
    "        return tabulate(rows, tablefmt='simple', headers=columns)\n",
    "\n",
    "def coder_report(economies):\n",
    "\n",
    "    global _coder_names\n",
    "\n",
    "    rows = [('ORIGINAL NAME', 'WBG NAME', 'ISO_CODE')]\n",
    "    for k,v in economies.items():\n",
    "        if v:\n",
    "            wb_name = _coder_names.get(v, '')\n",
    "        else:\n",
    "            wb_name = ''\n",
    "\n",
    "        rows.append((k, wb_name, v))\n",
    "\n",
    "    output = []\n",
    "    for row in rows:\n",
    "        output.append([row[0], row[1], row[2]])\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "def plot_anim_funct():\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.set_xlim((0, 2))\n",
    "    ax.set_ylim((-2, 2))\n",
    "\n",
    "    line, = ax.plot([], [], lw=2)\n",
    "\n",
    "    def init():\n",
    "        line.set_data([], [])\n",
    "        return (line,)\n",
    "\n",
    "    def animate(i):\n",
    "        x = np.linspace(0, 2, 1000)\n",
    "        y = np.sin(2 * np.pi * (x - 0.01 * i))\n",
    "        line.set_data(x, y)\n",
    "        return (line,)\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                                   frames=100, interval=20, \n",
    "                                   blit=True)\n",
    "\n",
    "\n",
    "    display(HTML(anim.to_jshtml()))\n",
    "\n",
    "plot_anim_funct()\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"GDP by Country 1999-2022.csv\", sep=',', header=0, thousands=\",\")\n",
    "df.set_index(\"Country\", inplace=True)\n",
    "df = df.T\n",
    "print(f\"Dataframe has {df.shape[0]} rows and {df.shape[1]} columns\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML, display\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import base64\n",
    "from io import BytesIO, TextIOWrapper\n",
    "from pathlib import Path\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "from matplotlib import rcParams\n",
    "from matplotlib import animation\n",
    "\n",
    "class FuncAnimation(animation.FuncAnimation):\n",
    "\n",
    "    def to_html5_video(self, embed_limit=None, savefig_kwargs=None):\n",
    "        \"\"\"\n",
    "        Convert the animation to an HTML5 ``<video>`` tag.\n",
    "\n",
    "        This saves the animation as an h264 video, encoded in base64\n",
    "        directly into the HTML5 video tag. This respects the rc parameters\n",
    "        for the writer as well as the bitrate. This also makes use of the\n",
    "        ``interval`` to control the speed, and uses the ``repeat``\n",
    "        parameter to decide whether to loop.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        embed_limit : float, optional\n",
    "            Limit, in MB, of the returned animation. No animation is created\n",
    "            if the limit is exceeded.\n",
    "            Defaults to :rc:`animation.embed_limit` = 20.0.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        video_tag : str\n",
    "            An HTML5 video tag with the animation embedded as base64 encoded\n",
    "            h264 video.\n",
    "            If the *embed_limit* is exceeded, this returns the string\n",
    "            \"Video too large to embed.\"\n",
    "        \"\"\"\n",
    "        VIDEO_TAG = r'''<video {size} {options}>\n",
    "  <source type=\"video/mp4\" src=\"data:video/mp4;base64,{video}\">\n",
    "  Your browser does not support the video tag.\n",
    "</video>'''\n",
    "        # Cache the rendering of the video as HTML\n",
    "        if not hasattr(self, '_base64_video'):\n",
    "            # Save embed limit, which is given in MB\n",
    "            if embed_limit is None:\n",
    "                embed_limit = rcParams['animation.embed_limit']\n",
    "\n",
    "            # Convert from MB to bytes\n",
    "            embed_limit *= 1024 * 1024\n",
    "\n",
    "            # Can't open a NamedTemporaryFile twice on Windows, so use a\n",
    "            # TemporaryDirectory instead.\n",
    "            with TemporaryDirectory() as tmpdir:\n",
    "                path = Path(tmpdir, \"temp.m4v\")\n",
    "                # We create a writer manually so that we can get the\n",
    "                # appropriate size for the tag\n",
    "                Writer = animation.writers[rcParams['animation.writer']]\n",
    "                writer = Writer(codec='h264',\n",
    "                                bitrate=rcParams['animation.bitrate'],\n",
    "                                fps=1000. / self._interval)\n",
    "                self.save(str(path), writer=writer, savefig_kwargs=savefig_kwargs)\n",
    "                # Now open and base64 encode.\n",
    "                vid64 = base64.encodebytes(path.read_bytes())\n",
    "\n",
    "            vid_len = len(vid64)\n",
    "            if vid_len >= embed_limit:\n",
    "                _log.warning(\n",
    "                    \"Animation movie is %s bytes, exceeding the limit of %s. \"\n",
    "                    \"If you're sure you want a large animation embedded, set \"\n",
    "                    \"the animation.embed_limit rc parameter to a larger value \"\n",
    "                    \"(in MB).\", vid_len, embed_limit)\n",
    "            else:\n",
    "                self._base64_video = vid64.decode('ascii')\n",
    "                self._video_size = 'width=\"{}\" height=\"{}\"'.format(\n",
    "                        *writer.frame_size)\n",
    "\n",
    "        # If we exceeded the size, this attribute won't exist\n",
    "        if hasattr(self, '_base64_video'):\n",
    "            # Default HTML5 options are to autoplay and display video controls\n",
    "            options = ['controls', 'autoplay']\n",
    "\n",
    "            # If we're set to repeat, make it loop\n",
    "            if hasattr(self, 'repeat') and self.repeat:\n",
    "                options.append('loop')\n",
    "\n",
    "            return VIDEO_TAG.format(video=self._base64_video,\n",
    "                                    size=self._video_size,\n",
    "                                    options=' '.join(options))\n",
    "        else:\n",
    "            return 'Video too large to embed.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import bar_chart_race as bcr\n",
    "import warnings\n",
    "import matplotlib.animation\n",
    "import imageio_ffmpeg as ffmpeg\n",
    "\n",
    "---\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "bcr.bar_chart_race(df=df,\n",
    "                   n_bars=10,\n",
    "                  orientation=\"h\",\n",
    "                  title=\"Gross Domestic Product (billions USD)\",\n",
    "                  cmap=\"tab20b\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import bar_chart_race as bcr\n",
    "\n",
    "create a dataframe with sample data\n",
    "set the index to 'Year'\n",
    "df.set_index('Year', inplace=True)\n",
    "\n",
    "create the bar chart race\n",
    "bcr.bar_chart_race(df=df, n_bars=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Youtube Exploratory Data Analysis <a class='anchor' id='Analysis'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare for Youtube API pull and research of top YouTubers, we need to first obtain the API key from Google Cloud Console. Once we have the API key, we can use it to authenticate our requests to the Youtube API. We can then use the API to pull data on top YouTubers, such as their subscriber count, view count, and video count. We can use this data to perform exploratory data analysis and gain insights into the trends and patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U.S. Top Channels\n",
    "\n",
    "\n",
    "1. Mr. Beasts view-source:https://www.youtube.com/@MrBeast/about\n",
    "* UCX6OQ3DkcsbYNE6H8uQQuVA\n",
    "\n",
    "2. Cocomelon - Nursery Rhymes view-source:https://www.youtube.com/channel/UCbCmjCuTUZos6Inko4u57UQ\n",
    "* UCbCmjCuTUZos6Inko4u57UQ\n",
    "\n",
    "3. Dude Perfect view-source:https://www.youtube.com/channel/UCRijo3ddMTht_IHyNSNXpNQ\n",
    "* UCRijo3ddMTht_IHyNSNXpNQ\n",
    "\n",
    "4.  Kids Diana Show view-source:https://www.youtube.com/channel/UCk8GzjMOrta8yxDcKfylJYw\n",
    "* UCk8GzjMOrta8yxDcKfylJYw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For India, the top two YouTubers are **Bhuvaneshwar Bam** and **Amit Bhadana**. Bhuvaneshwar Bam is the creator of **BB ki Vines**, a comedy channel that features him playing multiple characters. He has more than 20 million subscribers and over 3 billion views. Amit Bhadana is another comedy channel that features slice of life content, relationships, and comedic skits. He has more than 22 million subscribers and over 1.8 billion views. You can visit their YouTube pages here: [BB ki Vines](^1^) and [Amit Bhadana](^2^).\n",
    "\n",
    "- For Japan, the top two YouTubers are **HikakinTV** and **Yuka Kinoshita**. HikakinTV is a channel that features various content such as music, games, challenges, and collaborations with other celebrities. He has more than 8.8 million subscribers and over 6.7 billion views. Yuka Kinoshita is a channel that features her eating large amounts of food in a short time. She has more than 5.6 million subscribers and over 2.4 billion views. You can visit their YouTube pages here: [HikakinTV](^3^) and [Yuka Kinoshita].\n",
    "\n",
    "- For Mexico, the top two YouTubers are **Luisito Comunica** and **Badabun**. Luisito Comunica is a channel that features his travels around the world, exploring different cultures, cuisines, and attractions. He has more than 36 million subscribers and over 4.9 billion views. Badabun is a channel that features various content such as entertainment, news, pranks, and social experiments. He has more than 43 million subscribers and over 14 billion views. You can visit their YouTube pages here: [Luisito Comunica] and [Badabun].\n",
    "\n",
    "- For South Korea, the top two YouTubers are **Boram Tube Vlog** and **Saebyuk Jang**. Boram Tube Vlog is a channel that features a six-year-old girl named Boram and her family doing various activities such as playing with toys, cooking, traveling, and reviewing products. She has more than 26 million subscribers and over 10 billion views. Saebyuk Jang is a channel that features a young boy named Saebyuk and his parents doing various content such as games, challenges, vlogs, and animations. He has more than 23 million subscribers and over 8 billion views. You can visit their YouTube pages here: [Boram Tube Vlog] and [Saebyuk Jang].\n",
    "\n",
    "\n",
    "1) YouTube. https://www.youtube.com/index.\n",
    "2) Top 50 Popular YouTubers in India (2023) - Moneymint. https://moneymint.com/top-youtubers-in-india/.\n",
    "3) List of most-subscribed YouTube channels - Wikipedia. https://en.wikipedia.org/wiki/List_of_most-subscribed_YouTube_channels.\n",
    "#### India Top Channels\n",
    "1.  view-source:\n",
    "*\n",
    "2.   view-source:\n",
    "*\n",
    "\n",
    "#### Japan Top Channels\n",
    "1.  view-source:\n",
    "*\n",
    "2.  view-source:\n",
    "*\n",
    "\n",
    "#### Mexico Top Channels\n",
    "1.  view-source:\n",
    "*\n",
    "2.  view-source:\n",
    "*\n",
    "\n",
    "#### South Korea Top Channels\n",
    "1.  view-source:\n",
    "*\n",
    "2.  view-source:\n",
    "*\n",
    "\n",
    "#### United Kingdom Top Channels\n",
    "1.  view-source:\n",
    "*\n",
    "2.  view-source:\n",
    "*\n",
    "\n",
    "#### Germany Top Channels\n",
    "1.\n",
    "*\n",
    "2.\n",
    "*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YouTube API <a class='anchor' id='YouTube'></center> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data creation with Youtube API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'AIzaSyDs9TExsfc8fDMn4lBRYXZax1vSr0ftsdk'  # Youtube API key Personal \n",
    "\n",
    "channel_ids = ['UCX6OQ3DkcsbYNE6H8uQQuVA', # Mr. Beast US\n",
    "               'UCbCmjCuTUZos6Inko4u57UQ', # Cocomelon US\n",
    "               'UCqwUrj10mAEsqezcItqvwEw', # Bhuvaneshwar Bam IN\n",
    "               'UC_vcKmg67vjMP7ciLnSxSHQ', # Amit Bhadana IN\n",
    "               'UCjp_3PEaOau_nT_3vnqKIvg', # HikakinTV JP\n",
    "               'UC-lHJZR3Gqxm24_Vd_AJ5Yw', # PewDiePie SE\n",
    "               'UCYWOjHweP2V-8kGKmmAmQJQ', # Badabun MX \n",
    "               'UCECJDeK0MNapZbpaOzxrUPA', # Luisito Comunica MX\n",
    "               'UCOmHUn--16B90oW2L6FRR3A', # BLACKPINK\n",
    "              ]\n",
    "\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Function to pull data from Youtube API and create a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_stats(youtube, channel_ids):\n",
    "    \"\"\"\n",
    "    Get channel statistics: title, subscriber count, view count, video count, upload playlist\n",
    "    Params:\n",
    "    \n",
    "    youtube: the build object from googleapiclient.discovery\n",
    "    channels_ids: list of channel IDs\n",
    "    \n",
    "    Returns:\n",
    "    Dataframe containing the channel statistics for all channels in the provided list: title, subscriber count, view count, video count, upload playlist\n",
    "    \n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    request = youtube.channels().list(\n",
    "                part='snippet,contentDetails,statistics',\n",
    "                id=','.join(channel_ids))\n",
    "    response = request.execute() \n",
    "    \n",
    "    for i in range(len(response['items'])):\n",
    "        data = dict(channelName = response['items'][i]['snippet']['title'],\n",
    "                    subscribers = response['items'][i]['statistics']['subscriberCount'],\n",
    "                    views = response['items'][i]['statistics']['viewCount'],\n",
    "                    totalVideos = response['items'][i]['statistics']['videoCount'],\n",
    "                    playlistId = response['items'][i]['contentDetails']['relatedPlaylists']['uploads'])\n",
    "        all_data.append(data)\n",
    "    \n",
    "    return pd.DataFrame(all_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New method to pull data from Youtube API and create a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def get_video_ids(youtube, playlist_id):\n",
    "    \"\"\"\n",
    "    Get list of video IDs of all videos in the given playlist\n",
    "    Params:\n",
    "    \n",
    "    youtube: the build object from googleapiclient.discovery\n",
    "    playlist_id: playlist ID of the channel\n",
    "    \n",
    "    Returns:\n",
    "    List of video IDs of all videos in the playlist\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    request = youtube.playlistItems().list(\n",
    "                part='contentDetails',\n",
    "                playlistId = playlist_id,\n",
    "                maxResults = 50)\n",
    "    response = request.execute()\n",
    "    \n",
    "    video_ids = []\n",
    "\n",
    "        for i in range(len(response['items'])):\n",
    "        video_ids.append(response['items'][i]['contentDetails']['videoId'])\n",
    "        \n",
    "    next_page_token = response.get('nextPageToken')\n",
    "    more_pages = True\n",
    "    \n",
    "    while more_pages:\n",
    "        if next_page_token is None:\n",
    "            more_pages = False\n",
    "        else:\n",
    "            request = youtube.playlistItems().list(\n",
    "                        part='contentDetails',\n",
    "                        playlistId = playlist_id,\n",
    "                        maxResults = 50,\n",
    "                        pageToken = next_page_token)\n",
    "            response = request.execute()\n",
    "    \n",
    "            for i in range(len(response['items'])):\n",
    "                video_ids.append(response['items'][i]['contentDetails']['videoId'])\n",
    "            \n",
    "            next_page_token = response.get('nextPageToken')\n",
    "        \n",
    "    return video_ids\n",
    "def get_comments_in_videos(youtube, video_ids):\n",
    "    \"\"\"\n",
    "    Get the top 10 comments for each provided video ID.\n",
    "    \n",
    "    Parameters:\n",
    "    youtube (googleapiclient.discovery.Resource): The YouTube API resource object.\n",
    "    video_ids (list): List of video IDs.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing video IDs and associated top-level comments in text.\n",
    "    \"\"\"\n",
    "    all_comments = []\n",
    "    for video_id in video_ids:\n",
    "        try:\n",
    "            request = youtube.commentThreads().list(\n",
    "                part=\"snippet\",\n",
    "                videoId=video_id,\n",
    "                maxResults=10  # Fetch only the first 10 comments\n",
    "            )\n",
    "            response = request.execute()\n",
    "            # Process response data and append to all_comments\n",
    "            # ...\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error fetching comments for video {video_id}: {e}\")\n",
    "            continue\n",
    "    return pd.DataFrame(all_comments)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "import pandas as pd\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(filename='youtube_data.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Initialize YouTube API client\n",
    "# Replace 'YOUR_API_KEY' with your actual API key\n",
    "youtube = build('youtube', 'v3', developerKey='AIzaSyDs9TExsfc8fDMn4lBRYXZax1vSr0ftsdk')\n",
    "\n",
    "def get_channel_stats(youtube, channel_ids):\n",
    "    \"\"\"\n",
    "    Get channel statistics: title, subscriber count, view count, video count, upload playlist\n",
    "    Params:\n",
    "    \n",
    "    youtube: the build object from googleapiclient.discovery\n",
    "    channels_ids: list of channel IDs\n",
    "    \n",
    "    Returns:\n",
    "    Dataframe containing the channel statistics for all channels in the provided list: title, subscriber count, view count, video count, upload playlist\n",
    "    \n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    request = youtube.channels().list(\n",
    "                part='snippet,contentDetails,statistics',\n",
    "                id=','.join(channel_ids))\n",
    "    response = request.execute() \n",
    "    \n",
    "    for i in range(len(response['items'])):\n",
    "        data = dict(channelName = response['items'][i]['snippet']['title'],\n",
    "                    subscribers = response['items'][i]['statistics']['subscriberCount'],\n",
    "                    views = response['items'][i]['statistics']['viewCount'],\n",
    "                    totalVideos = response['items'][i]['statistics']['videoCount'],\n",
    "                    playlistId = response['items'][i]['contentDetails']['relatedPlaylists']['uploads'])\n",
    "        all_data.append(data)\n",
    "    \n",
    "    return pd.DataFrame(all_data)\n",
    "\n",
    "\n",
    "def get_top_video_ids_by_view_count(youtube, playlist_id):\n",
    "    \"\"\"\n",
    "    #Get the top 10 video IDs from the given playlist sorted by view count!\n",
    "    # Fetch video IDs from the playlist\n",
    "    # ...\n",
    "    # Sort video IDs by view count and return top 10\n",
    "    # ...\n",
    "    Params:\n",
    "    youtube (googleapiclient.discovery.Resource): The YouTube API resource object.\n",
    "    playlist_id (str): Playlist ID.\n",
    "    \n",
    "    Returns:\n",
    "    List of the top 10 video IDs in the playlist sorted by view count.\n",
    "    \"\"\"\n",
    "    request = youtube.playlistItems().list(\n",
    "        part='contentDetails',\n",
    "        playlistId=playlist_id,\n",
    "        maxResults=50\n",
    "    )\n",
    "    response = request.execute()\n",
    "\n",
    "    # Extract video IDs and view counts into a list of dictionaries\n",
    "    videos_data = [{'video_id': item['contentDetails']['videoId']} for item in response.get('items', [])]\n",
    "\n",
    "    # If there are more pages, continue fetching\n",
    "    next_page_token = response.get('nextPageToken')\n",
    "    while next_page_token and len(videos_data) < 10:\n",
    "        request = youtube.playlistItems().list(\n",
    "            part='contentDetails',\n",
    "            playlistId=playlist_id,\n",
    "            maxResults=50,\n",
    "            pageToken=next_page_token\n",
    "        )\n",
    "        response = request.execute()\n",
    "        videos_data.extend([{'video_id': item['contentDetails']['videoId']} for item in response.get('items', [])])\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "\n",
    "    # Sort the videos by view count in descending order and return the top 10\n",
    "    top_video_ids = [video['video_id'] for video in videos_data]\n",
    "    return top_video_ids[:10]\n",
    "\n",
    "\n",
    "def get_video_details(youtube, video_ids):\n",
    "    \"\"\"\n",
    "    Get details for the provided video IDs.\n",
    "    \n",
    "    Parameters:\n",
    "    youtube (googleapiclient.discovery.Resource): The YouTube API resource object.\n",
    "    video_ids (list): List of video IDs.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing video details.\n",
    "    \"\"\"\n",
    "    all_video_info = []\n",
    "    for video_id in video_ids:\n",
    "        try:\n",
    "            request = youtube.videos().list(\n",
    "                part=\"snippet,contentDetails,statistics\",\n",
    "                id=video_id\n",
    "            )\n",
    "            response = request.execute()\n",
    "            # Process response data and append to all_video_info\n",
    "            video_info = response['items'][0]\n",
    "            snippet = video_info['snippet']\n",
    "            statistics = video_info['statistics']\n",
    "            content_details = video_info['contentDetails']\n",
    "            \n",
    "            video_data = {\n",
    "                'video_id': video_id,\n",
    "                'channelTitle': snippet.get('channelTitle', ''),\n",
    "                'title': snippet.get('title', ''),\n",
    "                'description': snippet.get('description', ''),\n",
    "                'tags': snippet.get('tags', []),\n",
    "                'publishedAt': snippet.get('publishedAt', ''),\n",
    "                'viewCount': statistics.get('viewCount', 0),\n",
    "                'likeCount': statistics.get('likeCount', 0),\n",
    "                'favoriteCount': statistics.get('favoriteCount', 0),\n",
    "                'commentCount': statistics.get('commentCount', 0),\n",
    "                'duration': content_details.get('duration', ''),\n",
    "                'definition': content_details.get('definition', ''),\n",
    "                'caption': content_details.get('caption', ''),\n",
    "            }\n",
    "            \n",
    "            all_video_info.append(video_data)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error fetching details for video {video_id}: {e}\")\n",
    "            continue\n",
    "    return pd.DataFrame(all_video_info)\n",
    "\n",
    "def get_top_liked_comments(youtube, video_ids, max_results=10, min_likes=10):\n",
    "    \"\"\"\n",
    "    Get the top liked comments for each provided video ID and filter out spam-like comments.\n",
    "\n",
    "    Parameters:\n",
    "    youtube (googleapiclient.discovery.Resource): The YouTube API resource object.\n",
    "    video_ids (list): List of video IDs.\n",
    "    max_results (int): Maximum number of comments to retrieve for each video (default is 10).\n",
    "    min_likes (int): Minimum number of likes for a comment to be considered non-spam (default is 10).\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing video IDs and associated top liked comments.\n",
    "    \"\"\"\n",
    "    all_comments = []\n",
    "    for video_id in video_ids:\n",
    "        try:\n",
    "            request = youtube.commentThreads().list(\n",
    "                part=\"snippet\",\n",
    "                videoId=video_id,\n",
    "                maxResults=max_results,  # Fetch the specified number of comments\n",
    "                order=\"relevance\",  # Order comments by relevance (likely to include top liked comments)\n",
    "            )\n",
    "            response = request.execute()\n",
    "\n",
    "            # Process comments and filter out spam-like comments\n",
    "            comments_in_video = []\n",
    "            for item in response['items']:\n",
    "                snippet = item['snippet']['topLevelComment']['snippet']\n",
    "                like_count = snippet.get('likeCount', 0)\n",
    "                comment_text = snippet.get('textDisplay', '')\n",
    "\n",
    "                # Filter out spam-like comments based on the minimum likes threshold\n",
    "                if like_count >= min_likes:\n",
    "                    comments_in_video.append(comment_text)\n",
    "\n",
    "            comments_in_video_info = {'video_id': video_id,'comments': comments_in_video}\n",
    "            all_comments.append(comments_in_video_info)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error fetching comments for video {video_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(all_comments)\n",
    "\n",
    "\n",
    "def get_comments_in_videos(youtube, video_ids, max_results=10, min_likes=50):\n",
    "    \"\"\"\n",
    "    # ... (Implementation of get_top_liked_comments function)\n",
    "    Get the top 10 comments for each provided video ID.\n",
    "\n",
    "    Parameters:\n",
    "    youtube (googleapiclient.discovery.Resource): The YouTube API resource object.\n",
    "    video_ids (list): List of video IDs.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing video IDs and associated top-level comments in text.\n",
    "    \"\"\"\n",
    "    all_comments = []\n",
    "    for video_id in video_ids:\n",
    "        try:\n",
    "            request = youtube.commentThreads().list(\n",
    "                part=\"snippet\",\n",
    "                videoId=video_id,\n",
    "                maxResults=max_results,  # Fetch only the first 10 comments #UPDATED to Fetch the specified number of comments\n",
    "                order=\"relevance\",  # Order comments by relevance (likely to include top liked comments) \n",
    "            )\n",
    "            response = request.execute()\n",
    "            # Process response data and append to all_comments # UPDATED to Process comments and filter out spam-like comments\n",
    "            # Process comments and filter out spam-like comments\n",
    "            for item in response['items']:\n",
    "                snippet = item['snippet']['topLevelComment']['snippet']\n",
    "                comment_data = {\n",
    "                    'video_id': video_id,\n",
    "                    'comment_id': item['id'],\n",
    "                    'author': snippet.get('authorDisplayName', ''),\n",
    "                    'text': snippet.get('textDisplay', ''),\n",
    "                    'like_count': snippet.get('likeCount', 0),\n",
    "                    'published_at': snippet.get('publishedAt', ''),\n",
    "                }\n",
    "                all_comments.append(comment_data)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error fetching comments for video {video_id}: {e}\")\n",
    "            continue\n",
    "    return pd.DataFrame(all_comments)\n",
    "\n",
    "\n",
    "def main():\n",
    "    # List of channel IDs to process\n",
    "    channel_ids = ['UCX6OQ3DkcsbYNE6H8uQQuVA','UCbCmjCuTUZos6Inko4u57UQ','UCqwUrj10mAEsqezcItqvwEw','UC_vcKmg67vjMP7ciLnSxSHQ','UCjp_3PEaOau_nT_3vnqKIvg','UC-lHJZR3Gqxm24_Vd_AJ5Yw', 'UCYWOjHweP2V-8kGKmmAmQJQ','UCECJDeK0MNapZbpaOzxrUPA','UCOmHUn--16B90oW2L6FRR3A']\n",
    "    # Get channel statistics\n",
    "    channel_data = get_channel_stats(youtube, channel_ids)\n",
    "    \n",
    "    # Print the first few rows of channel_data to inspect column names\n",
    "    print(channel_data.head())\n",
    "    \n",
    "    video_df = pd.DataFrame()\n",
    "    comments_df = pd.DataFrame()\n",
    "    \n",
    "    # Ensure the column name matches the actual column name in channel_data\n",
    "    for channel in channel_data['channelName'].unique():\n",
    "        logging.info(f\"Processing channel: {channel}\")\n",
    "        playlist_id = channel_data.loc[channel_data['channelName'] == channel, 'playlistId'].iloc[0]\n",
    "        try:\n",
    "            video_ids = get_top_video_ids_by_view_count(youtube, playlist_id)\n",
    "            video_data = get_video_details(youtube, video_ids)\n",
    "            comments_data = get_comments_in_videos(youtube, video_ids)\n",
    "\n",
    "            video_df = pd.concat([video_df, video_data]).drop_duplicates(subset=['video_id'])\n",
    "            comments_df = pd.concat([comments_df, comments_data]).drop_duplicates(subset=['video_id'])\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing channel {channel}: {e}\")\n",
    "            continue\n",
    "        \n",
    "    # Save the data to CSV files\n",
    "    video_df.to_csv('video_data.csv', index=False)\n",
    "    comments_df.to_csv('comments_data.csv', index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "               'UC-lHJZR3Gqxm24_Vd_AJ5Yw', # PewDiePie SE\n",
    "               'UCYWOjHweP2V-8kGKmmAmQJQ', # Badabun MX \n",
    "               'UCECJDeK0MNapZbpaOzxrUPA', # Luisito Comunica MX\n",
    "               'UCOmHUn--16B90oW2L6FRR3A', # BLACKPINK\n",
    "\n",
    "def main():\n",
    "    # List of channel IDs to process \n",
    "    channel_ids = ['UCX6OQ3DkcsbYNE6H8uQQuVA', # Mr. Beast US\n",
    "               'UCbCmjCuTUZos6Inko4u57UQ', # Cocomelon US\n",
    "               'UCqwUrj10mAEsqezcItqvwEw', # Bhuvaneshwar Bam IN\n",
    "               'UC_vcKmg67vjMP7ciLnSxSHQ', # Amit Bhadana IN\n",
    "               'UCjp_3PEaOau_nT_3vnqKIvg', # HikakinTV JP\n",
    "              ]  # Replace with actual channel IDs\n",
    "    \n",
    "    # Get channel statistics\n",
    "    channel_data = get_channel_stats(youtube, channel_ids)\n",
    "    \n",
    "    video_df = pd.DataFrame()\n",
    "    comments_df = pd.DataFrame()\n",
    "    \n",
    "    for channel in channel_data['channelName'].unique():\n",
    "        logging.info(f\"Processing channel: {channel}\")\n",
    "        playlist_id = channel_data.loc[channel_data['channelName'] == channel, 'playlistId'].iloc[0]\n",
    "        try:\n",
    "            video_ids = get_top_video_ids_by_view_count(youtube, playlist_id)\n",
    "            video_data = get_video_details(youtube, video_ids)\n",
    "            comments_data = get_comments_in_videos(youtube, video_ids)\n",
    "\n",
    "            video_df = pd.concat([video_df, video_data]).drop_duplicates(subset=['video_id'])\n",
    "            comments_df = pd.concat([comments_df, comments_data]).drop_duplicates(subset=['video_id'])\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing channel {channel}: {e}\")\n",
    "            continue\n",
    "        \n",
    "    # Save the data to CSV files\n",
    "    video_df.to_csv('video_data.csv', index=False)\n",
    "    comments_df.to_csv('comments_data.csv', index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def get_top_video_ids(youtube, playlist_id):\n",
    "    \"\"\"\n",
    "    Get the top 10 video IDs from the given playlist sorted by view count.\n",
    "    \n",
    "    Params:\n",
    "    youtube (googleapiclient.discovery.Resource): The YouTube API resource object.\n",
    "    playlist_id (str): Playlist ID.\n",
    "    \n",
    "    Returns:\n",
    "    List of the top 10 video IDs in the playlist sorted by view count.\n",
    "    \"\"\"\n",
    "    request = youtube.playlistItems().list(\n",
    "        part='contentDetails',\n",
    "        playlistId=playlist_id,\n",
    "        maxResults=50\n",
    "    )\n",
    "    response = request.execute()\n",
    "\n",
    "    # Extract video IDs and view counts into a list of dictionaries\n",
    "    videos_data = [{'video_id': item['contentDetails']['videoId']} for item in response.get('items', [])]\n",
    "\n",
    "    # If there are more pages, continue fetching\n",
    "    next_page_token = response.get('nextPageToken')\n",
    "    while next_page_token and len(videos_data) < 10:\n",
    "        request = youtube.playlistItems().list(\n",
    "            part='contentDetails',\n",
    "            playlistId=playlist_id,\n",
    "            maxResults=50,\n",
    "            pageToken=next_page_token\n",
    "        )\n",
    "        response = request.execute()\n",
    "        videos_data.extend([{'video_id': item['contentDetails']['videoId']} for item in response.get('items', [])])\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "\n",
    "    # Sort the videos by view count in descending order and return the top 10\n",
    "    top_video_ids = [video['video_id'] for video in videos_data]\n",
    "    return top_video_ids[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "def get_video_details(youtube, video_ids):\n",
    "    \"\"\"\n",
    "    Get video statistics of all videos with given IDs\n",
    "    Params:\n",
    "    \n",
    "    youtube: the build object from googleapiclient.discovery\n",
    "    video_ids: list of video IDs\n",
    "    \n",
    "    Returns:\n",
    "    Dataframe with statistics of videos, i.e.:\n",
    "        'channelTitle', 'title', 'description', 'tags', 'publishedAt'\n",
    "        'viewCount', 'likeCount', 'favoriteCount', 'commentCount'\n",
    "        'duration', 'definition', 'caption'\n",
    "    \"\"\"\n",
    "        \n",
    "    all_video_info = []\n",
    "    \n",
    "    for i in range(0, len(video_ids), 50):\n",
    "        request = youtube.videos().list(\n",
    "            part=\"snippet,contentDetails,statistics\",\n",
    "            id=','.join(video_ids[i:i+50])\n",
    "        )\n",
    "        response = request.execute() \n",
    "\n",
    "        for video in response['items']:\n",
    "            stats_to_keep = {'snippet': ['channelTitle', 'title', 'description', 'tags', 'publishedAt'],\n",
    "                             'statistics': ['viewCount', 'likeCount', 'favouriteCount', 'commentCount'],\n",
    "                             'contentDetails': ['duration', 'definition', 'caption']\n",
    "                            }\n",
    "            video_info = {}\n",
    "            video_info['video_id'] = video['id']\n",
    "\n",
    "            for k in stats_to_keep.keys():\n",
    "                for v in stats_to_keep[k]:\n",
    "                    try:\n",
    "                        video_info[v] = video[k][v]\n",
    "                    except:\n",
    "                        video_info[v] = None\n",
    "\n",
    "            all_video_info.append(video_info)\n",
    "            \n",
    "    return pd.DataFrame(all_video_info)\n",
    "\n",
    "def get_comments_in_videos(youtube, video_ids):\n",
    "    \"\"\"\n",
    "    Get top level comments as text from all videos with given IDs (only the first 10 comments due to quote limit of Youtube API)\n",
    "    Params:\n",
    "    \n",
    "    youtube: the build object from googleapiclient.discovery\n",
    "    video_ids: list of video IDs\n",
    "    \n",
    "    Returns:\n",
    "    Dataframe with video IDs and associated top level comment in text.\n",
    "    \n",
    "    \"\"\"\n",
    "    all_comments = []\n",
    "    \n",
    "    for video_id in video_ids:\n",
    "        try:   \n",
    "            request = youtube.commentThreads().list(\n",
    "                part=\"snippet,replies\",\n",
    "                videoId=video_id\n",
    "            )\n",
    "            response = request.execute()\n",
    "        \n",
    "            comments_in_video = [comment['snippet']['topLevelComment']['snippet']['textOriginal'] for comment in response['items'][0:10]]\n",
    "            comments_in_video_info = {'video_id': video_id, 'comments': comments_in_video}\n",
    "\n",
    "            all_comments.append(comments_in_video_info)\n",
    "            \n",
    "        except: \n",
    "            # When error occurs - most likely because comments are disabled on a video\n",
    "            print('Could not get comments for video ' + video_id)\n",
    "        \n",
    "    return pd.DataFrame(all_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Get channel statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `get_channel_stats` function defined below, now we are going to obtain the channel statistics for the 9 channels in scope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_stats(youtube, channel_ids):\n",
    "    \"\"\"\n",
    "    Get channel statistics: title, subscriber count, view count, video count, upload playlist, and country.\n",
    "    \n",
    "    Parameters:\n",
    "    youtube: the build object from googleapiclient.discovery\n",
    "    channels_ids: list of channel IDs\n",
    "    \n",
    "    Returns:\n",
    "    Dataframe containing the channel statistics for all channels in the provided list: title, subscriber count, view count, video count, upload playlist, and country.\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    for channel_id in channel_ids:\n",
    "        try:\n",
    "            request = youtube.channels().list(\n",
    "                part='snippet,contentDetails,statistics',\n",
    "                id=channel_id\n",
    "            )\n",
    "            response = request.execute()\n",
    "\n",
    "            # Fetch additional data including country\n",
    "            snippet_request = youtube.channels().list(\n",
    "                part='snippet',\n",
    "                id=channel_id\n",
    "            )\n",
    "            snippet_response = snippet_request.execute()\n",
    "            country = snippet_response['items'][0]['snippet'].get('country', '')\n",
    "\n",
    "            data = dict(\n",
    "                channelName=response['items'][0]['snippet']['title'],\n",
    "                subscribers=response['items'][0]['statistics']['subscriberCount'],\n",
    "                views=response['items'][0]['statistics']['viewCount'],\n",
    "                totalVideos=response['items'][0]['statistics']['videoCount'],\n",
    "                playlistId=response['items'][0]['contentDetails']['relatedPlaylists']['uploads'],\n",
    "                country=country  # Add country information\n",
    "            )\n",
    "            all_data.append(data)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error fetching channel stats for {channel_id}: {e}\")\n",
    "            continue\n",
    "    return pd.DataFrame(all_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "    \n",
    "for channel_id in channel_ids:\n",
    "    try:\n",
    "        request = youtube.channels().list(\n",
    "            part='snippet,contentDetails,statistics',\n",
    "            id=channel_id\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        # Fetch additional data including country\n",
    "        snippet_request = youtube.channels().list(\n",
    "            part='snippet',\n",
    "            id=channel_id\n",
    "        )\n",
    "        snippet_response = snippet_request.execute()\n",
    "        country = snippet_response['items'][0]['snippet'].get('country', '')\n",
    "\n",
    "        data = dict(\n",
    "            channelName=response['items'][0]['snippet']['title'],\n",
    "            subscribers=response['items'][0]['statistics']['subscriberCount'],\n",
    "            views=response['items'][0]['statistics']['viewCount'],\n",
    "            totalVideos=response['items'][0]['statistics']['videoCount'],\n",
    "            playlistId=response['items'][0]['contentDetails']['relatedPlaylists']['uploads'],\n",
    "            country=country  # Add country information\n",
    "        )\n",
    "        all_data.append(data)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error fetching channel stats for {channel_id}: {e}\")\n",
    "        continue\n",
    "\n",
    "channel_data1 = pd.DataFrame(all_data)\n",
    "channel_data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_data1.to_csv('Top9channel_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert count columns to numeric columns\n",
    "numeric_cols = ['subscribers', 'views', 'totalVideos']\n",
    "channel_data[numeric_cols] = channel_data[numeric_cols].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_data.to_csv('channel_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top Viewership ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# Using Channel_data dataframe from previous step, the data is sorted, and the top 9 channels are plotted with a legend for clarity.\n",
    "\n",
    "# Sort the data and get the top 9 channels for clarity in the legend\n",
    "sorted_data = channel_data.sort_values('subscribers', ascending=False)[0:9]\n",
    "\n",
    "# Create a color palette with a distinct color for each bar\n",
    "palette = sns.color_palette(\"hsv\", len(sorted_data))\n",
    "\n",
    "# Create the bar plot with the specified palette\n",
    "ax = sns.barplot(\n",
    "    x='channelName', \n",
    "    y='subscribers', \n",
    "    data=sorted_data, \n",
    "    palette=palette\n",
    ")\n",
    "\n",
    "# Rotate the x-axis labels by 45 degrees\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Format the y-axis labels as thousands with a K suffix\n",
    "ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: f'{x/1000:.0f}K'))\n",
    "\n",
    "# Remove x-axis labels as we will add these as legends\n",
    "ax.set(xticklabels=[])\n",
    "\n",
    "# Create the legend manually\n",
    "for i, row in enumerate(sorted_data.itertuples()):\n",
    "    plt.bar(0, 0, color=palette[i], label=row.channelName,)\n",
    "\n",
    "# Place the legend below the chart # Adjust legend box height and width\n",
    "plt.legend(title='The Top YouTuber Channel Names', bbox_to_anchor=(1.35, .5), loc='center')\n",
    "\n",
    "# Add labels to the bars to show the exact subscriber count for each channel\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.text(p.get_x() + p.get_width() / 2., height + 0.02 * height, \n",
    "            f'{height/1000:.0f}K', ha='center', va='bottom', fontsize=8, color='black'\n",
    "            )\n",
    "\n",
    "#  Add a title and format it\n",
    "plt.title('Top 9 YouTuber Channels by Subscriber Count', x=0.7, y=1.15, loc='Center', fontsize=18, fontweight='bold')\n",
    "\n",
    "\n",
    "# FILEPATH: /c:/Users/jamal/jamaleb67.github.io/jamaleb67.github.io/work/Project.ipynb\n",
    "plt.suptitle('Source: YouTube API', x=0.05, y=0.02, ha='left', fontsize=7)\n",
    "\n",
    "# Save the plot as a PNG file\n",
    "plt.savefig(\"TOP9PLOT.png\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "ax = sns.barplot(x='channelName', y='views', data=channel_data.sort_values('views', ascending=False))\n",
    "ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x/1000) + 'K'))\n",
    "plot = ax.set_xticklabels(ax.get_xticklabels(),rotation = 90)\n",
    "\n",
    "\n",
    "# Using Channel_data dataframe from previous step, the data is sorted, and the top 9 channels are plotted with a legend for clarity.\n",
    "\n",
    "# Sort the data and get the top 9 channels for clarity in the legend\n",
    "sorted_data = channel_data.sort_values('views', ascending=False)[0:9]\n",
    "\n",
    "# Create a color palette with a distinct color for each bar\n",
    "palette = sns.color_palette(\"hsv\", len(sorted_data))\n",
    "\n",
    "# Create the bar plot with the specified palette\n",
    "ax = sns.barplot(\n",
    "    x='channelName', \n",
    "    y='views', \n",
    "    data=sorted_data, \n",
    "    palette=palette\n",
    ")\n",
    "\n",
    "# Rotate the x-axis labels by 45 degrees\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Format the y-axis labels as thousands with a K suffix\n",
    "ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: f'{x/1000:.0f}K'))\n",
    "\n",
    "# Remove x-axis labels as we will add these as legends\n",
    "ax.set(xticklabels=[])\n",
    "\n",
    "# Create the legend manually\n",
    "for i, row in enumerate(sorted_data.itertuples()):\n",
    "    plt.bar(0, 0, color=palette[i], label=row.channelName,)\n",
    "\n",
    "# Place the legend below the chart # Adjust legend box height and width\n",
    "plt.legend(title='The Top YouTuber Channels by Viewership', bbox_to_anchor=(1.35, .5), loc='center')\n",
    "\n",
    "# Add labels to the bars to show the exact subscriber count for each channel\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.text(p.get_x() + p.get_width() / 2., height + 0.02 * height, \n",
    "            f'{height/1000:.0f}K', ha='center', va='bottom', rotation=10,  fontsize=7\n",
    "            )\n",
    "\n",
    "#  Add a title and format it\n",
    "plt.title('Top 9 YouTuber Channels by View Count', x=0.7, y=1.15, loc='Center', fontsize=18, fontweight='bold')\n",
    "\n",
    "\n",
    "# FILEPATH: /c:/Users/jamal/jamaleb67.github.io/jamaleb67.github.io/work/Project.ipynb\n",
    "plt.suptitle('Source: YouTube API', x=0.05, y=0.02, ha='left', fontsize=8)\n",
    "\n",
    "# Save the plot as a PNG file\n",
    "plt.savefig(\"TOP9PLOT.png\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Video Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video statistics are obtained using the `get_video_stats` function defined below. The function takes in a list of video ids and returns a dataframe with the video statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_df = pd.DataFrame()\n",
    "comments_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(video_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a dataframe with video statistics and comments from all channels\n",
    "\n",
    "#video_df = pd.DataFrame()\n",
    "#comments_df = pd.DataFrame() \n",
    "\n",
    "for c in channel_data['channelName'].unique():\n",
    "    print(\"Getting video information from channel: \" + c)\n",
    "    playlist_id = channel_data.loc[channel_data['channelName']== c, 'playlistId'].iloc[0]\n",
    "    video_ids = get_video_ids(youtube, playlist_id)\n",
    "    \n",
    "    # get video data\n",
    "    video_data = get_video_details(youtube, video_ids)\n",
    "    # get comment data\n",
    "    comments_data = get_comments_in_videos(youtube, video_ids)\n",
    "\n",
    "    # append video data together and comment data toghether\n",
    "    video_df = video_df.concat(video_data, ignore_index=True)\n",
    "    comments_df = comments_df.concat(comments_data, ignore_index=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a dataframe with video statistics and comments from all channels\n",
    "import pandas as pd\n",
    "\n",
    "video_df = pd.DataFrame()\n",
    "comments_df = pd.DataFrame()\n",
    "\n",
    "for c in channel_data['channelName'].unique():\n",
    "    print(\"Getting video information from channel: \" + c)\n",
    "    playlist_id = channel_data.loc[channel_data['channelName']== c, 'playlistId'].iloc[0]\n",
    "    video_ids = get_video_ids(youtube, playlist_id)\n",
    "    \n",
    "    # get video data\n",
    "    video_data = get_video_details(youtube, video_ids)\n",
    "\n",
    "    # append video data together and comment data toghether\n",
    "    video_df = video_df.append(video_data, ignore_index=True)\n",
    "    comments_df = comments_df.concat(comments_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try Concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "video_df = pd.DataFrame()\n",
    "\n",
    "for c in channel_data['channelName'].unique():\n",
    "    print(\"Getting video information from channel: \" + c)\n",
    "    playlist_id = channel_data.loc[channel_data['channelName'] == c, 'playlistId'].iloc[0]\n",
    "    video_ids = get_video_ids(youtube, playlist_id)\n",
    "    \n",
    "    # get video data\n",
    "    video_data = get_video_details(youtube, video_ids)\n",
    "\n",
    "    # append video data together\n",
    "    video_df = pd.concat([video_df, video_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write video data to CSV file for future references\n",
    "video_df.to_csv('video_data_top10_channels.csv')\n",
    "comments_df.to_csv('comments_data_top10_channels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embed a Power BI report in a Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion <a class='anchor' id='Conclusion'></a>[](#Top)>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Reference\n",
    "\n",
    "#### Get all items\n",
    "\n",
    "```http\n",
    "  GET /api/items\n",
    "```\n",
    "\n",
    "| Parameter | Type     | Description                |\n",
    "| :-------- | :------- | :------------------------- |\n",
    "| `api_key` | `string` | **AIzaSyDs9TExsfc8fDMn4lBRYXZax1vSr0ftsdk**. YouTube API key |\n",
    "\n",
    "#### Get item\n",
    "\n",
    "```http\n",
    "  GET /api/items/${id}\n",
    "```\n",
    "\n",
    "| Parameter | Type     | Description                       |\n",
    "| :-------- | :------- | :-------------------------------- |\n",
    "| `id`      | `string` | **UCtYLUTtgS3k1Fg4y5tAhLbw** # Statquest\n",
    "| `id`      | `string` | 'UCCezIgC97PvUuR4_gbFUs5g', # Corey Schafer\n",
    "| `id`      | `string` | 'UCfzlCWGWYyIQ0aLC5w48gBQ', # Sentdex\n",
    "| `id`      | `string` | 'UCNU_lfiiWBdtULKOw6X0Dig', # Krish Naik\n",
    "| `id`      | `string` | 'UCzL_0nIe8B4-7ShhVPfJkgw', # DatascienceDoJo\n",
    "| `id`      | `string` | 'UCLLw7jmFsvfIVaUFsLs8mlQ', # Luke Barousse \n",
    "| `id`      | `string` | 'UCiT9RITQ9PW6BhXK0y2jaeg', # Ken Jee\n",
    "| `id`      | `string` | 'UC7cs8q-gJRlGwj4A8OmCmXg', # Alex the analyst\n",
    "| `id`      | `string` | 'UC2UXDak6o7rBm23k3Vv5dww', # Tina Huang\n",
    "\n",
    "\n",
    "#### add(more to follow)\n",
    "\n",
    "Takes two numbers and returns the sum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Badges\n",
    "\n",
    "\n",
    "[![MIT License](https://img.shields.io/badge/License-MIT-green.svg)](https://choosealicense.com/licenses/mit/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link to top of page <a class='anchor' id='Top'>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
