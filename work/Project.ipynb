{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [Youtube/GDP](Top)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=https://i.imgur.com/ACFFpv2.png width=1500 class=\"center\">\n",
    "<h1 align=\"center\">Top Youtubers effecting GDP between 2019 - 2022??</h1>\n",
    "    \n",
    "    In today's world, the internet has become an integral part of our lives. With the rise of online platforms such as YouTube, it has become easier than ever for people to access information and entertainment from all over the world. At the same time, Gross Domestic Product (GDP) remains one of the most widely used indicators of economic performance. In this project, we aim to explore the relationship between these two seemingly unrelated topics: GDP and YouTube. By analyzing data on GDP and YouTube usage patterns, we hope to gain insights into how these two factors are connected and what implications this may have on our understanding of the modern world.\n",
    "\n",
    "The objective of this project is to analyze the relationship between GDP and YouTube usage patterns. We will use data on GDP and YouTube usage patterns to gain insights into how these two factors are connected and what implications this may have on our understanding of the modern world.\n",
    "\n",
    "Our goal is to answer the following questions:\n",
    "\n",
    "- What are the the top Youtubers in countries around the globe?\n",
    "- What is the Top GDP countries, and what is there growth during COVID?\n",
    "- Is there a correlation between Top Youtubers and selected GDP Nations?\n",
    "- What is statistical corelations can be made?\n",
    "\n",
    "To answer these questions, we will use Python and its data analysis libraries, such as Pandas and Matplotlib. We will start by importing the dataset and cleaning the data, followed by exploratory data analysis and visualization.\n",
    "\n",
    "I will be using the following datasets: \n",
    "- [Top Youtubers](https://www.kaggle.com/mdhrumil/top-5000-youtube-channels-data-from-socialblade)\n",
    "- [GDP](https://www.kaggle.com/fernandol/countries-of-the-world)\n",
    "\n",
    "APIs:\n",
    "- [YouTube API](https://developers.google.com/youtube/v3/docs/channels/list)\n",
    "- [Google API](https://console.cloud.google.com/apis/library/youtube.googleapis.com)\n",
    "\n",
    "\n",
    "\n",
    "# Table of contents <a class='anchor' id='top'>\n",
    "- [Introduction](#Introduction)\n",
    "- [Import libraries](#import)\n",
    "- [Load data](#load_data)\n",
    "- [GDP Analysis](#gdpproject)\n",
    "- [Bar chart](#bar_chart)\n",
    "- [GDP Conclusion](#geo)\n",
    "- [YouTube Analysis](#Analysis)\n",
    "- [Youtube API](#YouTube)\n",
    "- [Conclusion](#Conclusion)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction  <a class='anchor' id='Introduction'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries <a class='anchor' id='import'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install isodate\n",
    "%pip install google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client\n",
    "%pip install wordcloud\n",
    "%pip install nltk\n",
    "%pip install wbgapi\n",
    "%pip install bar_chart_race\n",
    "%pip install plotly\n",
    "%pip install pandas\n",
    "%pip install matplotlib\n",
    "%pip install seaborn\n",
    "%pip install numpy\n",
    "%pip install requests\n",
    "%pip install scipy\n",
    "%pip install sklearn\n",
    "%pip install statsmodels\n",
    "%pip install xgboost\n",
    "%pip install lightgbm\n",
    "%pip install catboost\n",
    "%pip install bar_chart_race\n",
    "%pip install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil import parser\n",
    "import isodate\n",
    "\n",
    "# Data visualization libraries\n",
    "%pip install scikit-learn\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import pyplot as pyplot\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "sns.set(style=\"darkgrid\", color_codes=True)\n",
    "%pip install scikit-learn\n",
    "\n",
    "# Google API\n",
    "from googleapiclient.discovery import build\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP libraries\n",
    "import collections\n",
    "import itertools\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from wordcloud import WordCloud\n",
    "from wordcloud import ImageColorGenerator\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <b><u><span style=\"font-size: 24px\">\n",
    "  GDP Analysis from 2019 - 2020<a class='anchor' id='gdpproject'></span></u></b><br>\n",
    "</p>\n",
    "\n",
    "### Load data <a class='anchor' id='load_data'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "#load data\n",
    "data = pd.read_csv('GDP by Country 1999-2022.csv', decimal = ',')\n",
    "\n",
    "data = data.replace({'\\\"' :''}, regex=True)\n",
    "data = data.replace({',' :''}, regex=True)\n",
    "#display(data)\n",
    "\n",
    "data = data.astype({'1999' : 'float', '2022' : 'float'})\n",
    "\n",
    "#observe data\n",
    "data.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar Chart for Top 10 GDP countries and for targeted group <a class='anchor' id='bar_chart'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 10 GDP in 2022\n",
    "top_10_GDP_2022 = data.sort_values('2022', ascending = False).head(10)\n",
    "fig, ax = pyplot.subplots(figsize = (16, 6))\n",
    "sns.barplot(x = 'Country', y = '2022', data = top_10_GDP_2022, palette = 'Set1')\n",
    "ax.set_xlabel(ax.get_xlabel(), labelpad= 15)\n",
    "ax.set_ylabel('GDP by Country 2022', labelpad= 30)\n",
    "ax.xaxis.label.set_fontsize(16)\n",
    "ax.yaxis.label.set_fontsize(16)\n",
    "pyplot.xticks(rotation = 90)\n",
    "pyplot.title('Title Here', fontsize = 20)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2022 GDP for germany, south korea, UK, US, Mexico, japan and india\n",
    "\n",
    "Countries = data[data[\"Country\"].isin(['Germany', 'South Korea', 'United Kingdom', 'United States', 'Mexico', 'Japan', 'India'])] \n",
    "Countries_GDP_2022 = Countries.sort_values('2022', ascending = False)\n",
    "\n",
    "display(Countries_GDP_2022)\n",
    "\n",
    "fig, ax = pyplot.subplots(figsize = (16, 6))\n",
    "sns.barplot(x = 'Country', y = '2022', data = Countries_GDP_2022, legend=False, palette = 'Set1')\n",
    "ax.set_xlabel(ax.get_xlabel(), labelpad= 15)\n",
    "ax.set_ylabel('GDP by Country 2022', labelpad= 30)\n",
    "ax.xaxis.label.set_fontsize(16)\n",
    "ax.yaxis.label.set_fontsize(16)\n",
    "pyplot.xticks(rotation = 90)\n",
    "pyplot.title('Title Here', fontsize = 20)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ Gross Domestic product average for 2019 - 2020 <a class='anchor' id='19-20'>\n",
    "+ Germany, South Korea UK, US, Mexico, Japan and India"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average GDP between 2018-2022 for germany, south korea, UK, US, Mexico, japan and india\n",
    "Countries = data[data[\"Country\"].isin(['Germany', 'South Korea', 'United Kingdom', 'United States', 'Mexico', 'Japan', 'India'])] \n",
    "Countries_GDP_2022 = Countries[['Country', '2018', '2019', '2020', '2021', '2022']]\n",
    "\n",
    "fig, ax = pyplot.subplots(figsize = (16, 6))\n",
    "new_data = pd.melt(Countries_GDP_2022, id_vars = ['Country'], value_vars = ['2018', '2019', '2020', '2021', '2022'], var_name = 'Year', value_name = 'GDP')\n",
    "\n",
    "new_data = new_data.astype({'Country' : 'str'})\n",
    "new_data = new_data.astype({'GDP' : 'float'})\n",
    "\n",
    "\n",
    "display(new_data)\n",
    "\n",
    "sns.pointplot(data = new_data, x = 'Year', y = 'GDP', hue = 'Country', ax = ax, palette = 'nipy_spectral')\n",
    "\n",
    "ax.set_xlabel(ax.get_xlabel(), labelpad= 15)\n",
    "ax.set_ylabel('Average GDP by Country 2018-2022', labelpad= 30)\n",
    "ax.xaxis.label.set_fontsize(16)\n",
    "ax.yaxis.label.set_fontsize(16)\n",
    "pyplot.title('Average GDP between 2018-2022', fontsize = 20)\n",
    "pyplot.show()\n",
    "\n",
    "#sort_new_data = new_data.sort_values('GDP', ascending = True)\n",
    "#sort_new_data = resort_new_data.sort_values('GDP', ascending = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average GDP between 2018-2022 for germany, south korea, UK, Mexico, japan and india ***Without the US because it made the graph look bad***\n",
    "Countries = data[data[\"Country\"].isin(['Germany', 'South Korea', 'United Kingdom', 'Mexico', 'Japan', 'India'])] \n",
    "Countries_GDP_2022 = Countries[['Country', '2018', '2019', '2020', '2021', '2022']]\n",
    "\n",
    "fig, ax = pyplot.subplots(figsize = (16, 8))\n",
    "new_data = pd.melt(Countries_GDP_2022, id_vars = ['Country'], value_vars = ['2018', '2019', '2020', '2021', '2022'], var_name = 'Year', value_name = 'GDP')\n",
    "\n",
    "new_data = new_data.astype({'Country' : 'str'})\n",
    "new_data = new_data.astype({'GDP' : 'float'})\n",
    "\n",
    "#sort_new_data = new_data.sort_values('GDP', ascending = True)\n",
    "#sort_new_data = resort_new_data.sort_values('GDP', ascending = True)\n",
    "\n",
    "display(new_data)\n",
    "\n",
    "sns.pointplot(data = new_data, x = 'Year', y = 'GDP', hue = 'Country', ax = ax, palette = 'nipy_spectral')\n",
    "\n",
    "ax.set_xlabel(ax.get_xlabel(), labelpad= 15)\n",
    "ax.set_ylabel('Average GDP by Country 2018-2022', labelpad= 30)\n",
    "ax.xaxis.label.set_fontsize(16)\n",
    "ax.yaxis.label.set_fontsize(16)\n",
    "pyplot.title('Average GDP between 2018-2022 without the U.S.', fontsize = 20)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HalfTime <a class='anchor' id='geo'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Region Code: You must provide a two-letter ISO 3166â€“1 country code \n",
    "* (e.g., â€˜USâ€™ for the United States) to specify the region for which you want to find the top 10 YouTube channels.\n",
    "* Replace 'YOUR_REGION_CODE' in the code with the desired region code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ?WBGAPI World Bank Top 20 Countries by GDP?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import wbgapi as wb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(wb)\n",
    "wb.source.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##wb.economy.info(db=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## WORKING CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "class Coder(dict):\n",
    "    '''Class returned by coder if passed a list of terms\n",
    "    '''\n",
    "\n",
    "    def __repr__(self):\n",
    "        rows = self._coder_report()\n",
    "        columns = rows.pop(0)\n",
    "        return tabulate(rows, tablefmt='simple', headers=columns)\n",
    "\n",
    "def coder_report(economies):\n",
    "\n",
    "    global _coder_names\n",
    "\n",
    "    rows = [('ORIGINAL NAME', 'WBG NAME', 'ISO_CODE')]\n",
    "    for k,v in economies.items():\n",
    "        if v:\n",
    "            wb_name = _coder_names.get(v, '')\n",
    "        else:\n",
    "            wb_name = ''\n",
    "\n",
    "        rows.append((k, wb_name, v))\n",
    "\n",
    "    output = []\n",
    "    for row in rows:\n",
    "        output.append([row[0], row[1], row[2]])\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "def plot_anim_funct():\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.set_xlim((0, 2))\n",
    "    ax.set_ylim((-2, 2))\n",
    "\n",
    "    line, = ax.plot([], [], lw=2)\n",
    "\n",
    "    def init():\n",
    "        line.set_data([], [])\n",
    "        return (line,)\n",
    "\n",
    "    def animate(i):\n",
    "        x = np.linspace(0, 2, 1000)\n",
    "        y = np.sin(2 * np.pi * (x - 0.01 * i))\n",
    "        line.set_data(x, y)\n",
    "        return (line,)\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                                   frames=100, interval=20, \n",
    "                                   blit=True)\n",
    "\n",
    "\n",
    "    display(HTML(anim.to_jshtml()))\n",
    "\n",
    "plot_anim_funct()\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"GDP by Country 1999-2022.csv\", sep=',', header=0, thousands=\",\")\n",
    "df.set_index(\"Country\", inplace=True)\n",
    "df = df.T\n",
    "print(f\"Dataframe has {df.shape[0]} rows and {df.shape[1]} columns\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML, display\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from io import BytesIO, TextIOWrapper\n",
    "from pathlib import Path\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "from matplotlib import rcParams\n",
    "from matplotlib import animation\n",
    "\n",
    "class FuncAnimation(animation.FuncAnimation):\n",
    "\n",
    "    def to_html5_video(self, embed_limit=None, savefig_kwargs=None):\n",
    "        \"\"\"\n",
    "        Convert the animation to an HTML5 ``<video>`` tag.\n",
    "\n",
    "        This saves the animation as an h264 video, encoded in base64\n",
    "        directly into the HTML5 video tag. This respects the rc parameters\n",
    "        for the writer as well as the bitrate. This also makes use of the\n",
    "        ``interval`` to control the speed, and uses the ``repeat``\n",
    "        parameter to decide whether to loop.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        embed_limit : float, optional\n",
    "            Limit, in MB, of the returned animation. No animation is created\n",
    "            if the limit is exceeded.\n",
    "            Defaults to :rc:`animation.embed_limit` = 20.0.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        video_tag : str\n",
    "            An HTML5 video tag with the animation embedded as base64 encoded\n",
    "            h264 video.\n",
    "            If the *embed_limit* is exceeded, this returns the string\n",
    "            \"Video too large to embed.\"\n",
    "        \"\"\"\n",
    "        VIDEO_TAG = r'''<video {size} {options}>\n",
    "  <source type=\"video/mp4\" src=\"data:video/mp4;base64,{video}\">\n",
    "  Your browser does not support the video tag.\n",
    "</video>'''\n",
    "        # Cache the rendering of the video as HTML\n",
    "        if not hasattr(self, '_base64_video'):\n",
    "            # Save embed limit, which is given in MB\n",
    "            if embed_limit is None:\n",
    "                embed_limit = rcParams['animation.embed_limit']\n",
    "\n",
    "            # Convert from MB to bytes\n",
    "            embed_limit *= 1024 * 1024\n",
    "\n",
    "            # Can't open a NamedTemporaryFile twice on Windows, so use a\n",
    "            # TemporaryDirectory instead.\n",
    "            with TemporaryDirectory() as tmpdir:\n",
    "                path = Path(tmpdir, \"temp.m4v\")\n",
    "                # We create a writer manually so that we can get the\n",
    "                # appropriate size for the tag\n",
    "                Writer = animation.writers[rcParams['animation.writer']]\n",
    "                writer = Writer(codec='h264',\n",
    "                                bitrate=rcParams['animation.bitrate'],\n",
    "                                fps=1000. / self._interval)\n",
    "                self.save(str(path), writer=writer, savefig_kwargs=savefig_kwargs)\n",
    "                # Now open and base64 encode.\n",
    "                vid64 = base64.encodebytes(path.read_bytes())\n",
    "\n",
    "            vid_len = len(vid64)\n",
    "            if vid_len >= embed_limit:\n",
    "                _log.warning(\n",
    "                    \"Animation movie is %s bytes, exceeding the limit of %s. \"\n",
    "                    \"If you're sure you want a large animation embedded, set \"\n",
    "                    \"the animation.embed_limit rc parameter to a larger value \"\n",
    "                    \"(in MB).\", vid_len, embed_limit)\n",
    "            else:\n",
    "                self._base64_video = vid64.decode('ascii')\n",
    "                self._video_size = 'width=\"{}\" height=\"{}\"'.format(\n",
    "                        *writer.frame_size)\n",
    "\n",
    "        # If we exceeded the size, this attribute won't exist\n",
    "        if hasattr(self, '_base64_video'):\n",
    "            # Default HTML5 options are to autoplay and display video controls\n",
    "            options = ['controls', 'autoplay']\n",
    "\n",
    "            # If we're set to repeat, make it loop\n",
    "            if hasattr(self, 'repeat') and self.repeat:\n",
    "                options.append('loop')\n",
    "\n",
    "            return VIDEO_TAG.format(video=self._base64_video,\n",
    "                                    size=self._video_size,\n",
    "                                    options=' '.join(options))\n",
    "        else:\n",
    "            return 'Video too large to embed.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import bar_chart_race as bcr\n",
    "import warnings\n",
    "import matplotlib.animation\n",
    "import imageio_ffmpeg as ffmpeg\n",
    "\n",
    "---\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "bcr.bar_chart_race(df=df,\n",
    "                   n_bars=10,\n",
    "                  orientation=\"h\",\n",
    "                  title=\"Gross Domestic Product (billions USD)\",\n",
    "                  cmap=\"tab20b\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import bar_chart_race as bcr\n",
    "\n",
    "create a dataframe with sample data\n",
    "set the index to 'Year'\n",
    "df.set_index('Year', inplace=True)\n",
    "\n",
    "create the bar chart race\n",
    "bcr.bar_chart_race(df=df, n_bars=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Youtube Exploratory Data Analysis <a class='anchor' id='Analysis'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare for Youtube API pull and research of top YouTubers, we need to first obtain the API key from Google Cloud Console. Once we have the API key, we can use it to authenticate our requests to the Youtube API. We can then use the API to pull data on top YouTubers, such as their subscriber count, view count, and video count. We can use this data to perform exploratory data analysis and gain insights into the trends and patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U.S. Top Channels\n",
    "\n",
    "\n",
    "1. Mr. Beasts view-source:https://www.youtube.com/@MrBeast/about\n",
    "* UCX6OQ3DkcsbYNE6H8uQQuVA\n",
    "\n",
    "2. Cocomelon - Nursery Rhymes view-source:https://www.youtube.com/channel/UCbCmjCuTUZos6Inko4u57UQ\n",
    "* UCbCmjCuTUZos6Inko4u57UQ\n",
    "\n",
    "3. Dude Perfect view-source:https://www.youtube.com/channel/UCRijo3ddMTht_IHyNSNXpNQ\n",
    "* UCRijo3ddMTht_IHyNSNXpNQ\n",
    "\n",
    "4. âœ¿ Kids Diana Show view-source:https://www.youtube.com/channel/UCk8GzjMOrta8yxDcKfylJYw\n",
    "* UCk8GzjMOrta8yxDcKfylJYw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For India, the top two YouTubers are **Bhuvaneshwar Bam** and **Amit Bhadana**. Bhuvaneshwar Bam is the creator of **BB ki Vines**, a comedy channel that features him playing multiple characters. He has more than 20 million subscribers and over 3 billion views. Amit Bhadana is another comedy channel that features slice of life content, relationships, and comedic skits. He has more than 22 million subscribers and over 1.8 billion views. You can visit their YouTube pages here: [BB ki Vines](^1^) and [Amit Bhadana](^2^).\n",
    "\n",
    "- For Japan, the top two YouTubers are **HikakinTV** and **Yuka Kinoshita**. HikakinTV is a channel that features various content such as music, games, challenges, and collaborations with other celebrities. He has more than 8.8 million subscribers and over 6.7 billion views. Yuka Kinoshita is a channel that features her eating large amounts of food in a short time. She has more than 5.6 million subscribers and over 2.4 billion views. You can visit their YouTube pages here: [HikakinTV](^3^) and [Yuka Kinoshita].\n",
    "\n",
    "- For Mexico, the top two YouTubers are **Luisito Comunica** and **Badabun**. Luisito Comunica is a channel that features his travels around the world, exploring different cultures, cuisines, and attractions. He has more than 36 million subscribers and over 4.9 billion views. Badabun is a channel that features various content such as entertainment, news, pranks, and social experiments. He has more than 43 million subscribers and over 14 billion views. You can visit their YouTube pages here: [Luisito Comunica] and [Badabun].\n",
    "\n",
    "- For South Korea, the top two YouTubers are **Boram Tube Vlog** and **Saebyuk Jang**. Boram Tube Vlog is a channel that features a six-year-old girl named Boram and her family doing various activities such as playing with toys, cooking, traveling, and reviewing products. She has more than 26 million subscribers and over 10 billion views. Saebyuk Jang is a channel that features a young boy named Saebyuk and his parents doing various content such as games, challenges, vlogs, and animations. He has more than 23 million subscribers and over 8 billion views. You can visit their YouTube pages here: [Boram Tube Vlog] and [Saebyuk Jang].\n",
    "\n",
    "\n",
    "1) YouTube. https://www.youtube.com/index.\n",
    "2) Top 50 Popular YouTubers in India (2023) - Moneymint. https://moneymint.com/top-youtubers-in-india/.\n",
    "3) List of most-subscribed YouTube channels - Wikipedia. https://en.wikipedia.org/wiki/List_of_most-subscribed_YouTube_channels.\n",
    "#### India Top Channels\n",
    "1.  view-source:\n",
    "*\n",
    "2.   view-source:\n",
    "*\n",
    "\n",
    "#### Japan Top Channels\n",
    "1.  view-source:\n",
    "*\n",
    "2.  view-source:\n",
    "*\n",
    "\n",
    "#### Mexico Top Channels\n",
    "1.  view-source:\n",
    "*\n",
    "2.  view-source:\n",
    "*\n",
    "\n",
    "#### South Korea Top Channels\n",
    "1.  view-source:\n",
    "*\n",
    "2.  view-source:\n",
    "*\n",
    "\n",
    "#### United Kingdom Top Channels\n",
    "1.  view-source:\n",
    "*\n",
    "2.  view-source:\n",
    "*\n",
    "\n",
    "#### Germany Top Channels\n",
    "1.\n",
    "*\n",
    "2.\n",
    "*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YouTube API <a class='anchor' id='YouTube'></center> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'AIzaSyDs9TExsfc8fDMn4lBRYXZax1vSr0ftsdk'  # Youtube API key Personal \n",
    "\n",
    "channel_ids = ['UCtYLUTtgS3k1Fg4y5tAhLbw', # Statquest\n",
    "               'UCCezIgC97PvUuR4_gbFUs5g', # Corey Schafer\n",
    "               'UCfzlCWGWYyIQ0aLC5w48gBQ', # Sentdex\n",
    "               'UCNU_lfiiWBdtULKOw6X0Dig', # Krish Naik\n",
    "               'UCzL_0nIe8B4-7ShhVPfJkgw', # DatascienceDoJo\n",
    "               'UCLLw7jmFsvfIVaUFsLs8mlQ', # Luke Barousse \n",
    "               'UCiT9RITQ9PW6BhXK0y2jaeg', # Ken Jee\n",
    "               'UC7cs8q-gJRlGwj4A8OmCmXg', # Alex the analyst\n",
    "               'UC2UXDak6o7rBm23k3Vv5dww', # Tina Huang\n",
    "              ]\n",
    "\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_id = 'UCXuqSBlHAE6Xw-yeJA0Tunw'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining  CHANNEL IDS <a class='anchor' id='channel_ids'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_stats(youtube, channel_ids):\n",
    "    \"\"\"\n",
    "    Get channel statistics: title, subscriber count, view count, video count, upload playlist\n",
    "    Params:\n",
    "    \n",
    "    youtube: the build object from googleapiclient.discovery\n",
    "    channels_ids: list of channel IDs\n",
    "    \n",
    "    Returns:\n",
    "    Dataframe containing the channel statistics for all channels in the provided list: title, subscriber count, view count, video count, upload playlist\n",
    "    \n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    request = youtube.channels().list(\n",
    "                part='snippet,contentDetails,statistics',\n",
    "                id=','.join(channel_ids))\n",
    "    response = request.execute() \n",
    "    \n",
    "    for i in range(len(response['items'])):\n",
    "        data = dict(channelName = response['items'][i]['snippet']['title'],\n",
    "                    subscribers = response['items'][i]['statistics']['subscriberCount'],\n",
    "                    views = response['items'][i]['statistics']['viewCount'],\n",
    "                    totalVideos = response['items'][i]['statistics']['videoCount'],\n",
    "                    playlistId = response['items'][i]['contentDetails']['relatedPlaylists']['uploads'])\n",
    "        all_data.append(data)\n",
    "    \n",
    "    return pd.DataFrame(all_data)\n",
    "\n",
    "def get_video_ids(youtube, playlist_id):\n",
    "    \"\"\"\n",
    "    Get list of video IDs of all videos in the given playlist\n",
    "    Params:\n",
    "    \n",
    "    youtube: the build object from googleapiclient.discovery\n",
    "    playlist_id: playlist ID of the channel\n",
    "    \n",
    "    Returns:\n",
    "    List of video IDs of all videos in the playlist\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    request = youtube.playlistItems().list(\n",
    "                part='contentDetails',\n",
    "                playlistId = playlist_id,\n",
    "                maxResults = 50)\n",
    "    response = request.execute()\n",
    "    \n",
    "    video_ids = []\n",
    "    \n",
    "    for i in range(len(response['items'])):\n",
    "        video_ids.append(response['items'][i]['contentDetails']['videoId'])\n",
    "        \n",
    "    next_page_token = response.get('nextPageToken')\n",
    "    more_pages = True\n",
    "    \n",
    "    while more_pages:\n",
    "        if next_page_token is None:\n",
    "            more_pages = False\n",
    "        else:\n",
    "            request = youtube.playlistItems().list(\n",
    "                        part='contentDetails',\n",
    "                        playlistId = playlist_id,\n",
    "                        maxResults = 50,\n",
    "                        pageToken = next_page_token)\n",
    "            response = request.execute()\n",
    "    \n",
    "            for i in range(len(response['items'])):\n",
    "                video_ids.append(response['items'][i]['contentDetails']['videoId'])\n",
    "            \n",
    "            next_page_token = response.get('nextPageToken')\n",
    "        \n",
    "    return video_ids\n",
    "\n",
    "def get_video_details(youtube, video_ids):\n",
    "    \"\"\"\n",
    "    Get video statistics of all videos with given IDs\n",
    "    Params:\n",
    "    \n",
    "    youtube: the build object from googleapiclient.discovery\n",
    "    video_ids: list of video IDs\n",
    "    \n",
    "    Returns:\n",
    "    Dataframe with statistics of videos, i.e.:\n",
    "        'channelTitle', 'title', 'description', 'tags', 'publishedAt'\n",
    "        'viewCount', 'likeCount', 'favoriteCount', 'commentCount'\n",
    "        'duration', 'definition', 'caption'\n",
    "    \"\"\"\n",
    "        \n",
    "    all_video_info = []\n",
    "    \n",
    "    for i in range(0, len(video_ids), 50):\n",
    "        request = youtube.videos().list(\n",
    "            part=\"snippet,contentDetails,statistics\",\n",
    "            id=','.join(video_ids[i:i+50])\n",
    "        )\n",
    "        response = request.execute() \n",
    "\n",
    "        for video in response['items']:\n",
    "            stats_to_keep = {'snippet': ['channelTitle', 'title', 'description', 'tags', 'publishedAt'],\n",
    "                             'statistics': ['viewCount', 'likeCount', 'favouriteCount', 'commentCount'],\n",
    "                             'contentDetails': ['duration', 'definition', 'caption']\n",
    "                            }\n",
    "            video_info = {}\n",
    "            video_info['video_id'] = video['id']\n",
    "\n",
    "            for k in stats_to_keep.keys():\n",
    "                for v in stats_to_keep[k]:\n",
    "                    try:\n",
    "                        video_info[v] = video[k][v]\n",
    "                    except:\n",
    "                        video_info[v] = None\n",
    "\n",
    "            all_video_info.append(video_info)\n",
    "            \n",
    "    return pd.DataFrame(all_video_info)\n",
    "\n",
    "def get_comments_in_videos(youtube, video_ids):\n",
    "    \"\"\"\n",
    "    Get top level comments as text from all videos with given IDs (only the first 10 comments due to quote limit of Youtube API)\n",
    "    Params:\n",
    "    \n",
    "    youtube: the build object from googleapiclient.discovery\n",
    "    video_ids: list of video IDs\n",
    "    \n",
    "    Returns:\n",
    "    Dataframe with video IDs and associated top level comment in text.\n",
    "    \n",
    "    \"\"\"\n",
    "    all_comments = []\n",
    "    \n",
    "    for video_id in video_ids:\n",
    "        try:   \n",
    "            request = youtube.commentThreads().list(\n",
    "                part=\"snippet,replies\",\n",
    "                videoId=video_id\n",
    "            )\n",
    "            response = request.execute()\n",
    "        \n",
    "            comments_in_video = [comment['snippet']['topLevelComment']['snippet']['textOriginal'] for comment in response['items'][0:10]]\n",
    "            comments_in_video_info = {'video_id': video_id, 'comments': comments_in_video}\n",
    "\n",
    "            all_comments.append(comments_in_video_info)\n",
    "            \n",
    "        except: \n",
    "            # When error occurs - most likely because comments are disabled on a video\n",
    "            print('Could not get comments for video ' + video_id)\n",
    "        \n",
    "    return pd.DataFrame(all_comments)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get channel statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `get_channel_stats` function defined below, now we are going to obtain the channel statistics for the 9 channels in scope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_data = get_channel_stats(youtube, channel_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion <a class='anchor' id='Conclusion'></a>[â†‘](#Top)>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Reference\n",
    "\n",
    "#### Get all items\n",
    "\n",
    "```http\n",
    "  GET /api/items\n",
    "```\n",
    "\n",
    "| Parameter | Type     | Description                |\n",
    "| :-------- | :------- | :------------------------- |\n",
    "| `api_key` | `string` | **AIzaSyDs9TExsfc8fDMn4lBRYXZax1vSr0ftsdk**. YouTube API key |\n",
    "\n",
    "#### Get item\n",
    "\n",
    "```http\n",
    "  GET /api/items/${id}\n",
    "```\n",
    "\n",
    "| Parameter | Type     | Description                       |\n",
    "| :-------- | :------- | :-------------------------------- |\n",
    "| `id`      | `string` | **UCtYLUTtgS3k1Fg4y5tAhLbw** # Statquest\n",
    "| `id`      | `string` | 'UCCezIgC97PvUuR4_gbFUs5g', # Corey Schafer\n",
    "| `id`      | `string` | 'UCfzlCWGWYyIQ0aLC5w48gBQ', # Sentdex\n",
    "| `id`      | `string` | 'UCNU_lfiiWBdtULKOw6X0Dig', # Krish Naik\n",
    "| `id`      | `string` | 'UCzL_0nIe8B4-7ShhVPfJkgw', # DatascienceDoJo\n",
    "| `id`      | `string` | 'UCLLw7jmFsvfIVaUFsLs8mlQ', # Luke Barousse \n",
    "| `id`      | `string` | 'UCiT9RITQ9PW6BhXK0y2jaeg', # Ken Jee\n",
    "| `id`      | `string` | 'UC7cs8q-gJRlGwj4A8OmCmXg', # Alex the analyst\n",
    "| `id`      | `string` | 'UC2UXDak6o7rBm23k3Vv5dww', # Tina Huang\n",
    "\n",
    "\n",
    "#### add(more to follow)\n",
    "\n",
    "Takes two numbers and returns the sum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Badges\n",
    "\n",
    "\n",
    "[![MIT License](https://img.shields.io/badge/License-MIT-green.svg)](https://choosealicense.com/licenses/mit/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link to top of page <a class='anchor' id='Top'>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
